{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abd2336c",
   "metadata": {},
   "source": [
    "# ML Experiments using different bin sizes & widths based on outputs from supervised discretization usinf DT discretizer\n",
    "## Dataset: Satimage\n",
    "\n",
    "by: Malina & Sam , 03.07.2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83bc40c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score, recall_score, precision_score\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "import six\n",
    "import sys\n",
    "sys.modules['sklearn.externals.six'] = six\n",
    "import id3\n",
    "from id3 import Id3Estimator\n",
    "from id3 import export_graphviz\n",
    "import wittgenstein as lw\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from pandas import set_option\n",
    "import numpy as np\n",
    "from numpy import arange\n",
    "## EDA\n",
    "from collections import Counter\n",
    "\n",
    "# Knn-VDM 3\n",
    "from vdm3 import ValueDifferenceMetric\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Pre-processing\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "# Cross validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score # 1 metric\n",
    "from sklearn.model_selection import cross_validate # more than 1 metric\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50eb04fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data from ChiMerge discretization\n",
    "satimage6 = pd.read_csv('DT_small_discretized_satimage.csv')\n",
    "satimage8 = pd.read_csv('DT_medium_discretized_satimage.csv')\n",
    "satimage10 = pd.read_csv('DT_large_discretized_satimage.csv')\n",
    "satimage15 = pd.read_csv('DT_verylarge_discretized_satimage.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c693e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# satimage6 = satimage6.head(500)\n",
    "# satimage8 = satimage8.head(500)\n",
    "# satimage10 = satimage10.head(500)\n",
    "# satimage15 = satimage15.head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "652bdaa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>...</th>\n",
       "      <th>A28</th>\n",
       "      <th>A29</th>\n",
       "      <th>A30</th>\n",
       "      <th>A31</th>\n",
       "      <th>A32</th>\n",
       "      <th>A33</th>\n",
       "      <th>A34</th>\n",
       "      <th>A35</th>\n",
       "      <th>A36</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6430</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6431</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6432</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6433</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6434</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6435 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      A1  A2  A3  A4  A5  A6  A7  A8  A9  A10  ...  A28  A29  A30  A31  A32  \\\n",
       "0      0   0   2   2   1   1   3   2   1    1  ...    1    0    0    3    2   \n",
       "1      0   0   2   2   1   0   3   2   1    0  ...    1    0    0    3    2   \n",
       "2      2   2   1   2   2   2   0   2   2    2  ...    2    2    2    0    1   \n",
       "3      2   1   2   2   2   2   3   2   2    2  ...    1    2    0    3    2   \n",
       "4      2   2   0   0   2   2   0   1   2    2  ...    0    2    2    0    0   \n",
       "...   ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...  ...  ...  ...  ...  ...   \n",
       "6430   2   2   0   0   2   2   0   0   2    2  ...    1    2    2    2    1   \n",
       "6431   1   1   2   2   2   2   2   2   2    2  ...    1    1    2    2    2   \n",
       "6432   3   3   3   3   3   3   3   3   3    3  ...    3    3    3    3    3   \n",
       "6433   2   2   0   0   2   2   0   0   2    2  ...    0    2    2    0    0   \n",
       "6434   2   1   2   2   2   0   3   2   2    0  ...    1    2    0    3    2   \n",
       "\n",
       "      A33  A34  A35  A36  class  \n",
       "0       2    2    3    2      2  \n",
       "1       0    0    3    2      2  \n",
       "2       2    2    1    2      0  \n",
       "3       2    1    3    2      0  \n",
       "4       2    2    0    1      5  \n",
       "...   ...  ...  ...  ...    ...  \n",
       "6430    2    2    2    0      5  \n",
       "6431    0    1    3    2      3  \n",
       "6432    3    3    3    3      1  \n",
       "6433    2    2    0    1      4  \n",
       "6434    2    0    3    2      0  \n",
       "\n",
       "[6435 rows x 37 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "satimage6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24075c8",
   "metadata": {},
   "source": [
    "## Interval frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94258ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_list6 = satimage6.columns.drop('class')\n",
    "num_list8 = satimage8.columns.drop('class')\n",
    "num_list10 = satimage10.columns.drop('class')\n",
    "num_list15 = satimage15.columns.drop('class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be896d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interval frequency for 6 Intervals\n",
      "Interval for A1\n",
      "Counter({2: 4224, 0: 1048, 1: 617, 3: 546})\n",
      "Interval for A2\n",
      "Counter({2: 3210, 0: 1893, 1: 773, 3: 559})\n",
      "Interval for A3\n",
      "Counter({2: 3159, 0: 1624, 1: 829, 3: 823})\n",
      "Interval for A4\n",
      "Counter({2: 3545, 0: 1295, 1: 1047, 3: 548})\n",
      "Interval for A5\n",
      "Counter({2: 4408, 0: 1023, 3: 555, 1: 449})\n",
      "Interval for A6\n",
      "Counter({2: 3380, 0: 1855, 1: 629, 3: 571})\n",
      "Interval for A7\n",
      "Counter({3: 3222, 0: 1654, 2: 966, 1: 593})\n",
      "Interval for A8\n",
      "Counter({2: 3658, 0: 1253, 1: 974, 3: 550})\n",
      "Interval for A9\n",
      "Counter({2: 4436, 0: 982, 3: 564, 1: 453})\n",
      "Interval for A10\n",
      "Counter({2: 3329, 0: 1732, 1: 775, 3: 599})\n",
      "Interval for A11\n",
      "Counter({3: 3183, 0: 1538, 2: 1017, 1: 697})\n",
      "Interval for A12\n",
      "Counter({2: 3753, 0: 1262, 1: 852, 3: 568})\n",
      "Interval for A13\n",
      "Counter({2: 4393, 0: 1032, 3: 556, 1: 454})\n",
      "Interval for A14\n",
      "Counter({2: 3238, 0: 2227, 3: 564, 1: 406})\n",
      "Interval for A15\n",
      "Counter({2: 2933, 0: 1739, 3: 1047, 1: 716})\n",
      "Interval for A16\n",
      "Counter({2: 3826, 0: 1235, 1: 821, 3: 553})\n",
      "Interval for A17\n",
      "Counter({1: 4416, 0: 1451, 2: 568})\n",
      "Interval for A18\n",
      "Counter({1: 3569, 0: 2289, 2: 577})\n",
      "Interval for A19\n",
      "Counter({3: 3215, 0: 1649, 1: 835, 2: 736})\n",
      "Interval for A20\n",
      "Counter({2: 3666, 0: 1252, 1: 966, 3: 551})\n",
      "Interval for A21\n",
      "Counter({2: 4442, 0: 974, 3: 575, 1: 444})\n",
      "Interval for A22\n",
      "Counter({2: 3267, 0: 2175, 3: 587, 1: 406})\n",
      "Interval for A23\n",
      "Counter({3: 3181, 0: 1463, 2: 1025, 1: 766})\n",
      "Interval for A24\n",
      "Counter({2: 3830, 0: 1267, 1: 765, 3: 573})\n",
      "Interval for A25\n",
      "Counter({2: 4400, 0: 805, 1: 657, 3: 573})\n",
      "Interval for A26\n",
      "Counter({2: 3324, 0: 1767, 1: 771, 3: 573})\n",
      "Interval for A27\n",
      "Counter({2: 2789, 0: 1751, 3: 1102, 1: 793})\n",
      "Interval for A28\n",
      "Counter({1: 3671, 0: 1227, 2: 976, 3: 561})\n",
      "Interval for A29\n",
      "Counter({2: 4370, 0: 923, 1: 642, 3: 500})\n",
      "Interval for A30\n",
      "Counter({2: 3339, 0: 1849, 1: 674, 3: 573})\n",
      "Interval for A31\n",
      "Counter({3: 2976, 0: 1443, 2: 1273, 1: 743})\n",
      "Interval for A32\n",
      "Counter({2: 3800, 0: 1252, 1: 823, 3: 560})\n",
      "Interval for A33\n",
      "Counter({2: 4268, 0: 1172, 3: 501, 1: 494})\n",
      "Interval for A34\n",
      "Counter({2: 3365, 0: 1832, 1: 657, 3: 581})\n",
      "Interval for A35\n",
      "Counter({3: 3176, 0: 1471, 2: 1182, 1: 606})\n",
      "Interval for A36\n",
      "Counter({2: 3998, 1: 1270, 0: 616, 3: 551})\n"
     ]
    }
   ],
   "source": [
    "print('Interval frequency for 6 Intervals')\n",
    "for i in num_list6:\n",
    "    print('Interval for ' + i)\n",
    "    print(Counter(satimage6[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3edf860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency for iris with 8 Intervals\n",
      "Interval for A1\n",
      "Counter({4: 3071, 5: 1153, 1: 934, 7: 484, 2: 461, 3: 156, 0: 114, 6: 62})\n",
      "Interval for A2\n",
      "Counter({4: 2621, 1: 1806, 5: 589, 7: 485, 2: 424, 3: 349, 0: 87, 6: 74})\n",
      "Interval for A3\n",
      "Counter({5: 2419, 1: 1492, 4: 740, 6: 727, 3: 557, 2: 272, 0: 132, 7: 96})\n",
      "Interval for A4\n",
      "Counter({3: 2862, 2: 1221, 4: 728, 5: 683, 7: 500, 1: 319, 0: 74, 6: 48})\n",
      "Interval for A5\n",
      "Counter({3: 3227, 5: 1181, 1: 897, 7: 452, 2: 313, 4: 136, 0: 126, 6: 103})\n",
      "Interval for A6\n",
      "Counter({3: 2866, 1: 1775, 7: 528, 5: 514, 2: 428, 4: 201, 0: 80, 6: 43})\n",
      "Interval for A7\n",
      "Counter({6: 2406, 1: 1519, 7: 816, 4: 519, 5: 447, 2: 386, 3: 207, 0: 135})\n",
      "Interval for A8\n",
      "Counter({3: 2977, 2: 1178, 5: 681, 4: 579, 7: 503, 1: 395, 0: 75, 6: 47})\n",
      "Interval for A9\n",
      "Counter({2: 3250, 5: 1186, 0: 786, 7: 499, 1: 321, 3: 196, 4: 132, 6: 65})\n",
      "Interval for A10\n",
      "Counter({3: 2823, 1: 1664, 7: 544, 5: 506, 4: 503, 2: 272, 0: 68, 6: 55})\n",
      "Interval for A11\n",
      "Counter({6: 2398, 1: 1426, 7: 785, 5: 657, 3: 421, 4: 360, 2: 276, 0: 112})\n",
      "Interval for A12\n",
      "Counter({3: 3105, 1: 1193, 5: 648, 7: 539, 4: 431, 2: 421, 0: 69, 6: 29})\n",
      "Interval for A13\n",
      "Counter({4: 3234, 5: 1159, 1: 832, 7: 447, 2: 315, 0: 200, 3: 139, 6: 109})\n",
      "Interval for A14\n",
      "Counter({3: 2667, 1: 2141, 4: 571, 6: 525, 2: 342, 0: 150, 5: 39})\n",
      "Interval for A15\n",
      "Counter({5: 2182, 1: 1712, 6: 954, 4: 751, 2: 415, 3: 301, 7: 93, 0: 27})\n",
      "Interval for A16\n",
      "Counter({4: 2841, 1: 1140, 3: 985, 6: 499, 0: 477, 2: 439, 5: 54})\n",
      "Interval for A17\n",
      "Counter({1: 3237, 0: 1451, 2: 1179, 4: 461, 3: 107})\n",
      "Interval for A18\n",
      "Counter({1: 2978, 0: 2289, 2: 591, 4: 557, 3: 20})\n",
      "Interval for A19\n",
      "Counter({6: 2389, 1: 1532, 7: 826, 5: 439, 3: 434, 2: 401, 4: 297, 0: 117})\n",
      "Interval for A20\n",
      "Counter({2: 2724, 0: 1646, 3: 942, 1: 572, 5: 507, 4: 44})\n",
      "Interval for A21\n",
      "Counter({3: 3262, 5: 1180, 0: 776, 7: 464, 1: 302, 2: 198, 4: 142, 6: 111})\n",
      "Interval for A22\n",
      "Counter({2: 2661, 1: 2105, 5: 606, 7: 542, 3: 336, 0: 70, 4: 70, 6: 45})\n",
      "Interval for A23\n",
      "Counter({6: 2360, 1: 1295, 7: 821, 4: 587, 5: 438, 2: 425, 3: 341, 0: 168})\n",
      "Interval for A24\n",
      "Counter({5: 2769, 2: 1199, 4: 1061, 7: 544, 1: 415, 3: 350, 0: 68, 6: 29})\n",
      "Interval for A25\n",
      "Counter({4: 3257, 5: 1143, 7: 501, 2: 472, 3: 442, 0: 333, 1: 215, 6: 72})\n",
      "Interval for A26\n",
      "Counter({4: 2773, 2: 1676, 5: 551, 7: 531, 1: 435, 3: 336, 0: 91, 6: 42})\n",
      "Interval for A27\n",
      "Counter({5: 1959, 1: 1590, 6: 1008, 4: 830, 3: 651, 0: 161, 2: 142, 7: 94})\n",
      "Interval for A28\n",
      "Counter({3: 2973, 2: 1159, 5: 698, 4: 593, 7: 512, 1: 383, 0: 68, 6: 49})\n",
      "Interval for A29\n",
      "Counter({4: 3125, 5: 1245, 1: 782, 2: 364, 3: 278, 7: 252, 6: 248, 0: 141})\n",
      "Interval for A30\n",
      "Counter({3: 2756, 1: 1767, 4: 583, 6: 502, 2: 381, 0: 375, 5: 71})\n",
      "Interval for A31\n",
      "Counter({6: 1874, 1: 1278, 7: 1102, 4: 743, 5: 530, 2: 480, 3: 263, 0: 165})\n",
      "Interval for A32\n",
      "Counter({3: 2867, 2: 1183, 5: 933, 7: 509, 4: 445, 1: 378, 0: 69, 6: 51})\n",
      "Interval for A33\n",
      "Counter({2: 2999, 3: 1269, 0: 1245, 5: 457, 1: 421, 4: 44})\n",
      "Interval for A34\n",
      "Counter({3: 2859, 1: 1762, 6: 563, 4: 506, 2: 382, 0: 345, 5: 18})\n",
      "Interval for A35\n",
      "Counter({6: 2091, 2: 1356, 7: 1085, 4: 889, 3: 405, 5: 293, 1: 201, 0: 115})\n",
      "Interval for A36\n",
      "Counter({3: 2807, 4: 1199, 5: 1191, 7: 508, 1: 397, 2: 219, 0: 71, 6: 43})\n"
     ]
    }
   ],
   "source": [
    "print('Frequency for iris with 8 Intervals')\n",
    "for i in num_list8:\n",
    "    print('Interval for ' + i)\n",
    "    print(Counter(satimage8[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd8cdde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency for iris with 10 Intervals\n",
      "Interval for A1\n",
      "Counter({4: 2245, 7: 994, 6: 826, 1: 802, 11: 385, 3: 323, 0: 246, 8: 159, 5: 156, 2: 138, 10: 99, 9: 62})\n",
      "Interval for A2\n",
      "Counter({5: 1963, 1: 998, 0: 895, 6: 658, 9: 488, 13: 398, 2: 356, 4: 272, 8: 101, 12: 87, 3: 77, 11: 71, 7: 68, 10: 3})\n",
      "Interval for A3\n",
      "Counter({9: 1555, 1: 951, 10: 864, 3: 541, 11: 471, 8: 440, 4: 328, 7: 300, 12: 256, 5: 229, 2: 199, 0: 132, 6: 73, 13: 53, 14: 43})\n",
      "Interval for A4\n",
      "Counter({4: 2157, 2: 1186, 6: 705, 8: 629, 7: 446, 13: 400, 5: 282, 3: 179, 1: 140, 0: 109, 12: 100, 9: 54, 11: 29, 10: 19})\n",
      "Interval for A5\n",
      "Counter({5: 2343, 3: 884, 1: 762, 6: 746, 8: 435, 0: 261, 12: 259, 2: 242, 11: 193, 7: 136, 4: 71, 9: 66, 10: 37})\n",
      "Interval for A6\n",
      "Counter({4: 1755, 3: 1111, 1: 986, 0: 869, 7: 436, 11: 400, 2: 228, 5: 201, 6: 200, 10: 128, 8: 78, 9: 43})\n",
      "Interval for A7\n",
      "Counter({10: 1764, 2: 892, 12: 686, 11: 642, 1: 627, 5: 307, 3: 267, 0: 254, 9: 227, 8: 220, 7: 212, 4: 147, 13: 130, 6: 60})\n",
      "Interval for A8\n",
      "Counter({6: 2222, 8: 755, 1: 727, 9: 627, 14: 491, 5: 451, 7: 442, 3: 212, 2: 183, 4: 137, 0: 75, 10: 54, 12: 37, 13: 12, 11: 10})\n",
      "Interval for A9\n",
      "Counter({6: 2302, 2: 948, 9: 931, 3: 433, 0: 353, 13: 258, 10: 255, 1: 247, 12: 241, 8: 138, 7: 132, 4: 74, 11: 65, 5: 58})\n",
      "Interval for A10\n",
      "Counter({7: 1971, 2: 890, 4: 852, 1: 774, 9: 453, 13: 405, 8: 303, 3: 201, 6: 200, 12: 139, 0: 121, 5: 71, 11: 38, 10: 17})\n",
      "Interval for A11\n",
      "Counter({12: 1428, 11: 970, 2: 826, 13: 700, 3: 600, 10: 449, 7: 299, 4: 271, 8: 208, 6: 150, 5: 148, 1: 128, 0: 112, 14: 85, 9: 61})\n",
      "Interval for A12\n",
      "Counter({8: 1938, 5: 1167, 1: 733, 9: 541, 14: 504, 4: 460, 7: 296, 2: 227, 3: 194, 6: 135, 10: 107, 0: 69, 13: 35, 12: 18, 11: 11})\n",
      "Interval for A13\n",
      "Counter({3: 2343, 6: 909, 5: 891, 1: 597, 0: 509, 7: 250, 11: 244, 2: 241, 10: 203, 4: 139, 8: 66, 9: 43})\n",
      "Interval for A14\n",
      "Counter({3: 1698, 1: 1336, 0: 1087, 4: 969, 6: 477, 10: 418, 2: 210, 9: 107, 5: 94, 8: 34, 7: 5})\n",
      "Interval for A15\n",
      "Counter({10: 1653, 1: 1383, 11: 692, 9: 529, 8: 449, 2: 329, 7: 302, 4: 263, 12: 262, 6: 182, 3: 152, 5: 119, 13: 75, 0: 27, 14: 18})\n",
      "Interval for A16\n",
      "Counter({2: 2133, 0: 918, 7: 708, 1: 699, 6: 619, 11: 464, 5: 366, 3: 300, 4: 139, 10: 35, 9: 32, 8: 22})\n",
      "Interval for A17\n",
      "Counter({2: 2367, 0: 1451, 1: 870, 3: 742, 4: 437, 8: 258, 7: 203, 5: 65, 6: 42})\n",
      "Interval for A18\n",
      "Counter({0: 2289, 2: 1699, 1: 1279, 7: 536, 4: 485, 3: 106, 6: 21, 5: 20})\n",
      "Interval for A19\n",
      "Counter({9: 1865, 0: 1157, 11: 735, 1: 612, 10: 524, 4: 294, 2: 281, 7: 229, 5: 224, 8: 210, 3: 140, 12: 91, 6: 73})\n",
      "Interval for A20\n",
      "Counter({2: 1704, 0: 1646, 4: 1020, 5: 536, 9: 507, 1: 432, 6: 406, 3: 140, 8: 34, 7: 10})\n",
      "Interval for A21\n",
      "Counter({5: 2416, 9: 1069, 3: 846, 1: 570, 14: 260, 2: 232, 0: 206, 13: 204, 6: 142, 4: 139, 10: 111, 7: 70, 11: 66, 8: 59, 12: 45})\n",
      "Interval for A22\n",
      "Counter({4: 1722, 1: 1328, 2: 939, 0: 847, 12: 510, 8: 462, 3: 261, 7: 144, 6: 75, 5: 70, 10: 38, 11: 32, 9: 7})\n",
      "Interval for A23\n",
      "Counter({11: 1853, 1: 872, 13: 737, 12: 507, 3: 423, 5: 296, 8: 291, 2: 266, 9: 229, 7: 220, 10: 209, 0: 168, 6: 159, 4: 121, 14: 84})\n",
      "Interval for A24\n",
      "Counter({3: 2085, 1: 744, 5: 703, 9: 684, 13: 469, 4: 455, 8: 358, 0: 246, 2: 237, 6: 215, 7: 135, 12: 75, 10: 17, 11: 12})\n",
      "Interval for A25\n",
      "Counter({8: 2358, 7: 899, 9: 725, 13: 459, 10: 418, 5: 332, 1: 270, 6: 237, 2: 205, 3: 140, 4: 140, 0: 138, 11: 72, 12: 42})\n",
      "Interval for A26\n",
      "Counter({5: 1699, 6: 1074, 2: 884, 1: 792, 12: 503, 8: 469, 3: 307, 0: 279, 4: 276, 7: 82, 11: 28, 9: 21, 10: 21})\n",
      "Interval for A27\n",
      "Counter({1: 1251, 9: 1248, 10: 711, 11: 522, 12: 486, 8: 459, 5: 388, 7: 371, 3: 339, 4: 263, 0: 161, 2: 73, 6: 69, 13: 50, 14: 44})\n",
      "Interval for A28\n",
      "Counter({4: 2121, 3: 1115, 5: 852, 8: 680, 7: 448, 12: 346, 1: 211, 2: 172, 13: 166, 6: 145, 0: 112, 11: 36, 9: 18, 10: 13})\n",
      "Interval for A29\n",
      "Counter({6: 2394, 8: 738, 7: 731, 9: 507, 1: 445, 2: 337, 3: 288, 0: 217, 12: 148, 11: 144, 4: 139, 5: 139, 13: 104, 10: 104})\n",
      "Interval for A30\n",
      "Counter({4: 1721, 0: 1222, 3: 1035, 1: 977, 10: 429, 5: 402, 2: 324, 6: 181, 9: 73, 8: 52, 7: 19})\n",
      "Interval for A31\n",
      "Counter({12: 1311, 14: 1015, 3: 931, 13: 563, 11: 452, 7: 443, 1: 347, 9: 300, 5: 255, 6: 225, 8: 138, 2: 137, 4: 125, 15: 87, 10: 78, 0: 28})\n",
      "Interval for A32\n",
      "Counter({4: 1707, 5: 1160, 3: 1138, 7: 883, 14: 418, 8: 366, 1: 208, 2: 170, 13: 91, 9: 79, 0: 69, 10: 50, 6: 45, 12: 38, 11: 13})\n",
      "Interval for A33\n",
      "Counter({4: 2418, 0: 1245, 5: 1027, 3: 581, 1: 280, 9: 259, 6: 242, 8: 198, 2: 141, 7: 44})\n",
      "Interval for A34\n",
      "Counter({4: 2012, 0: 1115, 1: 992, 3: 847, 10: 507, 6: 391, 2: 322, 7: 115, 5: 60, 9: 56, 8: 18})\n",
      "Interval for A35\n",
      "Counter({10: 1305, 5: 1082, 13: 920, 11: 786, 6: 447, 8: 442, 7: 332, 3: 274, 9: 219, 14: 165, 4: 129, 1: 95, 0: 92, 12: 74, 2: 73})\n",
      "Interval for A36\n",
      "Counter({4: 2107, 5: 1093, 8: 700, 7: 692, 6: 499, 13: 413, 1: 327, 0: 141, 2: 136, 9: 106, 12: 95, 3: 83, 11: 26, 10: 17})\n"
     ]
    }
   ],
   "source": [
    "print('Frequency for iris with 10 Intervals')\n",
    "for i in num_list10:\n",
    "    print('Interval for ' + i)\n",
    "    print(Counter(satimage10[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25638c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency for iris with 15 Intervals\n",
      "Interval for A1\n",
      "Counter({3: 1324, 8: 921, 1: 779, 11: 622, 6: 434, 10: 392, 7: 372, 0: 269, 4: 250, 17: 247, 5: 156, 16: 138, 2: 138, 13: 114, 15: 99, 9: 73, 14: 62, 12: 45})\n",
      "Interval for A2\n",
      "Counter({7: 1522, 0: 1145, 1: 915, 4: 441, 11: 413, 6: 378, 8: 280, 2: 222, 20: 219, 5: 200, 19: 179, 3: 77, 13: 75, 9: 72, 18: 69, 12: 68, 10: 68, 15: 40, 16: 31, 17: 18, 14: 3})\n",
      "Interval for A3\n",
      "Counter({16: 1040, 1: 723, 17: 515, 3: 482, 15: 466, 18: 398, 19: 241, 20: 230, 4: 228, 14: 226, 12: 217, 13: 214, 7: 211, 0: 208, 8: 178, 21: 140, 2: 123, 5: 117, 22: 116, 6: 83, 10: 73, 9: 59, 24: 53, 11: 51, 25: 26, 23: 17})\n",
      "Interval for A4\n",
      "Counter({7: 1670, 1: 687, 9: 499, 5: 487, 12: 371, 13: 363, 14: 344, 4: 342, 8: 285, 23: 208, 22: 192, 0: 184, 11: 145, 2: 140, 6: 137, 3: 125, 21: 95, 10: 54, 15: 34, 16: 20, 20: 16, 17: 14, 19: 13, 18: 10})\n",
      "Interval for A5\n",
      "Counter({7: 1751, 3: 597, 6: 592, 0: 514, 1: 509, 8: 386, 10: 360, 5: 287, 11: 276, 17: 259, 2: 242, 12: 159, 9: 136, 16: 131, 4: 71, 13: 66, 15: 62, 14: 37})\n",
      "Interval for A6\n",
      "Counter({5: 1588, 0: 949, 1: 906, 6: 787, 11: 334, 3: 324, 17: 264, 2: 228, 7: 201, 16: 169, 9: 167, 8: 127, 10: 102, 15: 95, 4: 73, 13: 65, 14: 43, 12: 13})\n",
      "Interval for A7\n",
      "Counter({15: 1233, 2: 750, 16: 531, 1: 487, 18: 474, 17: 395, 0: 254, 14: 247, 6: 229, 12: 227, 11: 212, 19: 212, 3: 197, 7: 147, 13: 146, 4: 142, 5: 140, 8: 138, 21: 92, 10: 74, 9: 70, 20: 38})\n",
      "Interval for A8\n",
      "Counter({9: 1750, 1: 691, 10: 476, 7: 472, 14: 340, 5: 325, 0: 307, 8: 287, 11: 279, 22: 262, 21: 231, 13: 229, 3: 213, 4: 137, 2: 131, 6: 126, 12: 68, 15: 35, 19: 25, 16: 19, 18: 12, 20: 10, 17: 10})\n",
      "Interval for A9\n",
      "Counter({2: 1335, 11: 967, 14: 548, 1: 543, 6: 405, 12: 383, 0: 353, 7: 304, 4: 247, 19: 203, 21: 152, 15: 137, 10: 132, 3: 129, 16: 118, 20: 106, 13: 75, 5: 74, 17: 65, 9: 63, 8: 58, 18: 38})\n",
      "Interval for A10\n",
      "Counter({4: 1797, 2: 754, 6: 723, 1: 646, 0: 506, 12: 390, 20: 261, 7: 217, 3: 201, 10: 174, 19: 144, 9: 136, 18: 98, 8: 86, 11: 72, 5: 71, 13: 63, 17: 41, 16: 21, 14: 17, 15: 17})\n",
      "Interval for A11\n",
      "Counter({17: 895, 15: 702, 1: 605, 16: 533, 4: 459, 19: 448, 13: 305, 18: 268, 0: 253, 20: 252, 8: 248, 5: 221, 11: 208, 3: 199, 7: 150, 6: 148, 14: 144, 2: 128, 9: 72, 21: 64, 12: 61, 10: 51, 22: 21})\n",
      "Interval for A12\n",
      "Counter({11: 1476, 8: 730, 1: 705, 10: 462, 3: 437, 5: 330, 12: 276, 14: 265, 22: 263, 21: 241, 0: 224, 13: 223, 2: 155, 6: 140, 9: 135, 4: 130, 7: 72, 16: 55, 15: 52, 19: 20, 18: 18, 20: 15, 17: 11})\n",
      "Interval for A13\n",
      "Counter({4: 1417, 7: 926, 9: 733, 0: 509, 8: 470, 2: 421, 3: 308, 1: 289, 5: 241, 10: 176, 17: 143, 6: 139, 16: 137, 11: 134, 12: 116, 18: 101, 13: 66, 15: 66, 14: 43})\n",
      "Interval for A14\n",
      "Counter({6: 1185, 0: 1087, 2: 994, 4: 651, 5: 513, 10: 400, 1: 342, 7: 318, 16: 241, 17: 212, 3: 210, 12: 77, 15: 72, 8: 64, 9: 30, 13: 20, 14: 14, 11: 5})\n",
      "Interval for A15\n",
      "Counter({2: 1136, 16: 869, 18: 784, 20: 482, 15: 379, 1: 247, 14: 232, 12: 227, 13: 217, 3: 212, 19: 210, 9: 182, 21: 174, 17: 150, 7: 135, 6: 128, 4: 117, 0: 93, 22: 88, 5: 82, 10: 75, 8: 70, 11: 53, 23: 45, 24: 30, 25: 18})\n",
      "Interval for A16\n",
      "Counter({3: 1634, 0: 998, 1: 587, 7: 499, 17: 481, 12: 400, 9: 327, 4: 308, 10: 292, 5: 278, 8: 220, 6: 139, 2: 112, 11: 88, 15: 25, 14: 19, 16: 18, 13: 10})\n",
      "Interval for A17\n",
      "Counter({0: 1731, 1: 1435, 2: 932, 3: 590, 5: 388, 4: 354, 6: 326, 12: 153, 11: 138, 7: 111, 13: 105, 8: 65, 10: 65, 9: 42})\n",
      "Interval for A18\n",
      "Counter({0: 2289, 3: 1171, 1: 957, 12: 536, 4: 528, 5: 410, 2: 322, 8: 75, 7: 72, 6: 34, 9: 20, 11: 16, 10: 5})\n",
      "Interval for A19\n",
      "Counter({12: 1209, 0: 1157, 14: 656, 17: 477, 2: 400, 16: 381, 18: 258, 10: 229, 7: 224, 1: 212, 6: 179, 4: 153, 15: 143, 13: 141, 5: 140, 3: 128, 8: 115, 9: 73, 11: 69, 20: 46, 19: 45})\n",
      "Interval for A20\n",
      "Counter({0: 1646, 4: 1436, 9: 545, 15: 507, 6: 475, 1: 356, 10: 351, 7: 308, 3: 268, 8: 228, 5: 140, 2: 76, 11: 55, 14: 25, 12: 10, 13: 9})\n",
      "Interval for A21\n",
      "Counter({5: 1475, 9: 941, 11: 753, 1: 566, 0: 550, 12: 316, 2: 286, 4: 280, 3: 232, 18: 152, 7: 142, 17: 139, 13: 111, 19: 108, 6: 79, 8: 70, 14: 66, 16: 65, 10: 59, 15: 45})\n",
      "Interval for A22\n",
      "Counter({6: 1197, 0: 847, 1: 768, 2: 621, 3: 560, 9: 525, 19: 510, 13: 391, 4: 318, 5: 202, 12: 106, 11: 75, 14: 71, 7: 70, 8: 59, 10: 38, 17: 32, 16: 21, 18: 17, 15: 7})\n",
      "Interval for A23\n",
      "Counter({17: 1458, 1: 750, 21: 482, 19: 395, 0: 366, 5: 347, 20: 282, 22: 255, 6: 233, 14: 229, 16: 225, 9: 220, 13: 144, 18: 135, 4: 135, 2: 131, 7: 121, 10: 84, 8: 76, 3: 75, 15: 74, 12: 71, 23: 64, 11: 63, 24: 20})\n",
      "Interval for A24\n",
      "Counter({6: 1613, 1: 717, 14: 630, 2: 472, 7: 364, 21: 351, 0: 347, 11: 339, 4: 337, 10: 275, 3: 163, 5: 137, 9: 135, 20: 118, 8: 118, 13: 83, 12: 78, 15: 54, 19: 45, 18: 30, 16: 17, 17: 12})\n",
      "Interval for A25\n",
      "Counter({10: 1399, 8: 959, 12: 483, 9: 475, 6: 424, 0: 336, 13: 305, 1: 270, 5: 253, 18: 249, 11: 242, 7: 237, 17: 210, 3: 144, 2: 140, 14: 113, 4: 82, 15: 72, 16: 42})\n",
      "Interval for A26\n",
      "Counter({9: 1174, 3: 741, 4: 678, 10: 618, 7: 525, 6: 456, 20: 426, 0: 402, 11: 351, 1: 221, 2: 206, 8: 204, 14: 118, 5: 86, 19: 77, 13: 51, 12: 31, 18: 28, 16: 21, 17: 15, 15: 6})\n",
      "Interval for A27\n",
      "Counter({2: 730, 18: 667, 15: 581, 1: 521, 20: 449, 13: 387, 19: 360, 14: 351, 9: 311, 5: 269, 22: 257, 21: 229, 10: 221, 0: 161, 17: 150, 6: 132, 11: 131, 7: 77, 16: 73, 4: 73, 12: 72, 3: 70, 8: 69, 23: 27, 26: 25, 25: 23, 24: 19})\n",
      "Interval for A28\n",
      "Counter({5: 1560, 1: 696, 7: 561, 9: 479, 4: 419, 13: 375, 8: 373, 6: 305, 18: 301, 0: 231, 12: 225, 11: 223, 19: 166, 2: 145, 10: 145, 3: 119, 17: 63, 14: 18, 16: 18, 15: 13})\n",
      "Interval for A29\n",
      "Counter({8: 1440, 7: 954, 0: 679, 10: 668, 9: 457, 12: 322, 1: 319, 4: 274, 2: 226, 13: 185, 17: 148, 16: 144, 3: 139, 5: 139, 18: 104, 11: 70, 6: 63, 15: 61, 14: 43})\n",
      "Interval for A30\n",
      "Counter({0: 1434, 5: 1196, 1: 765, 2: 651, 7: 525, 6: 384, 8: 328, 17: 277, 3: 264, 16: 157, 10: 99, 9: 82, 11: 74, 15: 68, 4: 60, 13: 39, 12: 19, 14: 13})\n",
      "Interval for A31\n",
      "Counter({16: 949, 2: 874, 20: 752, 0: 462, 14: 379, 17: 362, 6: 294, 18: 284, 19: 279, 21: 263, 11: 239, 8: 151, 13: 149, 5: 140, 10: 138, 3: 125, 4: 115, 1: 107, 12: 78, 7: 74, 15: 73, 22: 68, 9: 61, 23: 19})\n",
      "Interval for A32\n",
      "Counter({4: 1337, 3: 704, 8: 618, 7: 546, 5: 542, 20: 460, 6: 434, 9: 370, 12: 337, 10: 223, 0: 216, 1: 146, 11: 143, 2: 120, 13: 79, 19: 49, 18: 38, 15: 31, 16: 19, 17: 13, 14: 10})\n",
      "Interval for A33\n",
      "Counter({6: 1777, 0: 1384, 7: 752, 3: 641, 4: 314, 8: 275, 1: 267, 9: 168, 14: 152, 5: 141, 2: 141, 13: 139, 15: 107, 10: 74, 12: 59, 11: 44})\n",
      "Interval for A34\n",
      "Counter({5: 1848, 0: 1391, 1: 774, 4: 717, 16: 438, 8: 314, 2: 264, 9: 164, 3: 130, 11: 77, 15: 69, 7: 65, 6: 60, 10: 50, 14: 41, 12: 18, 13: 15})\n",
      "Interval for A35\n",
      "Counter({13: 945, 6: 791, 16: 710, 18: 500, 20: 420, 15: 360, 9: 313, 11: 305, 7: 291, 10: 262, 5: 245, 12: 219, 14: 137, 8: 134, 4: 129, 0: 105, 1: 99, 22: 84, 2: 82, 21: 81, 19: 76, 17: 74, 3: 73})\n",
      "Interval for A36\n",
      "Counter({5: 1573, 6: 721, 4: 534, 13: 389, 7: 372, 10: 363, 8: 361, 21: 349, 11: 329, 9: 311, 1: 275, 0: 193, 12: 138, 2: 136, 3: 83, 20: 80, 15: 65, 18: 51, 19: 44, 14: 41, 17: 20, 16: 7})\n"
     ]
    }
   ],
   "source": [
    "print('Frequency for iris with 15 Intervals')\n",
    "for i in num_list15:\n",
    "    print('Interval for ' + i)\n",
    "    print(Counter(satimage15[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2d79abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6435 entries, 0 to 6434\n",
      "Data columns (total 37 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   A1      6435 non-null   int64\n",
      " 1   A2      6435 non-null   int64\n",
      " 2   A3      6435 non-null   int64\n",
      " 3   A4      6435 non-null   int64\n",
      " 4   A5      6435 non-null   int64\n",
      " 5   A6      6435 non-null   int64\n",
      " 6   A7      6435 non-null   int64\n",
      " 7   A8      6435 non-null   int64\n",
      " 8   A9      6435 non-null   int64\n",
      " 9   A10     6435 non-null   int64\n",
      " 10  A11     6435 non-null   int64\n",
      " 11  A12     6435 non-null   int64\n",
      " 12  A13     6435 non-null   int64\n",
      " 13  A14     6435 non-null   int64\n",
      " 14  A15     6435 non-null   int64\n",
      " 15  A16     6435 non-null   int64\n",
      " 16  A17     6435 non-null   int64\n",
      " 17  A18     6435 non-null   int64\n",
      " 18  A19     6435 non-null   int64\n",
      " 19  A20     6435 non-null   int64\n",
      " 20  A21     6435 non-null   int64\n",
      " 21  A22     6435 non-null   int64\n",
      " 22  A23     6435 non-null   int64\n",
      " 23  A24     6435 non-null   int64\n",
      " 24  A25     6435 non-null   int64\n",
      " 25  A26     6435 non-null   int64\n",
      " 26  A27     6435 non-null   int64\n",
      " 27  A28     6435 non-null   int64\n",
      " 28  A29     6435 non-null   int64\n",
      " 29  A30     6435 non-null   int64\n",
      " 30  A31     6435 non-null   int64\n",
      " 31  A32     6435 non-null   int64\n",
      " 32  A33     6435 non-null   int64\n",
      " 33  A34     6435 non-null   int64\n",
      " 34  A35     6435 non-null   int64\n",
      " 35  A36     6435 non-null   int64\n",
      " 36  class   6435 non-null   int64\n",
      "dtypes: int64(37)\n",
      "memory usage: 1.8 MB\n"
     ]
    }
   ],
   "source": [
    "satimage6.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d563125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>...</th>\n",
       "      <th>A28</th>\n",
       "      <th>A29</th>\n",
       "      <th>A30</th>\n",
       "      <th>A31</th>\n",
       "      <th>A32</th>\n",
       "      <th>A33</th>\n",
       "      <th>A34</th>\n",
       "      <th>A35</th>\n",
       "      <th>A36</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4435</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4436</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4437</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4438</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4439</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6430</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6431</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6432</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6433</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6434</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      A1  A2  A3  A4  A5  A6  A7  A8  A9  A10  ...  A28  A29  A30  A31  A32  \\\n",
       "4435   0   0   2   2   0   0   3   2   0    0  ...    1    0    0    3    2   \n",
       "4436   2   2   1   1   2   2   1   0   2    2  ...    2    1    1    3    2   \n",
       "4437   2   1   2   2   2   2   3   2   2    2  ...    1    2    2    3    2   \n",
       "4438   2   2   0   1   2   2   2   0   2    2  ...    2    2    2    1    1   \n",
       "4439   1   2   2   2   2   1   2   2   2    1  ...    1    0    0    3    2   \n",
       "...   ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...  ...  ...  ...  ...  ...   \n",
       "6430   2   2   0   0   2   2   0   0   2    2  ...    1    2    2    2    1   \n",
       "6431   1   1   2   2   2   2   2   2   2    2  ...    1    1    2    2    2   \n",
       "6432   3   3   3   3   3   3   3   3   3    3  ...    3    3    3    3    3   \n",
       "6433   2   2   0   0   2   2   0   0   2    2  ...    0    2    2    0    0   \n",
       "6434   2   1   2   2   2   0   3   2   2    0  ...    1    2    0    3    2   \n",
       "\n",
       "      A33  A34  A35  A36  class  \n",
       "4435    0    0    3    2      2  \n",
       "4436    0    0    3    2      5  \n",
       "4437    2    2    3    2      4  \n",
       "4438    2    2    2    0      3  \n",
       "4439    0    1    3    2      2  \n",
       "...   ...  ...  ...  ...    ...  \n",
       "6430    2    2    2    0      5  \n",
       "6431    0    1    3    2      3  \n",
       "6432    3    3    3    3      1  \n",
       "6433    2    2    0    1      4  \n",
       "6434    2    0    3    2      0  \n",
       "\n",
       "[2000 rows x 37 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train= satimage6.head(4435)\n",
    "test= satimage6.tail(2000)\n",
    "train\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb0320e",
   "metadata": {},
   "source": [
    "# 1. Categorical Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1cfced",
   "metadata": {},
   "source": [
    "## 1.1 small Intervals from DT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1325e346",
   "metadata": {},
   "source": [
    "## 1.1 debug version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3a31e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "train= satimage6.head(4435)\n",
    "test= satimage6.tail(2000)\n",
    "X_train = train.drop('class', axis=1)\n",
    "y_train = train['class']\n",
    "X_test = test.drop('class', axis=1)\n",
    "y_test = test['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ced3d839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02794337272644043\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "cnb = CategoricalNB()\n",
    "cnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_cnb = cnb.predict(X_test)\n",
    "y_prob_pred_cnb = cnb.predict_proba(X_test)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start) # Total time execution for this sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e4a26e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoricalNB\n",
      "=========================\n",
      "Misclassified samples: 526\n",
      "Accuracy: 0.74\n",
      "=========================\n",
      "Recall score :  0.737\n",
      "Precision score :  0.737\n",
      "F1 score :  0.737\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.78      0.83       489\n",
      "           1       0.98      0.91      0.95       202\n",
      "           2       0.88      0.92      0.90       424\n",
      "           3       0.42      0.59      0.50       214\n",
      "           4       0.35      0.27      0.30       227\n",
      "           5       0.71      0.74      0.72       444\n",
      "\n",
      "    accuracy                           0.74      2000\n",
      "   macro avg       0.71      0.70      0.70      2000\n",
      "weighted avg       0.74      0.74      0.74      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# how did our model perform?\n",
    "count_misclassified = (y_test != y_pred_cnb).sum()\n",
    "print(\"CategoricalNB\")\n",
    "print(\"=\" * 25)\n",
    "print('Misclassified samples: {}'.format(count_misclassified))\n",
    "accuracy = accuracy_score(y_test, y_pred_cnb)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_cnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3844d1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.263\n",
      "Average bias: 0.263\n",
      "Average variance: 0.018\n",
      "Sklearn 0-1 loss: 0.263\n"
     ]
    }
   ],
   "source": [
    "# calculate classification bias and variance\n",
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#We will load the Boston house dataset for our example\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import metrics\n",
    "\n",
    "# y_pred_cnb\n",
    "# y_prob_pred_cnb\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        cnb, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_cnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a86152",
   "metadata": {},
   "source": [
    "## 1.1 script version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99b94bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoricalNB\n",
      "=========================\n",
      "Misclassified samples: 526\n",
      "Accuracy: 0.74\n",
      "=========================\n",
      "Recall score :  0.737\n",
      "Precision score :  0.737\n",
      "F1 score :  0.737\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.78      0.83       489\n",
      "           1       0.98      0.91      0.95       202\n",
      "           2       0.88      0.92      0.90       424\n",
      "           3       0.42      0.59      0.50       214\n",
      "           4       0.35      0.27      0.30       227\n",
      "           5       0.71      0.74      0.72       444\n",
      "\n",
      "    accuracy                           0.74      2000\n",
      "   macro avg       0.71      0.70      0.70      2000\n",
      "weighted avg       0.74      0.74      0.74      2000\n",
      "\n",
      "Computation time:\n",
      "0.029172420501708984\n"
     ]
    }
   ],
   "source": [
    "# make test & train split\n",
    "train= satimage6.head(4435)\n",
    "test= satimage6.tail(2000)\n",
    "X_train = train.drop('class', axis=1)\n",
    "y_train = train['class']\n",
    "X_test = test.drop('class', axis=1)\n",
    "y_test = test['class']\n",
    "\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "cnb = CategoricalNB()\n",
    "cnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_cnb = cnb.predict(X_test)\n",
    "y_prob_pred_cnb = cnb.predict_proba(X_test)\n",
    "\n",
    "# how did our model perform?\n",
    "count_misclassified = (y_test != y_pred_cnb).sum()\n",
    "print(\"CategoricalNB\")\n",
    "print(\"=\" * 25)\n",
    "print('Misclassified samples: {}'.format(count_misclassified))\n",
    "accuracy = accuracy_score(y_test, y_pred_cnb)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_cnb))\n",
    "\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82d4dfb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.263\n",
      "Average bias: 0.263\n",
      "Average variance: 0.018\n",
      "Sklearn 0-1 loss: 0.263\n"
     ]
    }
   ],
   "source": [
    "# calculate classification bias and variance\n",
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#We will load the Boston house dataset for our example\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import metrics\n",
    "\n",
    "# y_pred_cnb\n",
    "# y_prob_pred_cnb\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        cnb, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_cnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf64c978",
   "metadata": {},
   "source": [
    "## 1.2 medium Intervals from DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91a2a331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoricalNB\n",
      "=========================\n",
      "Misclassified samples: 352\n",
      "Accuracy: 0.82\n",
      "=========================\n",
      "Recall score :  0.824\n",
      "Precision score :  0.824\n",
      "F1 score :  0.824\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.84      0.87       489\n",
      "           1       0.98      0.91      0.95       202\n",
      "           2       0.89      0.93      0.91       424\n",
      "           3       0.54      0.65      0.59       214\n",
      "           4       0.65      0.76      0.70       227\n",
      "           5       0.89      0.79      0.83       444\n",
      "\n",
      "    accuracy                           0.82      2000\n",
      "   macro avg       0.81      0.81      0.81      2000\n",
      "weighted avg       0.84      0.82      0.83      2000\n",
      "\n",
      "Computation time:\n",
      "0.0462651252746582\n"
     ]
    }
   ],
   "source": [
    "# make test & train split\n",
    "train= satimage8.head(4435)\n",
    "test= satimage8.tail(2000)\n",
    "X_train = train.drop('class', axis=1)\n",
    "y_train = train['class']\n",
    "X_test = test.drop('class', axis=1)\n",
    "y_test = test['class']\n",
    "\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "cnb = CategoricalNB()\n",
    "cnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_cnb = cnb.predict(X_test)\n",
    "y_prob_pred_cnb = cnb.predict_proba(X_test)\n",
    "\n",
    "# how did our model perform?\n",
    "count_misclassified = (y_test != y_pred_cnb).sum()\n",
    "print(\"CategoricalNB\")\n",
    "print(\"=\" * 25)\n",
    "print('Misclassified samples: {}'.format(count_misclassified))\n",
    "accuracy = accuracy_score(y_test, y_pred_cnb)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_cnb))\n",
    "\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fed455dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.176\n",
      "Average bias: 0.176\n",
      "Average variance: 0.012\n",
      "Sklearn 0-1 loss: 0.176\n"
     ]
    }
   ],
   "source": [
    "# calculate classification bias and variance\n",
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#We will load the Boston house dataset for our example\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import metrics\n",
    "\n",
    "# y_pred_cnb\n",
    "# y_prob_pred_cnb\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        cnb, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_cnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd86461",
   "metadata": {},
   "source": [
    "## 1.3 large Intervals from DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3b9b6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoricalNB\n",
      "=========================\n",
      "Misclassified samples: 353\n",
      "Accuracy: 0.82\n",
      "=========================\n",
      "Recall score :  0.8235\n",
      "Precision score :  0.8235\n",
      "F1 score :  0.8235\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.82      0.87       489\n",
      "           1       0.98      0.91      0.95       202\n",
      "           2       0.88      0.92      0.90       424\n",
      "           3       0.55      0.70      0.62       214\n",
      "           4       0.65      0.77      0.70       227\n",
      "           5       0.88      0.78      0.83       444\n",
      "\n",
      "    accuracy                           0.82      2000\n",
      "   macro avg       0.81      0.82      0.81      2000\n",
      "weighted avg       0.84      0.82      0.83      2000\n",
      "\n",
      "Computation time:\n",
      "0.03098583221435547\n"
     ]
    }
   ],
   "source": [
    "train= satimage10.head(4435)\n",
    "test= satimage10.tail(2000)\n",
    "X_train = train.drop('class', axis=1)\n",
    "y_train = train['class']\n",
    "X_test = test.drop('class', axis=1)\n",
    "y_test = test['class']\n",
    "\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "cnb = CategoricalNB()\n",
    "cnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_cnb = cnb.predict(X_test)\n",
    "y_prob_pred_cnb = cnb.predict_proba(X_test)\n",
    "\n",
    "# how did our model perform?\n",
    "count_misclassified = (y_test != y_pred_cnb).sum()\n",
    "print(\"CategoricalNB\")\n",
    "print(\"=\" * 25)\n",
    "print('Misclassified samples: {}'.format(count_misclassified))\n",
    "accuracy = accuracy_score(y_test, y_pred_cnb)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_cnb))\n",
    "\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b77b8fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.176\n",
      "Average bias: 0.176\n",
      "Average variance: 0.012\n",
      "Sklearn 0-1 loss: 0.176\n"
     ]
    }
   ],
   "source": [
    "# calculate classification bias and variance\n",
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#We will load the Boston house dataset for our example\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import metrics\n",
    "\n",
    "# y_pred_cnb\n",
    "# y_prob_pred_cnb\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        cnb, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_cnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b03574",
   "metadata": {},
   "source": [
    "## 1.4 extra large Intervals from DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eac24eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoricalNB\n",
      "=========================\n",
      "Misclassified samples: 347\n",
      "Accuracy: 0.83\n",
      "=========================\n",
      "Recall score :  0.8265\n",
      "Precision score :  0.8265\n",
      "F1 score :  0.8265\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.83      0.88       489\n",
      "           1       0.99      0.92      0.95       202\n",
      "           2       0.88      0.93      0.90       424\n",
      "           3       0.55      0.70      0.61       214\n",
      "           4       0.67      0.76      0.71       227\n",
      "           5       0.88      0.78      0.83       444\n",
      "\n",
      "    accuracy                           0.83      2000\n",
      "   macro avg       0.81      0.82      0.81      2000\n",
      "weighted avg       0.84      0.83      0.83      2000\n",
      "\n",
      "0.02714395523071289\n"
     ]
    }
   ],
   "source": [
    "train= satimage15.head(4435)\n",
    "test= satimage15.tail(2000)\n",
    "X_train = train.drop('class', axis=1)\n",
    "y_train = train['class']\n",
    "X_test = test.drop('class', axis=1)\n",
    "y_test = test['class']\n",
    "\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "cnb = CategoricalNB()\n",
    "cnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_cnb = cnb.predict(X_test)\n",
    "y_prob_pred_cnb = cnb.predict_proba(X_test)\n",
    "\n",
    "# how did our model perform?\n",
    "count_misclassified = (y_test != y_pred_cnb).sum()\n",
    "print(\"CategoricalNB\")\n",
    "print(\"=\" * 25)\n",
    "print('Misclassified samples: {}'.format(count_misclassified))\n",
    "accuracy = accuracy_score(y_test, y_pred_cnb)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_cnb))\n",
    "\n",
    "end = time.time()\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c0b14728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.173\n",
      "Average bias: 0.172\n",
      "Average variance: 0.015\n",
      "Sklearn 0-1 loss: 0.173\n"
     ]
    }
   ],
   "source": [
    "# calculate classification bias and variance\n",
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#We will load the Boston house dataset for our example\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import metrics\n",
    "\n",
    "# y_pred_cnb\n",
    "# y_prob_pred_cnb\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        cnb, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_cnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36de93a1",
   "metadata": {},
   "source": [
    "# 2. Decision Tree ID3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5da502c",
   "metadata": {},
   "source": [
    "## 2.1 small Intervals from DT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cc6ec6",
   "metadata": {},
   "source": [
    "### Debug version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "efd2a195",
   "metadata": {},
   "outputs": [],
   "source": [
    "train= satimage6.head(4435)\n",
    "test= satimage6.tail(2000)\n",
    "X_train = train.drop('class', axis=1)\n",
    "y_train = train['class']\n",
    "X_test = test.drop('class', axis=1)\n",
    "y_test = test['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b0a2232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation time:\n",
      "1.148970603942871\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "estimator = Id3Estimator()\n",
    "estimator = estimator.fit(X_train, y_train, check_input=True)\n",
    "#tree = export_graphviz(estimator.tree_, 'tree.dot', y)\n",
    "\n",
    "y_pred_id3 = estimator.predict(X_test)\n",
    "#_prob_pred_id3 = estimator.predict_proba(X_test)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a3dc865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75\n",
      "=========================\n",
      "Recall score :  0.752\n",
      "Precision score :  0.752\n",
      "F1 score :  0.752\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85       489\n",
      "           1       0.95      0.94      0.94       202\n",
      "           2       0.87      0.89      0.88       424\n",
      "           3       0.48      0.45      0.47       214\n",
      "           4       0.44      0.38      0.41       227\n",
      "           5       0.71      0.75      0.73       444\n",
      "\n",
      "    accuracy                           0.75      2000\n",
      "   macro avg       0.72      0.71      0.71      2000\n",
      "weighted avg       0.75      0.75      0.75      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred_id3)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_id3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d1fb0308",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_70976/3993180029.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# y_prob_pred_cnb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'0-1_loss'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mlxtend\\evaluate\\bias_variance_decomp.py\u001b[0m in \u001b[0;36mbias_variance_decomp\u001b[1;34m(estimator, X_train, y_train, X_test, y_test, loss, num_rounds, random_seed, **fit_params)\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_boot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_boot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m         \u001b[0mall_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\id3\\id3.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, check_input)\u001b[0m\n\u001b[0;32m    152\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilder_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilder_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\id3\\tree.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, tree, X, y, X_test, y_test)\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         tree.root = self._build(tree, np.arange(self.n_samples),\n\u001b[0m\u001b[0;32m     64\u001b[0m                                 np.arange(self.n_features))\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprune\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\id3\\tree.py\u001b[0m in \u001b[0;36m_build\u001b[1;34m(self, tree, examples_idx, features_idx, depth)\u001b[0m\n\u001b[0;32m    101\u001b[0m                 \u001b[0mroot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_child\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m                 root.add_child(self._build(tree, record.bag,\n\u001b[0m\u001b[0;32m    104\u001b[0m                                features_idx, depth+1),\n\u001b[0;32m    105\u001b[0m                                record)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\id3\\tree.py\u001b[0m in \u001b[0;36m_build\u001b[1;34m(self, tree, examples_idx, features_idx, depth)\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m         \u001b[0mcalc_record\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexamples_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         if (calc_record is None\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\id3\\splitter.py\u001b[0m in \u001b[0;36mcalc\u001b[1;34m(self, examples_idx, features_idx)\u001b[0m\n\u001b[0;32m    251\u001b[0m             \u001b[0mtmp_calc_record\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_numerical\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures_idx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m                 \u001b[0mtmp_calc_record\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_numerical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m                 \u001b[0mtmp_calc_record\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_nominal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\id3\\splitter.py\u001b[0m in \u001b[0;36m_info_numerical\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msorted_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0msorted_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m                 \u001b[0mtmp_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msorted_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m                            \u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msorted_y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtmp_info\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mmin_info\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\id3\\splitter.py\u001b[0m in \u001b[0;36m_entropy\u001b[1;34m(self, y, return_class_counts)\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m         \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrue_divide\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\id3\\utils\\array_operations.py\u001b[0m in \u001b[0;36munique\u001b[1;34m(array)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"dtype\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mcounts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbincount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcounts\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mbincount\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# calculate classification bias and variance\n",
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#We will load the Boston house dataset for our example\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import metrics\n",
    "\n",
    "# y_pred_cnb\n",
    "# y_prob_pred_cnb\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        estimator, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b305a740",
   "metadata": {},
   "source": [
    "### script version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfce8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make splits\n",
    "train= satimage6.head(4435)\n",
    "test= satimage6.tail(2000)\n",
    "X_train = train.drop('class', axis=1)\n",
    "y_train = train['class']\n",
    "X_test = test.drop('class', axis=1)\n",
    "y_test = test['class']\n",
    "#time recording\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "#build estimator\n",
    "estimator = Id3Estimator()\n",
    "estimator = estimator.fit(X_train, y_train, check_input=True)\n",
    "#tree = export_graphviz(estimator.tree_, 'tree.dot', y)\n",
    "#make predictions\n",
    "y_pred_id3 = estimator.predict(X_test)\n",
    "#_prob_pred_id3 = estimator.predict_proba(X_test)\n",
    "#report performance\n",
    "accuracy = accuracy_score(y_test, y_pred_id3)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "#stop time recoridng\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2421a98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate classification bias and variance\n",
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#We will load the Boston house dataset for our example\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import metrics\n",
    "\n",
    "# y_pred_cnb\n",
    "# y_prob_pred_cnb\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        estimator, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c21b52",
   "metadata": {},
   "source": [
    "## 2.2 medium Intervals from DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011a2f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make splits\n",
    "train= satimage8.head(4435)\n",
    "test= satimage8.tail(2000)\n",
    "X_train = train.drop('class', axis=1)\n",
    "y_train = train['class']\n",
    "X_test = test.drop('class', axis=1)\n",
    "y_test = test['class']\n",
    "#time recording\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "#build estimator\n",
    "estimator = Id3Estimator()\n",
    "estimator = estimator.fit(X_train, y_train)\n",
    "#tree = export_graphviz(estimator.tree_, 'tree.dot', y)\n",
    "#make predictions\n",
    "y_pred_id3 = estimator.predict(X_test)\n",
    "#_prob_pred_id3 = estimator.predict_proba(X_test)\n",
    "#report performance\n",
    "accuracy = accuracy_score(y_test, y_pred_id3)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "#stop time recoridng\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d626911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate classification bias and variance\n",
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#We will load the Boston house dataset for our example\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import metrics\n",
    "\n",
    "# y_pred_cnb\n",
    "# y_prob_pred_cnb\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        estimator, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687f1ea3",
   "metadata": {},
   "source": [
    "## 2.3 large Intervals from DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82063c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make splits\n",
    "train= satimage10.head(4435)\n",
    "test= satimage10.tail(2000)\n",
    "X_train = train.drop('class', axis=1)\n",
    "y_train = train['class']\n",
    "X_test = test.drop('class', axis=1)\n",
    "y_test = test['class']\n",
    "#time recording\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "#build estimator\n",
    "estimator = Id3Estimator()\n",
    "estimator = estimator.fit(X_train, y_train, check_input=True)\n",
    "#tree = export_graphviz(estimator.tree_, 'tree.dot', y)\n",
    "#make predictions\n",
    "y_pred_id3 = estimator.predict(X_test)\n",
    "#_prob_pred_id3 = estimator.predict_proba(X_test)\n",
    "#report performance\n",
    "accuracy = accuracy_score(y_test, y_pred_id3)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "#stop time recoridng\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457f91d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate classification bias and variance\n",
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#We will load the Boston house dataset for our example\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import metrics\n",
    "\n",
    "# y_pred_cnb\n",
    "# y_prob_pred_cnb\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        estimator, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251b1503",
   "metadata": {},
   "source": [
    "## 2.4 extra large Intervals from DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9907debd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make splits\n",
    "train= satimage15.head(4435)\n",
    "test= satimage15.tail(2000)\n",
    "X_train = train.drop('class', axis=1)\n",
    "y_train = train['class']\n",
    "X_test = test.drop('class', axis=1)\n",
    "y_test = test['class']\n",
    "#time recording\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "#build estimator\n",
    "estimator = Id3Estimator()\n",
    "estimator = estimator.fit(X_train, y_train, check_input=True)\n",
    "#tree = export_graphviz(estimator.tree_, 'tree.dot', y)\n",
    "#make predictions\n",
    "y_pred_id3 = estimator.predict(X_test)\n",
    "#_prob_pred_id3 = estimator.predict_proba(X_test)\n",
    "#report performance\n",
    "accuracy = accuracy_score(y_test, y_pred_id3)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "#stop time recoridng\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23fced9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate classification bias and variance\n",
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#We will load the Boston house dataset for our example\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import metrics\n",
    "\n",
    "# y_pred_cnb\n",
    "# y_prob_pred_cnb\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        estimator, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9d5f3d",
   "metadata": {},
   "source": [
    "# 3. KNN classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35401cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data from ChiMerge discretization\n",
    "satimage6 = pd.read_csv('ChiM_discretized_6Intervals_satimage.csv')\n",
    "satimage8 = pd.read_csv('ChiM_discretized_8Intervals_satimage.csv')\n",
    "satimage10 = pd.read_csv('ChiM_discretized_10Intervals_satimage.csv')\n",
    "satimage15 = pd.read_csv('ChiM_discretized_15Intervals_satimage.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6145e2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Complete code for data preperation\n",
    "# # Read data\n",
    "# #df_ewd1 = satimage6\n",
    "# disc = 'EWD'\n",
    "# k = 4\n",
    "\n",
    "# # df_ewd1.info()\n",
    "# # data = df_ewd1.values\n",
    "# # data.shape\n",
    "\n",
    "# # train= satimage6.head(4435)\n",
    "# # test= satimage6.tail(2000)\n",
    "\n",
    "# train= satimage6.head(3000)\n",
    "# test= satimage6.tail(1000)\n",
    "\n",
    "# data_train = train.values\n",
    "# data_train.shape\n",
    "# data_test = test.values\n",
    "# data_test.shape\n",
    "# features = satimage6.drop('class', axis = 1).columns\n",
    "\n",
    "\n",
    "# # separate the data into X and y\n",
    "# x_train = data_train[:, : len(features)]\n",
    "# y_train = data_train[:,-1]\n",
    "# x_test = data_test[:, : len(features)]\n",
    "# y_test = data_test[:,-1]\n",
    "\n",
    "# #print(X.shape, Y.shape)\n",
    "\n",
    "# # Split train test\n",
    "# #x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 30) \n",
    "\n",
    "# # Check representation of class\n",
    "# #print('Class representation - original: ', Counter(Y)) \n",
    "# print('Class representation - training data: ', Counter(y_train)) \n",
    "# print('Class representation - testing data: ', Counter(y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe593f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Knn-VDM complete code\n",
    "# import time\n",
    "# start = time.time() # For measuring time execution\n",
    "\n",
    "# # specific the continuous columns index if any\n",
    "# vdm = ValueDifferenceMetric(x_train, y_train, continuous = None)\n",
    "# vdm.fit()\n",
    "# # Knn model, n_neigbour = 3, metrics = vdm\n",
    "# knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "# # Fit model\n",
    "# knn_vdm.fit(x_train, y_train)\n",
    "# # Testing\n",
    "# y_pred_knn = knn_vdm.predict(x_test)\n",
    "# knn_vdm.classes_\n",
    "# print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "# end = time.time()\n",
    "# print(f'Time for training model Knn-VDM: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e68e4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "#         knn_vdm, x_train, y_train, x_test, y_test, \n",
    "#         loss='0-1_loss',\n",
    "#         random_seed=123)\n",
    "\n",
    "# print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "# print('Average bias: %.3f' % avg_bias)\n",
    "# print('Average variance: %.3f' % avg_var)\n",
    "# print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55006f71",
   "metadata": {},
   "source": [
    "## 3.1 KNN with DT small intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d96ac85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class representation - training data:  Counter({5: 137, 2: 111, 0: 108, 1: 53, 3: 46, 4: 45})\n",
      "Class representation - testing data:  Counter({2: 25, 0: 22, 1: 16, 5: 16, 3: 13, 4: 8})\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "#df_ewd1 = satimage6\n",
    "disc = 'EWD'\n",
    "k = 4\n",
    "\n",
    "# df_ewd1.info()\n",
    "# data = df_ewd1.values\n",
    "# data.shape\n",
    "\n",
    "# train= satimage6.head(4435)\n",
    "# test= satimage6.tail(2000)\n",
    "\n",
    "train= satimage6.head(500)\n",
    "test= satimage6.tail(100)\n",
    "\n",
    "data_train = train.values\n",
    "data_train.shape\n",
    "data_test = test.values\n",
    "data_test.shape\n",
    "features = satimage6.drop('class', axis = 1).columns\n",
    "\n",
    "\n",
    "# separate the data into X and y\n",
    "x_train = data_train[:, : len(features)]\n",
    "y_train = data_train[:,-1]\n",
    "x_test = data_test[:, : len(features)]\n",
    "y_test = data_test[:,-1]\n",
    "\n",
    "#print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "#x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 30) \n",
    "\n",
    "# Check representation of class\n",
    "#print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9e112dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "for i in satimage6.columns:\n",
    "    #print('Interval numbers for '+i)\n",
    "    print(len(Counter(train[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9946e8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "for i in train.columns:\n",
    "    #print('Interval numbers for '+i)\n",
    "    print(len(Counter(train[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4a55fc91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "for i in test.columns:\n",
    "    #print('Interval numbers for '+i)\n",
    "    print(len(Counter(train[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "930a188d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.95      0.86        22\n",
      "           1       1.00      0.69      0.81        16\n",
      "           2       0.80      0.96      0.87        25\n",
      "           3       0.60      0.23      0.33        13\n",
      "           4       1.00      0.38      0.55         8\n",
      "           5       0.62      0.94      0.75        16\n",
      "\n",
      "    accuracy                           0.77       100\n",
      "   macro avg       0.80      0.69      0.70       100\n",
      "weighted avg       0.79      0.77      0.74       100\n",
      "\n",
      "Time for training model Knn-VDM: 88.16726541519165.\n"
     ]
    }
   ],
   "source": [
    "# Knn-VDM complete code\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(x_train, y_train, continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "# Fit model\n",
    "knn_vdm.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(x_test)\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6cb4fba4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_70976/2301922218.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n\u001b[0m\u001b[0;32m      2\u001b[0m         \u001b[0mknn_vdm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'0-1_loss'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         random_seed=123)\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mlxtend\\evaluate\\bias_variance_decomp.py\u001b[0m in \u001b[0;36mbias_variance_decomp\u001b[1;34m(estimator, X_train, y_train, X_test, y_test, loss, num_rounds, random_seed, **fit_params)\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_boot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_boot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m         \u001b[0mall_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    217\u001b[0m             \u001b[1;31m# In that case, we do not need the distances to perform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m             \u001b[1;31m# the weighting so we do not compute them.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 219\u001b[1;33m             \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    220\u001b[0m             \u001b[0mneigh_dist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    794\u001b[0m                 \u001b[0mkwds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meffective_metric_params_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 796\u001b[1;33m             chunked_results = list(\n\u001b[0m\u001b[0;32m    797\u001b[0m                 pairwise_distances_chunked(\n\u001b[0;32m    798\u001b[0m                     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   1815\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1816\u001b[0m             \u001b[0mX_chunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msl\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1817\u001b[1;33m         \u001b[0mD_chunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpairwise_distances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_chunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1818\u001b[0m         if (X is Y or Y is None) and PAIRWISE_DISTANCE_FUNCTIONS.get(\n\u001b[0;32m   1819\u001b[0m             \u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[1;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   1987\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1988\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1989\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1990\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1529\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1530\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1532\u001b[0m     \u001b[1;31m# enforce a threading backend to prevent data communication overhead\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36m_pairwise_callable\u001b[1;34m(X, Y, metric, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   1572\u001b[0m         \u001b[0miterator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1573\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1574\u001b[1;33m             \u001b[0mout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1575\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1576\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\vdm3\\vdm.py\u001b[0m in \u001b[0;36mget_distance\u001b[1;34m(self, ins_1, ins_2, norm)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mDimensionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Dimension of ins_1 != Dimension of ins_2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m         \u001b[0mins_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[0mins_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        knn_vdm, x_train, y_train, x_test, y_test, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0074f7e6",
   "metadata": {},
   "source": [
    "## 3.2 KNN with DT medium intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d6b5aaea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class representation - training data:  Counter({5: 137, 2: 111, 0: 108, 1: 53, 3: 46, 4: 45})\n",
      "Class representation - testing data:  Counter({2: 25, 0: 22, 1: 16, 5: 16, 3: 13, 4: 8})\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "#df_ewd1 = satimage6\n",
    "disc = 'EWD'\n",
    "k = 4\n",
    "\n",
    "# df_ewd1.info()\n",
    "# data = df_ewd1.values\n",
    "# data.shape\n",
    "\n",
    "# train= satimage6.head(4435)\n",
    "# test= satimage6.tail(2000)\n",
    "\n",
    "train= satimage6.head(500)\n",
    "test= satimage6.tail(100)\n",
    "\n",
    "data_train = train.values\n",
    "data_train.shape\n",
    "data_test = test.values\n",
    "data_test.shape\n",
    "features = satimage6.drop('class', axis = 1).columns\n",
    "\n",
    "\n",
    "# separate the data into X and y\n",
    "x_train = data_train[:, : len(features)]\n",
    "y_train = data_train[:,-1]\n",
    "x_test = data_test[:, : len(features)]\n",
    "y_test = data_test[:,-1]\n",
    "\n",
    "#print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "#x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 30) \n",
    "\n",
    "# Check representation of class\n",
    "#print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bc402fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.95      0.86        22\n",
      "           1       1.00      0.69      0.81        16\n",
      "           2       0.80      0.96      0.87        25\n",
      "           3       0.60      0.23      0.33        13\n",
      "           4       1.00      0.38      0.55         8\n",
      "           5       0.62      0.94      0.75        16\n",
      "\n",
      "    accuracy                           0.77       100\n",
      "   macro avg       0.80      0.69      0.70       100\n",
      "weighted avg       0.79      0.77      0.74       100\n",
      "\n",
      "Time for training model Knn-VDM: 92.01916193962097.\n"
     ]
    }
   ],
   "source": [
    "# Knn-VDM complete code\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(x_train, y_train, continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "# Fit model\n",
    "knn_vdm.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(x_test)\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1c392d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "#         knn_vdm, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "#         loss='0-1_loss',\n",
    "#         random_seed=123)\n",
    "\n",
    "# print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "# print('Average bias: %.3f' % avg_bias)\n",
    "# print('Average variance: %.3f' % avg_var)\n",
    "# print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a527ed9",
   "metadata": {},
   "source": [
    "## 3.3 KNN with DT large intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5fba69b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class representation - training data:  Counter({5: 260, 2: 221, 0: 214, 1: 109, 4: 106, 3: 90})\n",
      "Class representation - testing data:  Counter({0: 132, 2: 115, 5: 112, 1: 49, 4: 46, 3: 46})\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "#df_ewd1 = satimage6\n",
    "disc = 'EWD'\n",
    "k = 4\n",
    "\n",
    "# df_ewd1.info()\n",
    "# data = df_ewd1.values\n",
    "# data.shape\n",
    "\n",
    "# train= satimage6.head(4435)\n",
    "# test= satimage6.tail(2000)\n",
    "\n",
    "train= satimage10.head(1000)\n",
    "test= satimage10.tail(500)\n",
    "\n",
    "data_train = train.values\n",
    "data_train.shape\n",
    "data_test = test.values\n",
    "data_test.shape\n",
    "features = satimage6.drop('class', axis = 1).columns\n",
    "\n",
    "\n",
    "# separate the data into X and y\n",
    "x_train = data_train[:, : len(features)]\n",
    "y_train = data_train[:,-1]\n",
    "x_test = data_test[:, : len(features)]\n",
    "y_test = data_test[:,-1]\n",
    "\n",
    "#print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "#x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 30) \n",
    "\n",
    "# Check representation of class\n",
    "#print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "25cef1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95       132\n",
      "           1       0.96      0.96      0.96        49\n",
      "           2       0.84      0.90      0.87       115\n",
      "           3       0.51      0.48      0.49        46\n",
      "           4       0.76      0.57      0.65        46\n",
      "           5       0.83      0.81      0.82       112\n",
      "\n",
      "    accuracy                           0.84       500\n",
      "   macro avg       0.80      0.78      0.79       500\n",
      "weighted avg       0.83      0.84      0.83       500\n",
      "\n",
      "Time for training model Knn-VDM: 948.4903318881989.\n"
     ]
    }
   ],
   "source": [
    "# Knn-VDM complete code\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(x_train, y_train, continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "# Fit model\n",
    "knn_vdm.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(x_test)\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f534d316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "#         knn_vdm, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "#         loss='0-1_loss',\n",
    "#         random_seed=123)\n",
    "\n",
    "# print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "# print('Average bias: %.3f' % avg_bias)\n",
    "# print('Average variance: %.3f' % avg_var)\n",
    "# print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb00a1f6",
   "metadata": {},
   "source": [
    "## 3.4 KNN with DT extra large intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "572a96f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class representation - training data:  Counter({5: 260, 2: 221, 0: 214, 1: 109, 4: 106, 3: 90})\n",
      "Class representation - testing data:  Counter({0: 132, 2: 115, 5: 112, 1: 49, 4: 46, 3: 46})\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "#df_ewd1 = satimage6\n",
    "disc = 'EWD'\n",
    "k = 4\n",
    "\n",
    "# df_ewd1.info()\n",
    "# data = df_ewd1.values\n",
    "# data.shape\n",
    "\n",
    "# train= satimage6.head(4435)\n",
    "# test= satimage6.tail(2000)\n",
    "\n",
    "train= satimage10.head(1000)\n",
    "test= satimage10.tail(500)\n",
    "\n",
    "data_train = train.values\n",
    "data_train.shape\n",
    "data_test = test.values\n",
    "data_test.shape\n",
    "features = satimage6.drop('class', axis = 1).columns\n",
    "\n",
    "\n",
    "# separate the data into X and y\n",
    "x_train = data_train[:, : len(features)]\n",
    "y_train = data_train[:,-1]\n",
    "x_test = data_test[:, : len(features)]\n",
    "y_test = data_test[:,-1]\n",
    "\n",
    "#print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "#x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 30) \n",
    "\n",
    "# Check representation of class\n",
    "#print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7ae25db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95       132\n",
      "           1       0.96      0.96      0.96        49\n",
      "           2       0.84      0.90      0.87       115\n",
      "           3       0.51      0.48      0.49        46\n",
      "           4       0.76      0.57      0.65        46\n",
      "           5       0.83      0.81      0.82       112\n",
      "\n",
      "    accuracy                           0.84       500\n",
      "   macro avg       0.80      0.78      0.79       500\n",
      "weighted avg       0.83      0.84      0.83       500\n",
      "\n",
      "Time for training model Knn-VDM: 1114.753978252411.\n"
     ]
    }
   ],
   "source": [
    "# Knn-VDM complete code\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(x_train, y_train, continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "# Fit model\n",
    "knn_vdm.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(x_test)\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed7255be",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bias_variance_decomp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_88096/2429275371.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n\u001b[0m\u001b[0;32m      2\u001b[0m         \u001b[0mknn_vdm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'0-1_loss'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         random_seed=123)\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'bias_variance_decomp' is not defined"
     ]
    }
   ],
   "source": [
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        knn_vdm, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
