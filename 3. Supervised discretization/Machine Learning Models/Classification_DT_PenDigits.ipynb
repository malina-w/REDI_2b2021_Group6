{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abd2336c",
   "metadata": {},
   "source": [
    "# ML Experiments using different bin sizes & widths based on outputs from supervised discretization using DT discretizer\n",
    "## Dataset: Pen Digits\n",
    "\n",
    "by: Malina & Sam , 03.07.2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "83bc40c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score, recall_score, precision_score\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "import six\n",
    "import sys\n",
    "sys.modules['sklearn.externals.six'] = six\n",
    "import id3\n",
    "from id3 import Id3Estimator\n",
    "from id3 import export_graphviz\n",
    "import wittgenstein as lw\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# calculate classification bias and variance\n",
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#We will load the Boston house dataset for our example\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import metrics\n",
    "\n",
    "## EDA\n",
    "from collections import Counter\n",
    "\n",
    "# Knn-VDM 3\n",
    "from vdm3 import ValueDifferenceMetric\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Pre-processing\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "# Cross validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score # 1 metric\n",
    "from sklearn.model_selection import cross_validate # more than 1 metric\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "50eb04fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data from ChiMerge discretization\n",
    "pen6 = pd.read_csv('DT_small_discretized_pen.csv')\n",
    "pen8 = pd.read_csv('DT_medium_discretized_pen.csv')\n",
    "pen10 = pd.read_csv('DT_large_discretized_pen.csv')\n",
    "pen15 = pd.read_csv('DT_verylarge_discretized_pen.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d489dc73",
   "metadata": {},
   "source": [
    "## Counting interval frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c98900ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_list6 = pen6.columns.drop('class')\n",
    "num_list8 = pen8.columns.drop('class')\n",
    "num_list10 = pen10.columns.drop('class')\n",
    "num_list15 = pen15.columns.drop('class')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b9bbb38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interval frequency for 6 Intervals\n",
      "Interval for A1\n",
      "Counter({2: 5567, 3: 2364, 0: 1918, 1: 1143})\n",
      "Interval for A2\n",
      "Counter({1: 5893, 0: 3115, 2: 1984})\n",
      "Interval for A3\n",
      "Counter({3: 7458, 0: 1954, 1: 1043, 2: 537})\n",
      "Interval for A4\n",
      "Counter({0: 4387, 3: 3489, 2: 2431, 1: 685})\n",
      "Interval for A5\n",
      "Counter({3: 3875, 2: 2950, 1: 2599, 0: 1568})\n",
      "Interval for A6\n",
      "Counter({3: 5007, 1: 2814, 2: 1630, 0: 1541})\n",
      "Interval for A7\n",
      "Counter({2: 7815, 1: 1201, 0: 1026, 3: 950})\n",
      "Interval for A8\n",
      "Counter({2: 4412, 1: 4404, 0: 2176})\n",
      "Interval for A9\n",
      "Counter({3: 3518, 2: 3098, 0: 2528, 1: 1848})\n",
      "Interval for A10\n",
      "Counter({2: 3335, 1: 2973, 3: 2445, 0: 2239})\n",
      "Interval for A11\n",
      "Counter({0: 3760, 1: 3397, 2: 2914, 3: 921})\n",
      "Interval for A12\n",
      "Counter({3: 3831, 1: 3643, 2: 2134, 0: 1384})\n",
      "Interval for A13\n",
      "Counter({1: 6621, 2: 2217, 3: 1645, 0: 509})\n",
      "Interval for A14\n",
      "Counter({2: 4696, 1: 3725, 0: 2571})\n",
      "Interval for A15\n",
      "Counter({0: 4887, 2: 3056, 1: 2988, 3: 61})\n",
      "Interval for A16\n",
      "Counter({2: 6484, 0: 2736, 1: 1772})\n"
     ]
    }
   ],
   "source": [
    "print('Interval frequency for small Intervals')\n",
    "for i in num_list6:\n",
    "    print('Interval for ' + i)\n",
    "    print(Counter(pen6[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "12e6e7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency for iris with 8 Intervals\n",
      "Interval for A1\n",
      "Counter({4: 3634, 5: 2364, 2: 1933, 3: 1143, 1: 975, 0: 943})\n",
      "Interval for A2\n",
      "Counter({2: 3334, 1: 3115, 0: 2559, 3: 1070, 4: 914})\n",
      "Interval for A3\n",
      "Counter({4: 4246, 7: 3212, 1: 1105, 3: 930, 0: 849, 6: 373, 5: 164, 2: 113})\n",
      "Interval for A4\n",
      "Counter({0: 4387, 6: 2481, 5: 1993, 4: 1008, 2: 451, 1: 438, 3: 234})\n",
      "Interval for A5\n",
      "Counter({6: 2723, 2: 1897, 0: 1568, 5: 1513, 4: 1437, 3: 1152, 1: 702})\n",
      "Interval for A6\n",
      "Counter({4: 3892, 0: 2567, 1: 1788, 5: 1115, 2: 896, 3: 734})\n",
      "Interval for A7\n",
      "Counter({5: 5073, 4: 2742, 2: 1000, 1: 988, 7: 899, 3: 201, 6: 51, 0: 38})\n",
      "Interval for A8\n",
      "Counter({2: 2912, 3: 2659, 0: 2176, 4: 1753, 1: 1492})\n",
      "Interval for A9\n",
      "Counter({5: 1973, 0: 1886, 7: 1805, 2: 1764, 6: 1713, 4: 1125, 3: 642, 1: 84})\n",
      "Interval for A10\n",
      "Counter({2: 2458, 0: 2239, 4: 2205, 6: 1229, 5: 1216, 3: 1130, 1: 515})\n",
      "Interval for A11\n",
      "Counter({3: 2656, 0: 2482, 4: 1823, 1: 1278, 7: 1091, 2: 741, 5: 593, 6: 328})\n",
      "Interval for A12\n",
      "Counter({2: 2379, 7: 2154, 4: 1677, 3: 1264, 6: 1227, 1: 1043, 5: 907, 0: 341})\n",
      "Interval for A13\n",
      "Counter({3: 4162, 2: 2459, 1: 1289, 4: 928, 5: 877, 6: 768, 0: 509})\n",
      "Interval for A14\n",
      "Counter({1: 3009, 0: 2571, 3: 1969, 2: 1756, 4: 1687})\n",
      "Interval for A15\n",
      "Counter({3: 2988, 0: 2917, 4: 2116, 1: 1970, 5: 940, 2: 39, 6: 22})\n",
      "Interval for A16\n",
      "Counter({3: 4044, 0: 3952, 2: 2440, 1: 556})\n"
     ]
    }
   ],
   "source": [
    "print('Frequency for pen with medium Intervals')\n",
    "for i in num_list8:\n",
    "    print('Interval for ' + i)\n",
    "    print(Counter(pen8[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8464588e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency for iris with 10 Intervals\n",
      "Interval for A1\n",
      "Counter({7: 2439, 9: 2364, 8: 1195, 6: 1143, 5: 1042, 4: 891, 2: 570, 1: 515, 3: 460, 0: 373})\n",
      "Interval for A2\n",
      "Counter({3: 3115, 2: 2022, 1: 1560, 5: 1312, 0: 999, 8: 887, 6: 706, 7: 364, 4: 27})\n",
      "Interval for A3\n",
      "Counter({7: 2858, 12: 1631, 13: 1581, 8: 1388, 3: 953, 5: 687, 2: 687, 10: 350, 6: 243, 0: 175, 1: 162, 9: 143, 4: 113, 11: 21})\n",
      "Interval for A4\n",
      "Counter({1: 4387, 12: 1690, 11: 1214, 8: 791, 10: 779, 7: 743, 4: 315, 2: 272, 9: 265, 0: 166, 5: 136, 3: 126, 6: 108})\n",
      "Interval for A5\n",
      "Counter({12: 2037, 1: 1568, 3: 1206, 9: 1155, 7: 759, 11: 754, 4: 691, 10: 686, 6: 614, 8: 538, 2: 479, 5: 282, 0: 223})\n",
      "Interval for A6\n",
      "Counter({8: 2920, 0: 2567, 1: 1193, 9: 1115, 7: 972, 2: 595, 4: 506, 3: 390, 6: 380, 5: 354})\n",
      "Interval for A7\n",
      "Counter({8: 4082, 7: 2418, 9: 991, 1: 988, 11: 899, 4: 640, 2: 360, 5: 324, 3: 139, 6: 62, 10: 51, 0: 38})\n",
      "Interval for A8\n",
      "Counter({0: 2176, 3: 2073, 6: 1590, 5: 1069, 7: 939, 4: 839, 8: 814, 2: 810, 1: 682})\n",
      "Interval for A9\n",
      "Counter({3: 1764, 10: 1608, 0: 1400, 9: 958, 11: 948, 13: 857, 12: 755, 8: 654, 1: 486, 6: 478, 7: 471, 5: 365, 4: 164, 2: 84})\n",
      "Interval for A10\n",
      "Counter({1: 2239, 5: 1730, 7: 1442, 6: 1023, 8: 763, 11: 733, 2: 728, 10: 625, 9: 591, 12: 496, 3: 271, 4: 244, 0: 107})\n",
      "Interval for A11\n",
      "Counter({1: 2482, 4: 1356, 10: 1300, 2: 1065, 9: 979, 13: 878, 5: 844, 3: 525, 8: 382, 7: 216, 0: 213, 11: 213, 14: 211, 12: 200, 6: 128})\n",
      "Interval for A12\n",
      "Counter({11: 1553, 6: 1467, 3: 1451, 10: 1227, 5: 928, 4: 633, 9: 631, 13: 601, 2: 576, 8: 510, 1: 467, 12: 397, 0: 341, 7: 210})\n",
      "Interval for A13\n",
      "Counter({3: 2853, 5: 2017, 8: 1309, 4: 1162, 7: 654, 11: 541, 0: 509, 10: 508, 2: 442, 6: 369, 9: 274, 12: 227, 1: 127})\n",
      "Interval for A14\n",
      "Counter({0: 2571, 3: 1848, 4: 1780, 2: 1756, 7: 1326, 1: 1161, 5: 361, 6: 189})\n",
      "Interval for A15\n",
      "Counter({5: 2988, 0: 2917, 8: 1651, 1: 1328, 2: 642, 6: 543, 3: 465, 7: 397, 4: 39, 9: 22})\n",
      "Interval for A16\n",
      "Counter({0: 4143, 4: 4044, 3: 1223, 2: 1217, 1: 365})\n"
     ]
    }
   ],
   "source": [
    "print('Frequency for pen with large Intervals')\n",
    "for i in num_list10:\n",
    "    print('Interval for ' + i)\n",
    "    print(Counter(pen10[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1584fcda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency for iris with 15 Intervals\n",
      "Interval for A1\n",
      "Counter({15: 2364, 13: 1881, 11: 1143, 14: 1051, 8: 957, 7: 630, 12: 558, 4: 528, 2: 404, 5: 398, 1: 341, 6: 261, 0: 159, 9: 144, 3: 111, 10: 62})\n",
      "Interval for A2\n",
      "Counter({5: 3115, 3: 1388, 6: 1070, 4: 952, 7: 875, 10: 592, 15: 573, 2: 505, 1: 494, 9: 437, 14: 314, 13: 198, 0: 172, 12: 166, 11: 114, 8: 27})\n",
      "Interval for A3\n",
      "Counter({8: 1679, 16: 1179, 12: 1031, 4: 953, 20: 869, 19: 792, 21: 789, 15: 762, 10: 526, 3: 398, 9: 357, 17: 309, 2: 289, 0: 242, 14: 163, 5: 161, 6: 124, 7: 113, 13: 99, 1: 95, 11: 41, 18: 21})\n",
      "Interval for A4\n",
      "Counter({3: 4387, 21: 1180, 19: 1000, 10: 583, 18: 528, 20: 510, 15: 454, 7: 337, 14: 251, 2: 241, 8: 214, 1: 162, 17: 160, 11: 153, 6: 136, 12: 135, 16: 130, 4: 126, 9: 108, 5: 90, 0: 76, 13: 31})\n",
      "Interval for A5\n",
      "Counter({1: 1568, 12: 1155, 20: 1069, 18: 968, 2: 712, 10: 697, 14: 588, 6: 524, 5: 500, 4: 494, 0: 466, 19: 383, 17: 371, 3: 279, 11: 278, 13: 260, 7: 239, 8: 191, 9: 98, 16: 90, 15: 62})\n",
      "Interval for A6\n",
      "Counter({0: 2567, 14: 1528, 15: 1392, 17: 1115, 13: 835, 2: 650, 1: 543, 3: 479, 7: 343, 6: 283, 10: 200, 11: 180, 8: 178, 12: 176, 5: 163, 16: 137, 9: 116, 4: 107})\n",
      "Interval for A7\n",
      "Counter({10: 2492, 12: 1590, 9: 1403, 11: 1015, 1: 988, 16: 899, 2: 527, 13: 524, 14: 467, 0: 350, 4: 257, 3: 118, 7: 113, 5: 69, 8: 67, 6: 62, 15: 51})\n",
      "Interval for A8\n",
      "Counter({0: 2437, 5: 1245, 12: 933, 13: 848, 4: 828, 10: 793, 15: 728, 7: 657, 6: 483, 3: 438, 1: 421, 2: 372, 8: 356, 9: 276, 11: 91, 14: 86})\n",
      "Interval for A9\n",
      "Counter({8: 1764, 18: 1122, 0: 1028, 24: 665, 13: 573, 15: 486, 21: 486, 22: 478, 17: 470, 23: 432, 25: 425, 10: 423, 14: 388, 19: 385, 1: 372, 9: 302, 4: 247, 2: 239, 16: 168, 11: 91, 20: 90, 3: 84, 12: 83, 5: 73, 7: 63, 6: 55})\n",
      "Interval for A10\n",
      "Counter({4: 2239, 14: 1193, 13: 791, 10: 733, 12: 709, 15: 684, 20: 664, 3: 537, 18: 456, 5: 409, 16: 343, 6: 319, 23: 318, 19: 248, 9: 232, 7: 180, 21: 178, 17: 169, 2: 159, 0: 107, 1: 91, 11: 85, 8: 79, 22: 69})\n",
      "Interval for A11\n",
      "Counter({1: 2482, 19: 1300, 3: 951, 5: 874, 13: 720, 16: 674, 11: 482, 23: 477, 24: 401, 6: 368, 14: 340, 15: 305, 21: 165, 20: 165, 7: 157, 22: 149, 8: 124, 18: 121, 4: 114, 2: 112, 0: 101, 10: 95, 12: 86, 17: 84, 25: 62, 9: 48, 26: 35})\n",
      "Interval for A12\n",
      "Counter({18: 1227, 3: 1115, 10: 1024, 21: 898, 7: 774, 14: 655, 0: 613, 1: 525, 15: 443, 13: 384, 17: 382, 23: 359, 4: 358, 5: 336, 6: 275, 9: 249, 19: 248, 2: 246, 22: 242, 11: 154, 20: 149, 12: 126, 8: 107, 16: 103})\n",
      "Interval for A13\n",
      "Counter({5: 1747, 6: 1319, 7: 1106, 8: 784, 16: 741, 11: 698, 10: 568, 1: 509, 9: 383, 3: 378, 21: 291, 19: 290, 18: 271, 22: 250, 4: 250, 20: 218, 12: 197, 13: 192, 24: 186, 15: 181, 14: 172, 2: 108, 17: 93, 23: 41, 0: 19})\n",
      "Interval for A14\n",
      "Counter({0: 2932, 3: 1756, 4: 1346, 7: 1001, 8: 833, 1: 800, 5: 779, 2: 502, 12: 493, 6: 272, 9: 100, 11: 89, 10: 89})\n",
      "Interval for A15\n",
      "Counter({8: 2988, 1: 2917, 12: 1426, 3: 834, 2: 494, 5: 431, 4: 423, 7: 390, 11: 327, 9: 225, 0: 211, 14: 153, 10: 70, 13: 42, 6: 39, 15: 22})\n",
      "Interval for A16\n",
      "Counter({0: 4199, 6: 4044, 3: 739, 5: 636, 4: 587, 2: 478, 1: 309})\n"
     ]
    }
   ],
   "source": [
    "print('Frequency for pen with extra large Intervals')\n",
    "for i in num_list15:\n",
    "    print('Interval for ' + i)\n",
    "    print(Counter(pen15[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ca83f36b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>A16</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10987</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10988</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10989</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10990</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10991</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10992 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       A1  A2  A3  A4  A5  A6  A7  A8  A9  A10  A11  A12  A13  A14  A15  A16  \\\n",
       "0       1   0   7   4   0   0   2   0   6    4    1    7    0    0    4    0   \n",
       "1       1   1   3   4   0   0   4   0   7    4    0    4    1    0    1    0   \n",
       "2       3   1   4   6   6   3   5   3   5    2    3    3    6    3    0    3   \n",
       "3       4   2   4   0   6   1   4   1   0    0    3    3    3    4    3    2   \n",
       "4       2   1   1   6   1   1   5   3   6    5    0    7    1    3    1    3   \n",
       "...    ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...  ...  ...  ...  ...  ...   \n",
       "10987   4   2   6   6   4   5   2   4   0    1    1    4    1    1    4    3   \n",
       "10988   2   0   3   6   3   2   5   4   7    5    0    3    3    2    0    2   \n",
       "10989   5   0   4   0   4   4   5   2   6    0    2    2    2    1    3    0   \n",
       "10990   3   2   4   0   6   4   6   4   7    5    7    7    2    3    0    3   \n",
       "10991   2   0   4   0   6   2   5   3   2    2    4    2    5    2    0    1   \n",
       "\n",
       "       class  \n",
       "0          0  \n",
       "1          0  \n",
       "2          1  \n",
       "3          2  \n",
       "4          9  \n",
       "...      ...  \n",
       "10987      9  \n",
       "10988      9  \n",
       "10989      7  \n",
       "10990      9  \n",
       "10991      3  \n",
       "\n",
       "[10992 rows x 17 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pen8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb0320e",
   "metadata": {},
   "source": [
    "# 1. Categorical Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1cfced",
   "metadata": {},
   "source": [
    "## 1.1 small Intervals from DT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1325e346",
   "metadata": {},
   "source": [
    "## 1.1 debug version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "219958cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataX = pen6.drop('class', axis=1)\n",
    "# dataY = pen6['class']\n",
    "\n",
    "# train_ratio = 0.75\n",
    "# validation_ratio = 0.15\n",
    "# test_ratio = 0.10\n",
    "\n",
    "# # train is now 75% of the entire data set\n",
    "# # the _junk suffix means that we drop that variable completely\n",
    "# # dataX, dataY: initial dataframe\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio)\n",
    "\n",
    "# # test is now 10% of the initial data set\n",
    "# # validation is now 15% of the initial data set\n",
    "# X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio))\n",
    "\n",
    "# #print(x_train, x_val, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ced3d839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# start = time.time() # For measuring time execution\n",
    "\n",
    "# cnb = CategoricalNB()\n",
    "# cnb.fit(X_train, y_train)\n",
    "\n",
    "# y_pred_cnb = cnb.predict(X_test)\n",
    "# y_prob_pred_cnb = cnb.predict_proba(X_test)\n",
    "\n",
    "# end = time.time()\n",
    "# print(end - start) # Total time execution for this sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e4a26e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # how did our model perform?\n",
    "# count_misclassified = (y_test != y_pred_cnb).sum()\n",
    "# print(\"CategoricalNB\")\n",
    "# print(\"=\" * 25)\n",
    "# print('Misclassified samples: {}'.format(count_misclassified))\n",
    "# accuracy = accuracy_score(y_test, y_pred_cnb)\n",
    "# print('Accuracy: {:.2f}'.format(accuracy))\n",
    "# print(\"=\" * 25)\n",
    "# print(\"Recall score : \", recall_score(y_test, y_pred_cnb , average='micro'))\n",
    "# print(\"Precision score : \",precision_score(y_test, y_pred_cnb , average='micro'))\n",
    "# print(\"F1 score : \",f1_score(y_test, y_pred_cnb , average='micro'))\n",
    "# print(\"=\" * 25)\n",
    "# print(\"Classification report:\")\n",
    "# print(classification_report(y_test, y_pred_cnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5989b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "#         cnb, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "#         loss='0-1_loss',\n",
    "#         random_seed=123)\n",
    "\n",
    "# print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "# print('Average bias: %.3f' % avg_bias)\n",
    "# print('Average variance: %.3f' % avg_var)\n",
    "# print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_cnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a86152",
   "metadata": {},
   "source": [
    "## 1.1 script version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99b94bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoricalNB\n",
      "=========================\n",
      "Misclassified samples: 156\n",
      "Accuracy: 0.86\n",
      "=========================\n",
      "Recall score :  0.8581818181818182\n",
      "Precision score :  0.8581818181818182\n",
      "F1 score :  0.858181818181818\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92       110\n",
      "           1       0.80      0.74      0.77       133\n",
      "           2       0.79      0.95      0.86       110\n",
      "           3       0.81      0.93      0.87       105\n",
      "           4       1.00      0.94      0.97       124\n",
      "           5       0.87      0.54      0.67       101\n",
      "           6       0.93      0.99      0.96       108\n",
      "           7       0.95      0.84      0.89        95\n",
      "           8       0.85      0.84      0.84       116\n",
      "           9       0.71      0.89      0.79        98\n",
      "\n",
      "    accuracy                           0.86      1100\n",
      "   macro avg       0.86      0.86      0.85      1100\n",
      "weighted avg       0.86      0.86      0.86      1100\n",
      "\n",
      "Classification report for validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91       176\n",
      "           1       0.72      0.72      0.72       144\n",
      "           2       0.86      0.96      0.91       174\n",
      "           3       0.85      0.98      0.91       159\n",
      "           4       0.98      0.95      0.96       170\n",
      "           5       0.91      0.56      0.69       149\n",
      "           6       0.98      0.99      0.98       163\n",
      "           7       0.96      0.84      0.90       176\n",
      "           8       0.88      0.83      0.86       163\n",
      "           9       0.71      0.92      0.80       174\n",
      "\n",
      "    accuracy                           0.87      1648\n",
      "   macro avg       0.88      0.87      0.86      1648\n",
      "weighted avg       0.88      0.87      0.87      1648\n",
      "\n",
      "Computation time:\n",
      "0.038524627685546875\n"
     ]
    }
   ],
   "source": [
    "# make test & train split\n",
    "dataX = pen6.drop('class', axis=1)\n",
    "dataY = pen6['class']\n",
    "\n",
    "train_ratio = 0.75\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.10\n",
    "\n",
    "# train is now 75% of the entire data set\n",
    "# the _junk suffix means that we drop that variable completely\n",
    "# dataX, dataY: initial dataframe\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio)\n",
    "\n",
    "# test is now 10% of the initial data set\n",
    "# validation is now 15% of the initial data set\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio))\n",
    "\n",
    "#print(x_train, x_val, x_test)\n",
    "\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "cnb = CategoricalNB()\n",
    "cnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_cnb = cnb.predict(X_test)\n",
    "y_prob_pred_cnb = cnb.predict_proba(X_test)\n",
    "\n",
    "\n",
    "# how did our model perform?\n",
    "count_misclassified = (y_test != y_pred_cnb).sum()\n",
    "print(\"CategoricalNB\")\n",
    "print(\"=\" * 25)\n",
    "print('Misclassified samples: {}'.format(count_misclassified))\n",
    "accuracy = accuracy_score(y_test, y_pred_cnb)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_cnb))\n",
    "\n",
    "#for validation\n",
    "y_val_cnb = cnb.predict(X_val)\n",
    "y_val_pred_cnb = cnb.predict_proba(X_val)\n",
    "print(\"Classification report for validation:\")\n",
    "print(classification_report(y_val, y_val_cnb))\n",
    "\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "294481f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.142\n",
      "Average bias: 0.141\n",
      "Average variance: 0.010\n",
      "Sklearn 0-1 loss: 0.142\n"
     ]
    }
   ],
   "source": [
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        cnb, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_cnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68d44662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92       110\n",
      "           1       0.80      0.74      0.77       133\n",
      "           2       0.79      0.95      0.86       110\n",
      "           3       0.81      0.93      0.87       105\n",
      "           4       1.00      0.94      0.97       124\n",
      "           5       0.87      0.54      0.67       101\n",
      "           6       0.93      0.99      0.96       108\n",
      "           7       0.95      0.84      0.89        95\n",
      "           8       0.85      0.84      0.84       116\n",
      "           9       0.71      0.89      0.79        98\n",
      "\n",
      "    accuracy                           0.86      1100\n",
      "   macro avg       0.86      0.86      0.85      1100\n",
      "weighted avg       0.86      0.86      0.86      1100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_cnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf64c978",
   "metadata": {},
   "source": [
    "## 1.2 medium Intervals from DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7f044694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make test & train split\n",
    "dataX = pen8.drop('class', axis=1)\n",
    "dataY = pen8['class']\n",
    "\n",
    "train_ratio = 0.75\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.10\n",
    "\n",
    "# train is now 75% of the entire data set\n",
    "# the _junk suffix means that we drop that variable completely\n",
    "# dataX, dataY: initial dataframe\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio)\n",
    "\n",
    "# test is now 10% of the initial data set\n",
    "# validation is now 15% of the initial data set\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio))\n",
    "\n",
    "#validation select the model or tune the parameters\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "91a2a331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoricalNB\n",
      "=========================\n",
      "Misclassified samples: 150\n",
      "Accuracy: 0.86\n",
      "=========================\n",
      "Recall score :  0.8636363636363636\n",
      "Precision score :  0.8636363636363636\n",
      "F1 score :  0.8636363636363636\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.86      0.88       115\n",
      "           1       0.88      0.77      0.82       128\n",
      "           2       0.81      0.96      0.88       104\n",
      "           3       0.88      0.97      0.92       115\n",
      "           4       0.97      0.97      0.97       112\n",
      "           5       0.90      0.51      0.65       105\n",
      "           6       0.98      0.96      0.97       116\n",
      "           7       0.91      0.83      0.87       103\n",
      "           8       0.74      0.85      0.79       100\n",
      "           9       0.71      0.95      0.82       102\n",
      "\n",
      "    accuracy                           0.86      1100\n",
      "   macro avg       0.87      0.86      0.86      1100\n",
      "weighted avg       0.87      0.86      0.86      1100\n",
      "\n",
      "Classification report for validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.85      0.90       175\n",
      "           1       0.76      0.72      0.74       176\n",
      "           2       0.82      0.95      0.88       176\n",
      "           3       0.84      0.95      0.89       149\n",
      "           4       1.00      0.95      0.98       171\n",
      "           5       0.89      0.62      0.73       162\n",
      "           6       0.95      0.98      0.96       141\n",
      "           7       0.96      0.85      0.90       162\n",
      "           8       0.77      0.88      0.82       149\n",
      "           9       0.80      0.94      0.86       187\n",
      "\n",
      "    accuracy                           0.87      1648\n",
      "   macro avg       0.87      0.87      0.87      1648\n",
      "weighted avg       0.87      0.87      0.86      1648\n",
      "\n",
      "Computation time:\n",
      "0.04492592811584473\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# make test & train split\n",
    "dataX = pen8.drop('class', axis=1)\n",
    "dataY = pen8['class']\n",
    "\n",
    "train_ratio = 0.75\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.10\n",
    "\n",
    "# train is now 75% of the entire data set\n",
    "# the _junk suffix means that we drop that variable completely\n",
    "# dataX, dataY: initial dataframe\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio)\n",
    "\n",
    "# test is now 10% of the initial data set\n",
    "# validation is now 15% of the initial data set\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio))\n",
    "\n",
    "#validation select the model or tune the parameters\n",
    "# \n",
    "\n",
    "cnb = CategoricalNB()\n",
    "cnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_cnb = cnb.predict(X_test)\n",
    "y_prob_pred_cnb = cnb.predict_proba(X_test)\n",
    "\n",
    "# how did our model perform?\n",
    "count_misclassified = (y_test != y_pred_cnb).sum()\n",
    "print(\"CategoricalNB\")\n",
    "print(\"=\" * 25)\n",
    "print('Misclassified samples: {}'.format(count_misclassified))\n",
    "accuracy = accuracy_score(y_test, y_pred_cnb)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_cnb))\n",
    "\n",
    "\n",
    "#for validation\n",
    "y_val_cnb = cnb.predict(X_val)\n",
    "y_val_pred_cnb = cnb.predict_proba(X_val)\n",
    "print(\"Classification report for validation:\")\n",
    "print(classification_report(y_val, y_val_cnb))\n",
    "\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e4d76235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.138\n",
      "Average bias: 0.135\n",
      "Average variance: 0.018\n",
      "Sklearn 0-1 loss: 0.136\n"
     ]
    }
   ],
   "source": [
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        cnb, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_cnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd86461",
   "metadata": {},
   "source": [
    "## 1.3 large Intervals from DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a3b9b6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoricalNB\n",
      "=========================\n",
      "Misclassified samples: 148\n",
      "Accuracy: 0.87\n",
      "=========================\n",
      "Recall score :  0.8654545454545455\n",
      "Precision score :  0.8654545454545455\n",
      "F1 score :  0.8654545454545455\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.91       101\n",
      "           1       0.79      0.73      0.76       120\n",
      "           2       0.81      0.91      0.86       115\n",
      "           3       0.85      0.96      0.90        97\n",
      "           4       1.00      0.97      0.98       131\n",
      "           5       0.87      0.58      0.69       123\n",
      "           6       0.97      0.98      0.98       105\n",
      "           7       0.93      0.84      0.89       102\n",
      "           8       0.85      0.87      0.86       105\n",
      "           9       0.73      0.93      0.82       101\n",
      "\n",
      "    accuracy                           0.87      1100\n",
      "   macro avg       0.87      0.87      0.86      1100\n",
      "weighted avg       0.87      0.87      0.86      1100\n",
      "\n",
      "Classification report for validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       164\n",
      "           1       0.78      0.70      0.74       170\n",
      "           2       0.82      0.97      0.88       178\n",
      "           3       0.88      0.97      0.92       180\n",
      "           4       0.99      0.96      0.97       177\n",
      "           5       0.91      0.57      0.70       141\n",
      "           6       0.97      0.97      0.97       161\n",
      "           7       0.95      0.87      0.91       172\n",
      "           8       0.85      0.84      0.84       155\n",
      "           9       0.76      0.96      0.85       150\n",
      "\n",
      "    accuracy                           0.88      1648\n",
      "   macro avg       0.88      0.87      0.87      1648\n",
      "weighted avg       0.88      0.88      0.88      1648\n",
      "\n",
      "Computation time:\n",
      "0.03278613090515137\n"
     ]
    }
   ],
   "source": [
    "# make test & train split\n",
    "dataX = pen10.drop('class', axis=1)\n",
    "dataY = pen10['class']\n",
    "\n",
    "train_ratio = 0.75\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.10\n",
    "\n",
    "# train is now 75% of the entire data set\n",
    "# the _junk suffix means that we drop that variable completely\n",
    "# dataX, dataY: initial dataframe\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio)\n",
    "\n",
    "# test is now 10% of the initial data set\n",
    "# validation is now 15% of the initial data set\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio))\n",
    "\n",
    "#validation select the model or tune the parameters\n",
    "# \n",
    "\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "cnb = CategoricalNB()\n",
    "cnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_cnb = cnb.predict(X_test)\n",
    "y_prob_pred_cnb = cnb.predict_proba(X_test)\n",
    "\n",
    "# how did our model perform?\n",
    "count_misclassified = (y_test != y_pred_cnb).sum()\n",
    "print(\"CategoricalNB\")\n",
    "print(\"=\" * 25)\n",
    "print('Misclassified samples: {}'.format(count_misclassified))\n",
    "accuracy = accuracy_score(y_test, y_pred_cnb)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_cnb))\n",
    "\n",
    "\n",
    "#for validation\n",
    "y_val_cnb = cnb.predict(X_val)\n",
    "y_val_pred_cnb = cnb.predict_proba(X_val)\n",
    "print(\"Classification report for validation:\")\n",
    "print(classification_report(y_val, y_val_cnb))\n",
    "\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95a8a3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.134\n",
      "Average bias: 0.135\n",
      "Average variance: 0.017\n",
      "Sklearn 0-1 loss: 0.135\n"
     ]
    }
   ],
   "source": [
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        cnb, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_cnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b03574",
   "metadata": {},
   "source": [
    "## 1.4 extra large Intervals from DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "eac24eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoricalNB\n",
      "=========================\n",
      "Misclassified samples: 151\n",
      "Accuracy: 0.86\n",
      "=========================\n",
      "Recall score :  0.8627272727272727\n",
      "Precision score :  0.8627272727272727\n",
      "F1 score :  0.8627272727272727\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.93       110\n",
      "           1       0.79      0.73      0.76       128\n",
      "           2       0.82      0.94      0.87       109\n",
      "           3       0.83      0.94      0.88       110\n",
      "           4       0.99      0.96      0.98       106\n",
      "           5       0.93      0.60      0.73       113\n",
      "           6       0.98      0.98      0.98       102\n",
      "           7       0.93      0.79      0.85       100\n",
      "           8       0.82      0.86      0.84       106\n",
      "           9       0.73      0.96      0.83       116\n",
      "\n",
      "    accuracy                           0.86      1100\n",
      "   macro avg       0.88      0.87      0.86      1100\n",
      "weighted avg       0.87      0.86      0.86      1100\n",
      "\n",
      "Classification report for validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.92      0.93       167\n",
      "           1       0.80      0.73      0.77       174\n",
      "           2       0.81      0.91      0.86       179\n",
      "           3       0.83      0.97      0.90       145\n",
      "           4       0.99      0.96      0.97       176\n",
      "           5       0.92      0.61      0.74       166\n",
      "           6       0.98      0.99      0.99       170\n",
      "           7       0.93      0.84      0.89       165\n",
      "           8       0.85      0.86      0.85       159\n",
      "           9       0.73      0.96      0.83       147\n",
      "\n",
      "    accuracy                           0.87      1648\n",
      "   macro avg       0.88      0.87      0.87      1648\n",
      "weighted avg       0.88      0.87      0.87      1648\n",
      "\n",
      "0.03410601615905762\n"
     ]
    }
   ],
   "source": [
    "# make test & train split\n",
    "dataX = pen15.drop('class', axis=1)\n",
    "dataY = pen15['class']\n",
    "\n",
    "train_ratio = 0.75\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.10\n",
    "\n",
    "# train is now 75% of the entire data set\n",
    "# the _junk suffix means that we drop that variable completely\n",
    "# dataX, dataY: initial dataframe\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio)\n",
    "\n",
    "# test is now 10% of the initial data set\n",
    "# validation is now 15% of the initial data set\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio))\n",
    "\n",
    "#validation select the model or tune the parameters\n",
    "# \n",
    "\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "cnb = CategoricalNB()\n",
    "cnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_cnb = cnb.predict(X_test)\n",
    "y_prob_pred_cnb = cnb.predict_proba(X_test)\n",
    "\n",
    "# how did our model perform?\n",
    "count_misclassified = (y_test != y_pred_cnb).sum()\n",
    "print(\"CategoricalNB\")\n",
    "print(\"=\" * 25)\n",
    "print('Misclassified samples: {}'.format(count_misclassified))\n",
    "accuracy = accuracy_score(y_test, y_pred_cnb)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_cnb))\n",
    "\n",
    "\n",
    "#for validation\n",
    "y_val_cnb = cnb.predict(X_val)\n",
    "y_val_pred_cnb = cnb.predict_proba(X_val)\n",
    "print(\"Classification report for validation:\")\n",
    "print(classification_report(y_val, y_val_cnb))\n",
    "\n",
    "end = time.time()\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f9331673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.141\n",
      "Average bias: 0.137\n",
      "Average variance: 0.024\n",
      "Sklearn 0-1 loss: 0.137\n"
     ]
    }
   ],
   "source": [
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        cnb, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_cnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36de93a1",
   "metadata": {},
   "source": [
    "# 2. Decision Tree ID3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5da502c",
   "metadata": {},
   "source": [
    "## 2.1 small Intervals from DT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cc6ec6",
   "metadata": {},
   "source": [
    "### Debug version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "efd2a195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = pena6.drop('label', axis=1)\n",
    "# y = pen6['label']\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0b0a2232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# start = time.time() # For measuring time execution\n",
    "\n",
    "# estimator = Id3Estimator()\n",
    "# estimator = estimator.fit(X_train, y_train, check_input=True)\n",
    "# tree = export_graphviz(estimator.tree_, 'tree.dot', y)\n",
    "\n",
    "# y_pred_id3 = estimator.predict(X_test)\n",
    "# #_prob_pred_id3 = estimator.predict_proba(X_test)\n",
    "\n",
    "# end = time.time()\n",
    "# print(\"Computation time:\")\n",
    "# print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4a3dc865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy = accuracy_score(y_test, y_pred_id3)\n",
    "# print('Accuracy: {:.2f}'.format(accuracy))\n",
    "# print(\"=\" * 25)\n",
    "# print(\"Recall score : \", recall_score(y_test, y_pred_id3 , average='micro'))\n",
    "# print(\"Precision score : \",precision_score(y_test, y_pred_id3 , average='micro'))\n",
    "# print(\"F1 score : \",f1_score(y_test, y_pred_id3 , average='micro'))\n",
    "# print(\"=\" * 25)\n",
    "# print(\"Classification report:\")\n",
    "# print(classification_report(y_test, y_pred_id3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "95681052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "#         estimator, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "#         loss='0-1_loss',\n",
    "#         random_seed=123)\n",
    "\n",
    "# print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "# print('Average bias: %.3f' % avg_bias)\n",
    "# print('Average variance: %.3f' % avg_var)\n",
    "# print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b305a740",
   "metadata": {},
   "source": [
    "### script version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6cfce8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.93\n",
      "=========================\n",
      "Recall score :  0.9327272727272727\n",
      "Precision score :  0.9327272727272727\n",
      "F1 score :  0.9327272727272727\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97       118\n",
      "           1       0.88      0.88      0.88       122\n",
      "           2       0.93      0.92      0.92       126\n",
      "           3       0.89      0.92      0.91       120\n",
      "           4       0.97      0.97      0.97        99\n",
      "           5       0.92      0.92      0.92       100\n",
      "           6       0.97      0.94      0.96       106\n",
      "           7       0.96      0.97      0.97       108\n",
      "           8       0.92      0.97      0.94        95\n",
      "           9       0.93      0.88      0.90       106\n",
      "\n",
      "    accuracy                           0.93      1100\n",
      "   macro avg       0.93      0.93      0.93      1100\n",
      "weighted avg       0.93      0.93      0.93      1100\n",
      "\n",
      "Classification report for validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       170\n",
      "           1       0.91      0.90      0.91       177\n",
      "           2       0.90      0.94      0.91       155\n",
      "           3       0.91      0.96      0.94       144\n",
      "           4       0.98      0.99      0.98       197\n",
      "           5       0.92      0.87      0.89       156\n",
      "           6       0.95      0.97      0.96       160\n",
      "           7       0.98      0.94      0.96       181\n",
      "           8       0.96      0.95      0.95       144\n",
      "           9       0.92      0.94      0.93       164\n",
      "\n",
      "    accuracy                           0.94      1648\n",
      "   macro avg       0.94      0.94      0.94      1648\n",
      "weighted avg       0.94      0.94      0.94      1648\n",
      "\n",
      "Computation time:\n",
      "0.5746464729309082\n"
     ]
    }
   ],
   "source": [
    "# make test & train split\n",
    "dataX = pen6.drop('class', axis=1)\n",
    "dataY = pen6['class']\n",
    "\n",
    "train_ratio = 0.75\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.10\n",
    "\n",
    "# train is now 75% of the entire data set\n",
    "# the _junk suffix means that we drop that variable completely\n",
    "# dataX, dataY: initial dataframe\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio)\n",
    "\n",
    "# test is now 10% of the initial data set\n",
    "# validation is now 15% of the initial data set\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio))\n",
    "#time recording\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "#build estimator\n",
    "estimator = Id3Estimator()\n",
    "estimator = estimator.fit(X_train, y_train, check_input=True)\n",
    "#tree = export_graphviz(estimator.tree_, 'tree.dot', y)\n",
    "#make predictions\n",
    "y_pred_id3 = estimator.predict(X_test)\n",
    "#_prob_pred_id3 = estimator.predict_proba(X_test)\n",
    "#report performance\n",
    "accuracy = accuracy_score(y_test, y_pred_id3)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "\n",
    "#for validation\n",
    "y_val_id3 = estimator.predict(X_val)\n",
    "print(\"Classification report for validation:\")\n",
    "print(classification_report(y_val, y_val_id3))\n",
    "\n",
    "\n",
    "#stop time recoridng\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fbdd3878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.075\n",
      "Average bias: 0.050\n",
      "Average variance: 0.053\n",
      "Sklearn 0-1 loss: 0.067\n"
     ]
    }
   ],
   "source": [
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        estimator, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c21b52",
   "metadata": {},
   "source": [
    "## 2.2 medium Intervals from DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "011a2f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.93\n",
      "=========================\n",
      "Recall score :  0.9254545454545454\n",
      "Precision score :  0.9254545454545454\n",
      "F1 score :  0.9254545454545455\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95       118\n",
      "           1       0.89      0.82      0.86       112\n",
      "           2       0.91      0.91      0.91       105\n",
      "           3       0.93      0.96      0.94       116\n",
      "           4       0.96      0.94      0.95       108\n",
      "           5       0.89      0.94      0.91       116\n",
      "           6       0.92      0.97      0.95       109\n",
      "           7       0.92      0.99      0.95        93\n",
      "           8       0.95      0.89      0.92       119\n",
      "           9       0.92      0.90      0.91       104\n",
      "\n",
      "    accuracy                           0.93      1100\n",
      "   macro avg       0.93      0.93      0.93      1100\n",
      "weighted avg       0.93      0.93      0.93      1100\n",
      "\n",
      "Classification report for validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       187\n",
      "           1       0.90      0.84      0.87       188\n",
      "           2       0.90      0.91      0.90       167\n",
      "           3       0.94      0.95      0.94       153\n",
      "           4       0.95      0.96      0.96       193\n",
      "           5       0.91      0.96      0.93       138\n",
      "           6       0.95      0.95      0.95       150\n",
      "           7       0.95      0.98      0.97       213\n",
      "           8       0.93      0.91      0.92       127\n",
      "           9       0.95      0.94      0.95       132\n",
      "\n",
      "    accuracy                           0.94      1648\n",
      "   macro avg       0.94      0.94      0.94      1648\n",
      "weighted avg       0.94      0.94      0.94      1648\n",
      "\n",
      "Computation time:\n",
      "0.910346269607544\n"
     ]
    }
   ],
   "source": [
    "# make test & train split\n",
    "dataX = pen8.drop('class', axis=1)\n",
    "dataY = pen8['class']\n",
    "\n",
    "train_ratio = 0.75\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.10\n",
    "\n",
    "# train is now 75% of the entire data set\n",
    "# the _junk suffix means that we drop that variable completely\n",
    "# dataX, dataY: initial dataframe\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio)\n",
    "\n",
    "# test is now 10% of the initial data set\n",
    "# validation is now 15% of the initial data set\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio))\n",
    "#time recording\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "#build estimator\n",
    "estimator = Id3Estimator()\n",
    "estimator = estimator.fit(X_train, y_train)\n",
    "#tree = export_graphviz(estimator.tree_, 'tree.dot', y)\n",
    "#make predictions\n",
    "y_pred_id3 = estimator.predict(X_test)\n",
    "#_prob_pred_id3 = estimator.predict_proba(X_test)\n",
    "#report performance\n",
    "accuracy = accuracy_score(y_test, y_pred_id3)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "\n",
    "#for validation\n",
    "y_val_id3 = estimator.predict(X_val)\n",
    "print(\"Classification report for validation:\")\n",
    "print(classification_report(y_val, y_val_id3))\n",
    "\n",
    "#stop time recoridng\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b1fa40c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.084\n",
      "Average bias: 0.048\n",
      "Average variance: 0.061\n",
      "Sklearn 0-1 loss: 0.075\n"
     ]
    }
   ],
   "source": [
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        estimator, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687f1ea3",
   "metadata": {},
   "source": [
    "## 2.3 large Intervals from DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "82063c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.92\n",
      "=========================\n",
      "Recall score :  0.9209090909090909\n",
      "Precision score :  0.9209090909090909\n",
      "F1 score :  0.9209090909090909\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       115\n",
      "           1       0.88      0.85      0.86       118\n",
      "           2       0.88      0.89      0.88       112\n",
      "           3       0.91      0.91      0.91       114\n",
      "           4       0.94      0.97      0.96       123\n",
      "           5       0.89      0.91      0.90       112\n",
      "           6       0.93      0.91      0.92       113\n",
      "           7       0.94      0.97      0.95       106\n",
      "           8       0.92      0.91      0.92       104\n",
      "           9       0.96      0.90      0.93        83\n",
      "\n",
      "    accuracy                           0.92      1100\n",
      "   macro avg       0.92      0.92      0.92      1100\n",
      "weighted avg       0.92      0.92      0.92      1100\n",
      "\n",
      "Classification report for validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98       184\n",
      "           1       0.90      0.85      0.88       188\n",
      "           2       0.86      0.93      0.89       161\n",
      "           3       0.91      0.94      0.92       159\n",
      "           4       0.95      0.96      0.96       169\n",
      "           5       0.93      0.86      0.89       153\n",
      "           6       0.95      0.98      0.96       174\n",
      "           7       0.96      0.95      0.96       170\n",
      "           8       0.91      0.91      0.91       139\n",
      "           9       0.93      0.94      0.94       151\n",
      "\n",
      "    accuracy                           0.93      1648\n",
      "   macro avg       0.93      0.93      0.93      1648\n",
      "weighted avg       0.93      0.93      0.93      1648\n",
      "\n",
      "Computation time:\n",
      "1.0760793685913086\n"
     ]
    }
   ],
   "source": [
    "# make test & train split\n",
    "dataX = pen10.drop('class', axis=1)\n",
    "dataY = pen10['class']\n",
    "\n",
    "train_ratio = 0.75\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.10\n",
    "\n",
    "# train is now 75% of the entire data set\n",
    "# the _junk suffix means that we drop that variable completely\n",
    "# dataX, dataY: initial dataframe\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio)\n",
    "\n",
    "# test is now 10% of the initial data set\n",
    "# validation is now 15% of the initial data set\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio))\n",
    "#time recording\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "#build estimator\n",
    "estimator = Id3Estimator()\n",
    "estimator = estimator.fit(X_train, y_train, check_input=True)\n",
    "#tree = export_graphviz(estimator.tree_, 'tree.dot', y)\n",
    "#make predictions\n",
    "y_pred_id3 = estimator.predict(X_test)\n",
    "#_prob_pred_id3 = estimator.predict_proba(X_test)\n",
    "#report performance\n",
    "accuracy = accuracy_score(y_test, y_pred_id3)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "\n",
    "#for validation\n",
    "y_val_id3 = estimator.predict(X_val)\n",
    "print(\"Classification report for validation:\")\n",
    "print(classification_report(y_val, y_val_id3))\n",
    "\n",
    "#stop time recoridng\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4239d3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.092\n",
      "Average bias: 0.051\n",
      "Average variance: 0.072\n",
      "Sklearn 0-1 loss: 0.079\n"
     ]
    }
   ],
   "source": [
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        estimator, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251b1503",
   "metadata": {},
   "source": [
    "## 2.4 extra large Intervals from DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9907debd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.91\n",
      "=========================\n",
      "Recall score :  0.9118181818181819\n",
      "Precision score :  0.9118181818181819\n",
      "F1 score :  0.9118181818181819\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       119\n",
      "           1       0.86      0.89      0.88       115\n",
      "           2       0.92      0.88      0.90       117\n",
      "           3       0.84      0.84      0.84        94\n",
      "           4       0.95      0.96      0.96       105\n",
      "           5       0.88      0.88      0.88       106\n",
      "           6       0.93      0.94      0.93        99\n",
      "           7       0.92      0.93      0.93       128\n",
      "           8       0.93      0.91      0.92       112\n",
      "           9       0.92      0.92      0.92       105\n",
      "\n",
      "    accuracy                           0.91      1100\n",
      "   macro avg       0.91      0.91      0.91      1100\n",
      "weighted avg       0.91      0.91      0.91      1100\n",
      "\n",
      "Classification report for validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97       166\n",
      "           1       0.89      0.88      0.88       178\n",
      "           2       0.91      0.92      0.91       179\n",
      "           3       0.87      0.91      0.89       160\n",
      "           4       0.95      0.96      0.95       167\n",
      "           5       0.91      0.87      0.89       169\n",
      "           6       0.90      0.94      0.92       151\n",
      "           7       0.94      0.96      0.95       170\n",
      "           8       0.94      0.95      0.94       152\n",
      "           9       0.91      0.86      0.88       156\n",
      "\n",
      "    accuracy                           0.92      1648\n",
      "   macro avg       0.92      0.92      0.92      1648\n",
      "weighted avg       0.92      0.92      0.92      1648\n",
      "\n",
      "Computation time:\n",
      "1.4830832481384277\n"
     ]
    }
   ],
   "source": [
    "# make test & train split\n",
    "dataX = pen15.drop('class', axis=1)\n",
    "dataY = pen15['class']\n",
    "\n",
    "train_ratio = 0.75\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.10\n",
    "\n",
    "# train is now 75% of the entire data set\n",
    "# the _junk suffix means that we drop that variable completely\n",
    "# dataX, dataY: initial dataframe\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio)\n",
    "\n",
    "# test is now 10% of the initial data set\n",
    "# validation is now 15% of the initial data set\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio))\n",
    "#time recording\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "#build estimator\n",
    "estimator = Id3Estimator()\n",
    "estimator = estimator.fit(X_train, y_train, check_input=True)\n",
    "#tree = export_graphviz(estimator.tree_, 'tree.dot', y)\n",
    "#make predictions\n",
    "y_pred_id3 = estimator.predict(X_test)\n",
    "#_prob_pred_id3 = estimator.predict_proba(X_test)\n",
    "#report performance\n",
    "accuracy = accuracy_score(y_test, y_pred_id3)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "\n",
    "#for validation\n",
    "y_val_id3 = estimator.predict(X_val)\n",
    "print(\"Classification report for validation:\")\n",
    "print(classification_report(y_val, y_val_id3))\n",
    "\n",
    "#stop time recoridng\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "da73d6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.099\n",
      "Average bias: 0.056\n",
      "Average variance: 0.078\n",
      "Sklearn 0-1 loss: 0.088\n"
     ]
    }
   ],
   "source": [
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        estimator, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3533e6de",
   "metadata": {},
   "source": [
    "# 3. KNN classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "434480bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data from ChiMerge discretization\n",
    "pen6 = pd.read_csv('chim_pen_6int.csv')\n",
    "pen8 = pd.read_csv('chim_pen_8int.csv')\n",
    "pen10 = pd.read_csv('chim_pen_10int.csv')\n",
    "pen15 = pd.read_csv('chim_pen_15int.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6c2243",
   "metadata": {},
   "source": [
    "## 3.1 KNN with DT small Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2aa62f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 17 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   A1      1000 non-null   int64\n",
      " 1   A2      1000 non-null   int64\n",
      " 2   A3      1000 non-null   int64\n",
      " 3   A4      1000 non-null   int64\n",
      " 4   A5      1000 non-null   int64\n",
      " 5   A6      1000 non-null   int64\n",
      " 6   A7      1000 non-null   int64\n",
      " 7   A8      1000 non-null   int64\n",
      " 8   A9      1000 non-null   int64\n",
      " 9   A10     1000 non-null   int64\n",
      " 10  A11     1000 non-null   int64\n",
      " 11  A12     1000 non-null   int64\n",
      " 12  A13     1000 non-null   int64\n",
      " 13  A14     1000 non-null   int64\n",
      " 14  A15     1000 non-null   int64\n",
      " 15  A16     1000 non-null   int64\n",
      " 16  class   1000 non-null   int64\n",
      "dtypes: int64(17)\n",
      "memory usage: 132.9 KB\n",
      "(1000, 16) (1000,)\n",
      "Class representation - original:  Counter({2: 115, 5: 113, 8: 107, 1: 104, 0: 104, 3: 103, 6: 95, 4: 93, 7: 88, 9: 78})\n",
      "Class representation - training data:  Counter({5: 90, 2: 86, 8: 82, 0: 81, 3: 77, 1: 76, 6: 73, 7: 70, 4: 62, 9: 53})\n",
      "Class representation - testing data:  Counter({4: 31, 2: 29, 1: 28, 3: 26, 9: 25, 8: 25, 0: 23, 5: 23, 6: 22, 7: 18})\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_ewd1 = pen6.head(1000)\n",
    "disc = 'EWD'\n",
    "k = 4\n",
    "\n",
    "df_ewd1.info()\n",
    "data = df_ewd1.values\n",
    "data.shape\n",
    "\n",
    "features = df_ewd1.drop('class', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 30)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a8733d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        23\n",
      "           1       1.00      0.86      0.92        28\n",
      "           2       0.91      1.00      0.95        29\n",
      "           3       0.96      0.96      0.96        26\n",
      "           4       0.97      1.00      0.98        31\n",
      "           5       0.96      1.00      0.98        23\n",
      "           6       1.00      0.95      0.98        22\n",
      "           7       0.95      1.00      0.97        18\n",
      "           8       1.00      1.00      1.00        25\n",
      "           9       1.00      0.92      0.96        25\n",
      "\n",
      "    accuracy                           0.97       250\n",
      "   macro avg       0.97      0.97      0.97       250\n",
      "weighted avg       0.97      0.97      0.97       250\n",
      "\n",
      "Time for training model Knn-VDM: 313.62438583374023.\n"
     ]
    }
   ],
   "source": [
    "# Knn-VDM complete code\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(x_train, y_train, continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "# Fit model\n",
    "knn_vdm.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(x_test)\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c978b0f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_61452/2301922218.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n\u001b[0m\u001b[0;32m      2\u001b[0m         \u001b[0mknn_vdm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'0-1_loss'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         random_seed=123)\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mlxtend\\evaluate\\bias_variance_decomp.py\u001b[0m in \u001b[0;36mbias_variance_decomp\u001b[1;34m(estimator, X_train, y_train, X_test, y_test, loss, num_rounds, random_seed, **fit_params)\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_boot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_boot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m         \u001b[0mall_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    217\u001b[0m             \u001b[1;31m# In that case, we do not need the distances to perform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m             \u001b[1;31m# the weighting so we do not compute them.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 219\u001b[1;33m             \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    220\u001b[0m             \u001b[0mneigh_dist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    794\u001b[0m                 \u001b[0mkwds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meffective_metric_params_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 796\u001b[1;33m             chunked_results = list(\n\u001b[0m\u001b[0;32m    797\u001b[0m                 pairwise_distances_chunked(\n\u001b[0;32m    798\u001b[0m                     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   1815\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1816\u001b[0m             \u001b[0mX_chunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msl\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1817\u001b[1;33m         \u001b[0mD_chunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpairwise_distances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_chunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1818\u001b[0m         if (X is Y or Y is None) and PAIRWISE_DISTANCE_FUNCTIONS.get(\n\u001b[0;32m   1819\u001b[0m             \u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[1;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   1987\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1988\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1989\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1990\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1529\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1530\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1532\u001b[0m     \u001b[1;31m# enforce a threading backend to prevent data communication overhead\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36m_pairwise_callable\u001b[1;34m(X, Y, metric, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   1572\u001b[0m         \u001b[0miterator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1573\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1574\u001b[1;33m             \u001b[0mout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1575\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1576\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\vdm3\\vdm.py\u001b[0m in \u001b[0;36mget_distance\u001b[1;34m(self, ins_1, ins_2, norm)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[0mins_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m         \u001b[0mins_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontinuous\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        knn_vdm, x_train, y_train, x_test, y_test, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed92116",
   "metadata": {},
   "source": [
    "## 3.2 KNN with DT medium Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b884bb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 17 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   A1      1000 non-null   int64\n",
      " 1   A2      1000 non-null   int64\n",
      " 2   A3      1000 non-null   int64\n",
      " 3   A4      1000 non-null   int64\n",
      " 4   A5      1000 non-null   int64\n",
      " 5   A6      1000 non-null   int64\n",
      " 6   A7      1000 non-null   int64\n",
      " 7   A8      1000 non-null   int64\n",
      " 8   A9      1000 non-null   int64\n",
      " 9   A10     1000 non-null   int64\n",
      " 10  A11     1000 non-null   int64\n",
      " 11  A12     1000 non-null   int64\n",
      " 12  A13     1000 non-null   int64\n",
      " 13  A14     1000 non-null   int64\n",
      " 14  A15     1000 non-null   int64\n",
      " 15  A16     1000 non-null   int64\n",
      " 16  class   1000 non-null   int64\n",
      "dtypes: int64(17)\n",
      "memory usage: 132.9 KB\n",
      "(1000, 16) (1000,)\n",
      "Class representation - original:  Counter({2: 115, 5: 113, 8: 107, 1: 104, 0: 104, 3: 103, 6: 95, 4: 93, 7: 88, 9: 78})\n",
      "Class representation - training data:  Counter({5: 90, 2: 86, 8: 82, 0: 81, 3: 77, 1: 76, 6: 73, 7: 70, 4: 62, 9: 53})\n",
      "Class representation - testing data:  Counter({4: 31, 2: 29, 1: 28, 3: 26, 9: 25, 8: 25, 0: 23, 5: 23, 6: 22, 7: 18})\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_ewd1 = pen8.head(1000)\n",
    "disc = 'EWD'\n",
    "k = 4\n",
    "\n",
    "df_ewd1.info()\n",
    "data = df_ewd1.values\n",
    "data.shape\n",
    "\n",
    "features = df_ewd1.drop('class', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 30)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1e564bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        23\n",
      "           1       0.96      0.89      0.93        28\n",
      "           2       0.94      1.00      0.97        29\n",
      "           3       0.92      0.92      0.92        26\n",
      "           4       0.97      0.97      0.97        31\n",
      "           5       0.92      1.00      0.96        23\n",
      "           6       1.00      1.00      1.00        22\n",
      "           7       0.89      0.94      0.92        18\n",
      "           8       1.00      0.92      0.96        25\n",
      "           9       0.96      0.92      0.94        25\n",
      "\n",
      "    accuracy                           0.96       250\n",
      "   macro avg       0.96      0.96      0.96       250\n",
      "weighted avg       0.96      0.96      0.96       250\n",
      "\n",
      "Time for training model Knn-VDM: 315.3986611366272.\n"
     ]
    }
   ],
   "source": [
    "# Knn-VDM complete code\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(x_train, y_train, continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "# Fit model\n",
    "knn_vdm.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(x_test)\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7231bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        knn_vdm, x_train, y_train, x_test, y_test, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654ef1a1",
   "metadata": {},
   "source": [
    "## 3.3 KNN with DT large Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "74bf57e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 17 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   A1      1000 non-null   int64\n",
      " 1   A2      1000 non-null   int64\n",
      " 2   A3      1000 non-null   int64\n",
      " 3   A4      1000 non-null   int64\n",
      " 4   A5      1000 non-null   int64\n",
      " 5   A6      1000 non-null   int64\n",
      " 6   A7      1000 non-null   int64\n",
      " 7   A8      1000 non-null   int64\n",
      " 8   A9      1000 non-null   int64\n",
      " 9   A10     1000 non-null   int64\n",
      " 10  A11     1000 non-null   int64\n",
      " 11  A12     1000 non-null   int64\n",
      " 12  A13     1000 non-null   int64\n",
      " 13  A14     1000 non-null   int64\n",
      " 14  A15     1000 non-null   int64\n",
      " 15  A16     1000 non-null   int64\n",
      " 16  class   1000 non-null   int64\n",
      "dtypes: int64(17)\n",
      "memory usage: 132.9 KB\n",
      "(1000, 16) (1000,)\n",
      "Class representation - original:  Counter({2: 115, 5: 113, 8: 107, 1: 104, 0: 104, 3: 103, 6: 95, 4: 93, 7: 88, 9: 78})\n",
      "Class representation - training data:  Counter({5: 90, 2: 86, 8: 82, 0: 81, 3: 77, 1: 76, 6: 73, 7: 70, 4: 62, 9: 53})\n",
      "Class representation - testing data:  Counter({4: 31, 2: 29, 1: 28, 3: 26, 9: 25, 8: 25, 0: 23, 5: 23, 6: 22, 7: 18})\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_ewd1 = pen10.head(1000)\n",
    "disc = 'EWD'\n",
    "k = 4\n",
    "\n",
    "df_ewd1.info()\n",
    "data = df_ewd1.values\n",
    "data.shape\n",
    "\n",
    "features = df_ewd1.drop('class', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 30)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "221f0a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        23\n",
      "           1       0.96      0.93      0.95        28\n",
      "           2       0.97      1.00      0.98        29\n",
      "           3       0.93      0.96      0.94        26\n",
      "           4       0.97      0.97      0.97        31\n",
      "           5       0.92      1.00      0.96        23\n",
      "           6       1.00      1.00      1.00        22\n",
      "           7       0.94      0.94      0.94        18\n",
      "           8       1.00      0.92      0.96        25\n",
      "           9       0.96      0.92      0.94        25\n",
      "\n",
      "    accuracy                           0.96       250\n",
      "   macro avg       0.96      0.96      0.96       250\n",
      "weighted avg       0.96      0.96      0.96       250\n",
      "\n",
      "Time for training model Knn-VDM: 307.64182806015015.\n"
     ]
    }
   ],
   "source": [
    "# Knn-VDM complete code\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(x_train, y_train, continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "# Fit model\n",
    "knn_vdm.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(x_test)\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3a80da",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        knn_vdm, x_train, y_train, x_test, y_test, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9516fd7",
   "metadata": {},
   "source": [
    "## 3.4 KNN with DT extra large Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cfbf9df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 17 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   A1      1000 non-null   int64\n",
      " 1   A2      1000 non-null   int64\n",
      " 2   A3      1000 non-null   int64\n",
      " 3   A4      1000 non-null   int64\n",
      " 4   A5      1000 non-null   int64\n",
      " 5   A6      1000 non-null   int64\n",
      " 6   A7      1000 non-null   int64\n",
      " 7   A8      1000 non-null   int64\n",
      " 8   A9      1000 non-null   int64\n",
      " 9   A10     1000 non-null   int64\n",
      " 10  A11     1000 non-null   int64\n",
      " 11  A12     1000 non-null   int64\n",
      " 12  A13     1000 non-null   int64\n",
      " 13  A14     1000 non-null   int64\n",
      " 14  A15     1000 non-null   int64\n",
      " 15  A16     1000 non-null   int64\n",
      " 16  class   1000 non-null   int64\n",
      "dtypes: int64(17)\n",
      "memory usage: 132.9 KB\n",
      "(1000, 16) (1000,)\n",
      "Class representation - original:  Counter({2: 115, 5: 113, 8: 107, 1: 104, 0: 104, 3: 103, 6: 95, 4: 93, 7: 88, 9: 78})\n",
      "Class representation - training data:  Counter({5: 90, 2: 86, 8: 82, 0: 81, 3: 77, 1: 76, 6: 73, 7: 70, 4: 62, 9: 53})\n",
      "Class representation - testing data:  Counter({4: 31, 2: 29, 1: 28, 3: 26, 9: 25, 8: 25, 0: 23, 5: 23, 6: 22, 7: 18})\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_ewd1 = pen15.head(1000)\n",
    "disc = 'EWD'\n",
    "k = 4\n",
    "\n",
    "df_ewd1.info()\n",
    "data = df_ewd1.values\n",
    "data.shape\n",
    "\n",
    "features = df_ewd1.drop('class', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 30)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2e7d598f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        23\n",
      "           1       0.96      0.86      0.91        28\n",
      "           2       0.94      1.00      0.97        29\n",
      "           3       0.89      0.92      0.91        26\n",
      "           4       0.97      0.97      0.97        31\n",
      "           5       0.88      0.96      0.92        23\n",
      "           6       1.00      1.00      1.00        22\n",
      "           7       0.89      0.94      0.92        18\n",
      "           8       1.00      0.92      0.96        25\n",
      "           9       0.96      0.92      0.94        25\n",
      "\n",
      "    accuracy                           0.95       250\n",
      "   macro avg       0.95      0.95      0.95       250\n",
      "weighted avg       0.95      0.95      0.95       250\n",
      "\n",
      "Time for training model Knn-VDM: 279.1525971889496.\n"
     ]
    }
   ],
   "source": [
    "# Knn-VDM complete code\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(x_train, y_train, continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "# Fit model\n",
    "knn_vdm.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(x_test)\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffcccbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        knn_vdm, x_train, y_train, x_test, y_test, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
