{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abd2336c",
   "metadata": {},
   "source": [
    "# ML Experiments using different bin sizes & widths based on outputs from supervised discretization using ChiMerge discretizer\n",
    "## Dataset: Satimage\n",
    "\n",
    "by: Malina & Sam , 04.07.2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83bc40c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score, recall_score, precision_score\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "import six\n",
    "import sys\n",
    "sys.modules['sklearn.externals.six'] = six\n",
    "import id3\n",
    "from id3 import Id3Estimator\n",
    "from id3 import export_graphviz\n",
    "import wittgenstein as lw\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from pandas import set_option\n",
    "import numpy as np\n",
    "from numpy import arange\n",
    "## EDA\n",
    "from collections import Counter\n",
    "\n",
    "# Knn-VDM 3\n",
    "from vdm3 import ValueDifferenceMetric\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Pre-processing\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "# Cross validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score # 1 metric\n",
    "from sklearn.model_selection import cross_validate # more than 1 metric\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50eb04fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data from ChiMerge discretization\n",
    "satimage6 = pd.read_csv('ChiM_discretized_6Intervals_satimage.csv')\n",
    "satimage8 = pd.read_csv('ChiM_discretized_8Intervals_satimage.csv')\n",
    "satimage10 = pd.read_csv('ChiM_discretized_10Intervals_satimage.csv')\n",
    "satimage15 = pd.read_csv('ChiM_discretized_15Intervals_satimage.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24075c8",
   "metadata": {},
   "source": [
    "## Interval frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94258ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_list6 = satimage6.columns.drop('class')\n",
    "num_list8 = satimage8.columns.drop('class')\n",
    "num_list10 = satimage10.columns.drop('class')\n",
    "num_list15 = satimage15.columns.drop('class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be896d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interval frequency for 6 Intervals\n",
      "Interval for A1\n",
      "Counter({2: 2245, 1: 1215, 5: 1048, 4: 880, 3: 563, 0: 484})\n",
      "Interval for A2\n",
      "Counter({5: 1893, 2: 1649, 3: 972, 4: 773, 1: 577, 0: 571})\n",
      "Interval for A3\n",
      "Counter({3: 1769, 4: 1377, 1: 1141, 0: 1083, 2: 969, 5: 96})\n",
      "Interval for A4\n",
      "Counter({3: 1970, 0: 1295, 2: 1174, 1: 765, 4: 731, 5: 500})\n",
      "Interval for A5\n",
      "Counter({3: 2259, 5: 1472, 2: 1063, 4: 968, 0: 489, 1: 184})\n",
      "Interval for A6\n",
      "Counter({5: 1855, 3: 1403, 2: 1315, 4: 777, 1: 557, 0: 528})\n",
      "Interval for A7\n",
      "Counter({4: 2161, 0: 1027, 1: 894, 2: 845, 5: 816, 3: 692})\n",
      "Interval for A8\n",
      "Counter({3: 1958, 0: 1648, 1: 887, 2: 711, 4: 681, 5: 550})\n",
      "Interval for A9\n",
      "Counter({3: 2392, 5: 1435, 2: 1068, 4: 858, 0: 499, 1: 183})\n",
      "Interval for A10\n",
      "Counter({2: 2000, 5: 1818, 4: 760, 1: 661, 3: 652, 0: 544})\n",
      "Interval for A11\n",
      "Counter({3: 2130, 2: 1293, 0: 1044, 4: 968, 1: 915, 5: 85})\n",
      "Interval for A12\n",
      "Counter({3: 1376, 2: 1292, 1: 1289, 0: 1262, 4: 677, 5: 539})\n",
      "Interval for A13\n",
      "Counter({2: 2343, 1: 1268, 5: 1032, 3: 891, 4: 454, 0: 447})\n",
      "Interval for A14\n",
      "Counter({5: 1799, 2: 1698, 3: 969, 4: 834, 1: 610, 0: 525})\n",
      "Interval for A15\n",
      "Counter({4: 1266, 5: 1240, 2: 1083, 0: 1007, 3: 955, 1: 884})\n",
      "Interval for A16\n",
      "Counter({3: 1684, 1: 1440, 0: 1235, 2: 1123, 5: 553, 4: 400})\n",
      "Interval for A17\n",
      "Counter({2: 1737, 1: 1244, 3: 1091, 5: 1003, 4: 857, 0: 503})\n",
      "Interval for A18\n",
      "Counter({5: 2218, 2: 1580, 3: 1066, 1: 632, 0: 536, 4: 403})\n",
      "Interval for A19\n",
      "Counter({3: 1758, 0: 1437, 2: 1257, 4: 1139, 1: 753, 5: 91})\n",
      "Interval for A20\n",
      "Counter({3: 1981, 2: 1441, 4: 1210, 1: 1184, 5: 551, 0: 68})\n",
      "Interval for A21\n",
      "Counter({2: 2416, 1: 1246, 5: 974, 3: 846, 0: 509, 4: 444})\n",
      "Interval for A22\n",
      "Counter({2: 2040, 5: 1823, 4: 758, 3: 621, 1: 606, 0: 587})\n",
      "Interval for A23\n",
      "Counter({3: 1740, 0: 1463, 1: 1353, 4: 1132, 2: 663, 5: 84})\n",
      "Interval for A24\n",
      "Counter({2: 1585, 3: 1561, 0: 1267, 1: 765, 4: 713, 5: 544})\n",
      "Interval for A25\n",
      "Counter({2: 2358, 1: 1215, 3: 899, 5: 805, 4: 657, 0: 501})\n",
      "Interval for A26\n",
      "Counter({2: 1699, 5: 1630, 3: 999, 4: 983, 0: 573, 1: 551})\n",
      "Interval for A27\n",
      "Counter({3: 1757, 1: 1575, 0: 1412, 4: 1128, 2: 469, 5: 94})\n",
      "Interval for A28\n",
      "Counter({3: 1990, 4: 1184, 0: 1116, 1: 942, 2: 624, 5: 579})\n",
      "Interval for A29\n",
      "Counter({2: 2394, 1: 1245, 5: 923, 3: 870, 4: 503, 0: 500})\n",
      "Interval for A30\n",
      "Counter({5: 1849, 2: 1721, 3: 961, 4: 748, 1: 622, 0: 534})\n",
      "Interval for A31\n",
      "Counter({3: 1751, 0: 1443, 2: 1273, 4: 1138, 1: 743, 5: 87})\n",
      "Interval for A32\n",
      "Counter({4: 2220, 3: 1609, 1: 1183, 2: 744, 5: 610, 0: 69})\n",
      "Interval for A33\n",
      "Counter({2: 1777, 1: 1269, 5: 1172, 3: 1097, 4: 619, 0: 501})\n",
      "Interval for A34\n",
      "Counter({5: 2037, 2: 1719, 3: 978, 1: 598, 0: 581, 4: 522})\n",
      "Interval for A35\n",
      "Counter({3: 1747, 0: 1471, 2: 1275, 4: 1118, 1: 740, 5: 84})\n",
      "Interval for A36\n",
      "Counter({4: 2273, 3: 1587, 1: 1199, 2: 754, 5: 551, 0: 71})\n"
     ]
    }
   ],
   "source": [
    "print('Interval frequency for 6 Intervals')\n",
    "for i in num_list6:\n",
    "    print('Interval for ' + i)\n",
    "    print(Counter(satimage6[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3edf860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency for iris with 8 Intervals\n",
      "Interval for A1\n",
      "Counter({3: 2245, 7: 1048, 2: 994, 4: 563, 0: 484, 6: 461, 5: 419, 1: 221})\n",
      "Interval for A2\n",
      "Counter({7: 1893, 4: 1649, 5: 972, 6: 773, 0: 485, 2: 393, 3: 184, 1: 86})\n",
      "Interval for A3\n",
      "Counter({4: 1769, 0: 1083, 3: 969, 6: 727, 5: 650, 2: 600, 1: 541, 7: 96})\n",
      "Interval for A4\n",
      "Counter({4: 1970, 1: 1229, 3: 1174, 2: 765, 5: 629, 7: 500, 6: 102, 0: 66})\n",
      "Interval for A5\n",
      "Counter({3: 2259, 2: 1063, 7: 1023, 5: 585, 0: 489, 6: 449, 4: 383, 1: 184})\n",
      "Interval for A6\n",
      "Counter({7: 1855, 3: 1315, 6: 777, 4: 764, 5: 639, 0: 528, 2: 436, 1: 121})\n",
      "Interval for A7\n",
      "Counter({4: 1313, 0: 1027, 1: 894, 5: 848, 2: 845, 6: 724, 3: 692, 7: 92})\n",
      "Interval for A8\n",
      "Counter({5: 1958, 1: 1062, 3: 887, 4: 711, 6: 681, 7: 550, 2: 521, 0: 65})\n",
      "Interval for A9\n",
      "Counter({4: 2392, 7: 982, 5: 858, 2: 685, 0: 499, 6: 453, 3: 383, 1: 183})\n",
      "Interval for A10\n",
      "Counter({7: 1818, 3: 1218, 4: 782, 6: 760, 5: 652, 0: 544, 1: 508, 2: 153})\n",
      "Interval for A11\n",
      "Counter({5: 1597, 0: 1044, 6: 968, 1: 915, 3: 730, 2: 563, 4: 533, 7: 85})\n",
      "Interval for A12\n",
      "Counter({5: 1376, 4: 1292, 1: 1193, 3: 868, 6: 677, 7: 539, 2: 421, 0: 69})\n",
      "Interval for A13\n",
      "Counter({3: 2343, 7: 1032, 2: 733, 1: 535, 4: 470, 6: 454, 0: 447, 5: 421})\n",
      "Interval for A14\n",
      "Counter({7: 1799, 4: 1698, 5: 969, 6: 834, 0: 525, 2: 400, 1: 116, 3: 94})\n",
      "Interval for A15\n",
      "Counter({5: 1266, 6: 1147, 0: 1007, 4: 955, 1: 884, 2: 564, 3: 519, 7: 93})\n",
      "Interval for A16\n",
      "Counter({5: 1684, 1: 1140, 4: 1123, 2: 821, 3: 619, 7: 553, 6: 400, 0: 95})\n",
      "Interval for A17\n",
      "Counter({3: 1737, 4: 1091, 2: 1014, 7: 1003, 0: 503, 6: 448, 5: 409, 1: 230})\n",
      "Interval for A18\n",
      "Counter({7: 2218, 3: 1580, 5: 753, 0: 536, 2: 516, 6: 403, 4: 313, 1: 116})\n",
      "Interval for A19\n",
      "Counter({5: 1758, 1: 1159, 6: 1139, 2: 753, 4: 666, 3: 591, 0: 278, 7: 91})\n",
      "Interval for A20\n",
      "Counter({6: 1210, 1: 1184, 5: 1073, 3: 1047, 4: 908, 7: 551, 2: 394, 0: 68})\n",
      "Interval for A21\n",
      "Counter({3: 1790, 2: 1069, 7: 974, 5: 846, 4: 626, 0: 509, 6: 444, 1: 177})\n",
      "Interval for A22\n",
      "Counter({7: 1823, 3: 1243, 4: 797, 6: 758, 5: 621, 0: 587, 1: 462, 2: 144})\n",
      "Interval for A23\n",
      "Counter({5: 1740, 1: 1325, 6: 1132, 3: 853, 4: 663, 2: 500, 0: 138, 7: 84})\n",
      "Interval for A24\n",
      "Counter({5: 1561, 1: 1199, 4: 882, 2: 765, 6: 713, 3: 703, 7: 544, 0: 68})\n",
      "Interval for A25\n",
      "Counter({3: 2358, 7: 805, 2: 725, 6: 657, 4: 610, 0: 501, 1: 490, 5: 289})\n",
      "Interval for A26\n",
      "Counter({3: 1699, 7: 1630, 4: 999, 0: 573, 5: 539, 6: 444, 1: 427, 2: 124})\n",
      "Interval for A27\n",
      "Counter({5: 1757, 1: 1251, 6: 1128, 3: 1094, 2: 481, 4: 469, 0: 161, 7: 94})\n",
      "Interval for A28\n",
      "Counter({6: 1184, 4: 1118, 1: 1048, 2: 942, 5: 872, 3: 624, 7: 579, 0: 68})\n",
      "Interval for A29\n",
      "Counter({3: 2394, 7: 923, 2: 738, 1: 507, 6: 503, 0: 500, 4: 457, 5: 413})\n",
      "Interval for A30\n",
      "Counter({7: 1849, 4: 1721, 5: 961, 6: 748, 0: 534, 2: 328, 1: 163, 3: 131})\n",
      "Interval for A31\n",
      "Counter({5: 1751, 1: 1415, 6: 1138, 3: 816, 2: 743, 4: 457, 7: 87, 0: 28})\n",
      "Interval for A32\n",
      "Counter({3: 1609, 1: 1183, 5: 1162, 4: 1058, 2: 744, 7: 509, 6: 101, 0: 69})\n",
      "Interval for A33\n",
      "Counter({3: 1777, 4: 1097, 2: 925, 7: 747, 5: 619, 0: 501, 6: 425, 1: 344})\n",
      "Interval for A34\n",
      "Counter({3: 1719, 6: 1197, 4: 978, 7: 840, 0: 581, 5: 522, 1: 391, 2: 207})\n",
      "Interval for A35\n",
      "Counter({5: 1747, 1: 1307, 6: 1118, 3: 829, 2: 740, 4: 446, 0: 164, 7: 84})\n",
      "Interval for A36\n",
      "Counter({6: 1200, 1: 1199, 5: 1073, 4: 897, 2: 754, 3: 690, 7: 551, 0: 71})\n"
     ]
    }
   ],
   "source": [
    "print('Frequency for iris with 8 Intervals')\n",
    "for i in num_list8:\n",
    "    print('Interval for ' + i)\n",
    "    print(Counter(satimage8[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd8cdde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency for iris with 10 Intervals\n",
      "Interval for A1\n",
      "Counter({5: 1324, 9: 1048, 4: 921, 2: 622, 6: 563, 0: 484, 8: 461, 7: 419, 3: 372, 1: 221})\n",
      "Interval for A2\n",
      "Counter({9: 1893, 5: 1061, 8: 773, 7: 658, 4: 588, 0: 485, 2: 393, 6: 314, 3: 184, 1: 86})\n",
      "Interval for A3\n",
      "Counter({6: 1769, 1: 974, 8: 727, 7: 650, 3: 600, 2: 541, 4: 529, 5: 440, 0: 109, 9: 96})\n",
      "Interval for A4\n",
      "Counter({1: 1229, 5: 1207, 2: 765, 6: 763, 7: 629, 3: 624, 4: 550, 9: 500, 8: 102, 0: 66})\n",
      "Interval for A5\n",
      "Counter({5: 1321, 9: 1023, 4: 938, 2: 677, 7: 585, 0: 489, 8: 449, 3: 386, 6: 383, 1: 184})\n",
      "Interval for A6\n",
      "Counter({4: 1223, 8: 986, 9: 869, 7: 777, 5: 764, 6: 639, 0: 528, 2: 436, 1: 121, 3: 92})\n",
      "Interval for A7\n",
      "Counter({5: 1313, 2: 894, 1: 870, 6: 848, 3: 845, 4: 692, 7: 474, 8: 250, 0: 157, 9: 92})\n",
      "Interval for A8\n",
      "Counter({5: 1217, 1: 1062, 3: 887, 6: 741, 4: 711, 7: 627, 9: 550, 2: 521, 0: 65, 8: 54})\n",
      "Interval for A9\n",
      "Counter({4: 1471, 9: 982, 5: 921, 2: 685, 0: 499, 8: 453, 6: 453, 7: 405, 3: 383, 1: 183})\n",
      "Interval for A10\n",
      "Counter({4: 1218, 8: 976, 9: 842, 5: 782, 7: 760, 6: 652, 0: 544, 2: 390, 3: 153, 1: 118})\n",
      "Interval for A11\n",
      "Counter({6: 1597, 1: 932, 2: 915, 4: 730, 3: 563, 5: 533, 7: 496, 8: 472, 0: 112, 9: 85})\n",
      "Interval for A12\n",
      "Counter({6: 1376, 1: 1193, 3: 868, 4: 730, 5: 562, 7: 541, 9: 539, 2: 421, 8: 136, 0: 69})\n",
      "Interval for A13\n",
      "Counter({5: 1594, 9: 1032, 4: 749, 3: 733, 6: 470, 8: 454, 0: 447, 2: 426, 7: 421, 1: 109})\n",
      "Interval for A14\n",
      "Counter({9: 1799, 4: 1698, 6: 651, 0: 525, 8: 428, 7: 406, 2: 400, 5: 318, 1: 116, 3: 94})\n",
      "Interval for A15\n",
      "Counter({6: 1266, 5: 955, 7: 885, 2: 884, 1: 733, 3: 564, 4: 519, 0: 274, 8: 262, 9: 93})\n",
      "Interval for A16\n",
      "Counter({1: 1140, 5: 1123, 7: 895, 6: 789, 4: 619, 9: 553, 3: 439, 8: 400, 2: 382, 0: 95})\n",
      "Interval for A17\n",
      "Counter({4: 1737, 9: 1003, 2: 626, 5: 548, 6: 543, 0: 503, 8: 448, 7: 409, 3: 388, 1: 230})\n",
      "Interval for A18\n",
      "Counter({4: 1580, 8: 1349, 9: 869, 6: 753, 0: 536, 7: 403, 2: 325, 5: 313, 3: 191, 1: 116})\n",
      "Interval for A19\n",
      "Counter({6: 1176, 1: 1159, 7: 881, 2: 753, 4: 666, 3: 591, 5: 582, 0: 278, 8: 258, 9: 91})\n",
      "Interval for A20\n",
      "Counter({1: 1184, 5: 1073, 3: 1047, 4: 908, 6: 804, 9: 507, 7: 406, 2: 394, 0: 68, 8: 44})\n",
      "Interval for A21\n",
      "Counter({4: 1790, 9: 974, 2: 691, 5: 626, 0: 509, 6: 450, 8: 444, 7: 396, 3: 378, 1: 177})\n",
      "Interval for A22\n",
      "Counter({4: 1243, 8: 976, 9: 847, 5: 797, 7: 758, 6: 621, 0: 542, 2: 462, 3: 144, 1: 45})\n",
      "Interval for A23\n",
      "Counter({7: 1171, 8: 1132, 4: 853, 2: 780, 5: 663, 6: 569, 1: 545, 3: 500, 0: 138, 9: 84})\n",
      "Interval for A24\n",
      "Counter({6: 1561, 5: 882, 3: 765, 4: 703, 1: 616, 2: 583, 7: 578, 9: 544, 8: 135, 0: 68})\n",
      "Interval for A25\n",
      "Counter({5: 1399, 4: 959, 9: 805, 3: 725, 8: 657, 6: 610, 0: 501, 2: 305, 7: 289, 1: 185})\n",
      "Interval for A26\n",
      "Counter({4: 1699, 9: 1630, 6: 586, 0: 573, 7: 539, 8: 444, 5: 413, 2: 309, 3: 124, 1: 118})\n",
      "Interval for A27\n",
      "Counter({1: 1251, 5: 1166, 3: 1094, 7: 871, 6: 591, 2: 481, 4: 469, 8: 257, 0: 161, 9: 94})\n",
      "Interval for A28\n",
      "Counter({4: 1118, 1: 1048, 2: 942, 5: 872, 6: 809, 3: 624, 9: 498, 7: 375, 8: 81, 0: 68})\n",
      "Interval for A29\n",
      "Counter({5: 1440, 4: 954, 9: 923, 3: 738, 8: 503, 0: 500, 6: 457, 7: 413, 2: 322, 1: 185})\n",
      "Interval for A30\n",
      "Counter({5: 1196, 8: 977, 6: 961, 9: 872, 7: 748, 0: 534, 4: 525, 2: 328, 1: 163, 3: 131})\n",
      "Interval for A31\n",
      "Counter({6: 1751, 4: 816, 7: 810, 3: 743, 2: 718, 1: 697, 5: 457, 8: 328, 9: 87, 0: 28})\n",
      "Interval for A32\n",
      "Counter({1: 1183, 5: 1058, 4: 912, 6: 776, 2: 744, 3: 697, 9: 509, 7: 386, 8: 101, 0: 69})\n",
      "Interval for A33\n",
      "Counter({4: 1777, 9: 747, 5: 641, 7: 619, 0: 501, 3: 498, 6: 456, 2: 427, 8: 425, 1: 344})\n",
      "Interval for A34\n",
      "Counter({8: 1197, 4: 1101, 9: 840, 6: 647, 3: 618, 0: 581, 7: 522, 1: 391, 5: 331, 2: 207})\n",
      "Interval for A35\n",
      "Counter({6: 1747, 7: 862, 4: 829, 2: 791, 3: 740, 1: 516, 5: 446, 8: 256, 0: 164, 9: 84})\n",
      "Interval for A36\n",
      "Counter({1: 1199, 6: 1073, 5: 897, 7: 811, 4: 690, 9: 551, 2: 397, 8: 389, 3: 357, 0: 71})\n"
     ]
    }
   ],
   "source": [
    "print('Frequency for iris with 10 Intervals')\n",
    "for i in num_list10:\n",
    "    print('Interval for ' + i)\n",
    "    print(Counter(satimage10[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25638c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency for iris with 15 Intervals\n",
      "Interval for A1\n",
      "Counter({13: 934, 7: 921, 8: 804, 10: 563, 9: 520, 12: 461, 11: 419, 6: 372, 5: 291, 3: 267, 0: 247, 1: 237, 2: 221, 14: 114, 4: 64})\n",
      "Interval for A2\n",
      "Counter({6: 1061, 12: 998, 13: 808, 5: 588, 0: 485, 10: 417, 2: 393, 8: 378, 11: 356, 7: 314, 9: 280, 4: 101, 14: 87, 1: 86, 3: 83})\n",
      "Interval for A3\n",
      "Counter({10: 1254, 11: 650, 1: 547, 7: 529, 9: 515, 12: 471, 8: 440, 2: 427, 6: 328, 3: 326, 5: 272, 13: 256, 4: 215, 0: 109, 14: 96})\n",
      "Interval for A4\n",
      "Counter({9: 763, 8: 647, 5: 624, 2: 618, 1: 611, 7: 560, 6: 550, 14: 500, 4: 446, 11: 344, 3: 319, 10: 285, 0: 66, 12: 54, 13: 48})\n",
      "Interval for A5\n",
      "Counter({6: 938, 7: 813, 14: 514, 13: 509, 8: 508, 12: 449, 5: 386, 9: 383, 4: 360, 3: 317, 10: 298, 11: 287, 0: 259, 1: 230, 2: 184})\n",
      "Interval for A6\n",
      "Counter({12: 986, 13: 789, 6: 703, 9: 639, 0: 528, 5: 520, 7: 440, 3: 436, 10: 418, 11: 359, 8: 324, 4: 92, 14: 80, 2: 78, 1: 43})\n",
      "Interval for A7\n",
      "Counter({9: 1313, 2: 870, 6: 519, 3: 487, 12: 474, 8: 472, 10: 453, 4: 407, 11: 395, 5: 326, 13: 250, 7: 220, 1: 129, 14: 92, 0: 28})\n",
      "Interval for A8\n",
      "Counter({9: 741, 6: 711, 8: 654, 2: 582, 7: 563, 5: 522, 3: 521, 1: 480, 14: 397, 4: 365, 11: 340, 10: 287, 13: 153, 0: 65, 12: 54})\n",
      "Interval for A9\n",
      "Counter({9: 921, 7: 790, 8: 681, 13: 629, 12: 453, 10: 453, 11: 405, 6: 383, 5: 363, 14: 353, 4: 322, 0: 258, 1: 203, 3: 183, 2: 38})\n",
      "Interval for A10\n",
      "Counter({6: 1218, 12: 976, 13: 774, 9: 652, 7: 463, 10: 408, 0: 405, 4: 390, 11: 352, 8: 319, 5: 153, 1: 139, 3: 80, 14: 68, 2: 38})\n",
      "Interval for A11\n",
      "Counter({9: 1013, 2: 711, 10: 584, 5: 563, 8: 533, 11: 496, 3: 494, 7: 449, 4: 421, 6: 281, 13: 252, 1: 221, 12: 220, 0: 112, 14: 85})\n",
      "Interval for A12\n",
      "Counter({9: 914, 2: 720, 8: 562, 7: 559, 11: 541, 5: 510, 1: 473, 10: 462, 3: 421, 14: 411, 4: 358, 6: 171, 12: 136, 13: 128, 0: 69})\n",
      "Interval for A13\n",
      "Counter({8: 971, 13: 797, 7: 749, 9: 623, 10: 470, 12: 454, 11: 421, 6: 373, 5: 360, 4: 261, 0: 244, 14: 235, 1: 203, 3: 165, 2: 109})\n",
      "Interval for A14\n",
      "Counter({6: 1110, 12: 1064, 13: 649, 5: 588, 0: 525, 11: 428, 10: 406, 3: 400, 8: 382, 7: 318, 9: 269, 4: 94, 14: 86, 2: 77, 1: 39})\n",
      "Interval for A15\n",
      "Counter({9: 798, 2: 733, 8: 573, 5: 564, 6: 519, 12: 482, 4: 481, 10: 468, 11: 403, 3: 403, 7: 382, 13: 262, 1: 247, 14: 93, 0: 27})\n",
      "Interval for A16\n",
      "Counter({8: 789, 7: 757, 2: 699, 5: 619, 9: 587, 14: 464, 1: 441, 4: 439, 3: 382, 6: 366, 11: 346, 10: 308, 0: 95, 13: 89, 12: 54})\n",
      "Interval for A17\n",
      "Counter({7: 994, 6: 743, 8: 548, 9: 543, 14: 510, 13: 493, 12: 448, 5: 388, 4: 354, 11: 280, 3: 272, 0: 258, 1: 245, 2: 230, 10: 129})\n",
      "Interval for A18\n",
      "Counter({12: 999, 6: 974, 13: 793, 5: 606, 0: 536, 10: 403, 9: 383, 8: 370, 11: 350, 3: 325, 7: 313, 4: 191, 14: 76, 2: 75, 1: 41})\n",
      "Interval for A19\n",
      "Counter({10: 1176, 2: 759, 6: 591, 9: 582, 12: 477, 7: 439, 5: 421, 11: 404, 3: 400, 4: 332, 13: 258, 1: 249, 8: 227, 14: 91, 0: 29})\n",
      "Interval for A20\n",
      "Counter({9: 1073, 10: 804, 6: 616, 2: 593, 3: 562, 7: 545, 14: 507, 5: 431, 4: 394, 8: 363, 11: 272, 12: 134, 0: 68, 13: 44, 1: 29})\n",
      "Interval for A21\n",
      "Counter({6: 777, 7: 698, 9: 626, 13: 547, 10: 450, 12: 444, 14: 427, 11: 396, 5: 378, 4: 375, 3: 316, 8: 315, 0: 260, 1: 249, 2: 177})\n",
      "Interval for A22\n",
      "Counter({12: 976, 13: 777, 6: 641, 9: 621, 5: 602, 0: 542, 7: 479, 10: 406, 11: 352, 3: 340, 8: 318, 4: 144, 2: 122, 14: 70, 1: 45})\n",
      "Interval for A23\n",
      "Counter({10: 1171, 9: 569, 5: 562, 1: 545, 4: 500, 8: 454, 3: 423, 12: 412, 11: 395, 2: 357, 13: 325, 6: 291, 7: 209, 0: 138, 14: 84})\n",
      "Interval for A24\n",
      "Counter({8: 829, 9: 732, 5: 703, 1: 616, 2: 583, 14: 544, 6: 533, 3: 415, 4: 350, 7: 349, 10: 308, 11: 270, 12: 106, 0: 68, 13: 29})\n",
      "Interval for A25\n",
      "Counter({6: 959, 14: 805, 7: 785, 8: 614, 5: 483, 12: 452, 9: 326, 3: 305, 11: 289, 10: 284, 1: 252, 0: 249, 4: 242, 13: 205, 2: 185})\n",
      "Interval for A26\n",
      "Counter({6: 1174, 12: 913, 13: 626, 10: 539, 5: 525, 11: 444, 0: 426, 7: 413, 8: 323, 3: 309, 9: 263, 1: 147, 4: 124, 2: 118, 14: 91})\n",
      "Interval for A27\n",
      "Counter({3: 760, 9: 667, 10: 591, 5: 574, 6: 520, 8: 499, 2: 491, 4: 481, 7: 469, 12: 467, 11: 404, 13: 257, 1: 134, 14: 94, 0: 27})\n",
      "Interval for A28\n",
      "Counter({1: 1048, 6: 934, 8: 872, 9: 504, 14: 498, 2: 494, 3: 448, 5: 331, 10: 305, 4: 293, 11: 269, 7: 184, 12: 106, 13: 81, 0: 68})\n",
      "Interval for A29\n",
      "Counter({6: 954, 7: 798, 8: 642, 13: 553, 4: 549, 9: 457, 10: 413, 14: 370, 3: 322, 12: 288, 0: 252, 1: 248, 11: 215, 5: 189, 2: 185})\n",
      "Interval for A30\n",
      "Counter({6: 1196, 13: 790, 8: 642, 0: 534, 9: 525, 5: 525, 12: 499, 11: 478, 3: 328, 7: 319, 10: 223, 4: 131, 2: 124, 14: 82, 1: 39})\n",
      "Interval for A31\n",
      "Counter({6: 816, 3: 718, 10: 595, 9: 593, 8: 563, 2: 560, 7: 457, 4: 406, 11: 406, 12: 404, 5: 337, 13: 328, 1: 137, 14: 87, 0: 28})\n",
      "Interval for A32\n",
      "Counter({2: 1138, 8: 1058, 7: 912, 14: 509, 10: 497, 11: 386, 3: 378, 5: 367, 4: 366, 6: 330, 9: 279, 0: 69, 13: 51, 12: 50, 1: 45})\n",
      "Interval for A33\n",
      "Counter({7: 964, 8: 813, 14: 747, 9: 641, 10: 456, 4: 427, 13: 425, 11: 405, 5: 309, 0: 259, 1: 242, 12: 214, 2: 192, 6: 189, 3: 152})\n",
      "Interval for A34\n",
      "Counter({6: 1101, 12: 770, 13: 770, 8: 647, 5: 618, 11: 427, 0: 414, 10: 392, 7: 331, 3: 314, 4: 207, 1: 167, 9: 130, 2: 77, 14: 70})\n",
      "Interval for A35\n",
      "Counter({2: 791, 5: 618, 11: 617, 9: 595, 10: 593, 8: 559, 1: 516, 7: 446, 3: 405, 4: 335, 13: 256, 12: 245, 6: 211, 0: 164, 14: 84})\n",
      "Interval for A36\n",
      "Counter({8: 1073, 7: 897, 3: 721, 6: 690, 9: 500, 14: 410, 4: 397, 2: 372, 5: 357, 11: 342, 10: 311, 13: 141, 1: 106, 0: 71, 12: 47})\n"
     ]
    }
   ],
   "source": [
    "print('Frequency for iris with 15 Intervals')\n",
    "for i in num_list15:\n",
    "    print('Interval for ' + i)\n",
    "    print(Counter(satimage15[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2d79abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6435 entries, 0 to 6434\n",
      "Data columns (total 37 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   A1      6435 non-null   int64\n",
      " 1   A2      6435 non-null   int64\n",
      " 2   A3      6435 non-null   int64\n",
      " 3   A4      6435 non-null   int64\n",
      " 4   A5      6435 non-null   int64\n",
      " 5   A6      6435 non-null   int64\n",
      " 6   A7      6435 non-null   int64\n",
      " 7   A8      6435 non-null   int64\n",
      " 8   A9      6435 non-null   int64\n",
      " 9   A10     6435 non-null   int64\n",
      " 10  A11     6435 non-null   int64\n",
      " 11  A12     6435 non-null   int64\n",
      " 12  A13     6435 non-null   int64\n",
      " 13  A14     6435 non-null   int64\n",
      " 14  A15     6435 non-null   int64\n",
      " 15  A16     6435 non-null   int64\n",
      " 16  A17     6435 non-null   int64\n",
      " 17  A18     6435 non-null   int64\n",
      " 18  A19     6435 non-null   int64\n",
      " 19  A20     6435 non-null   int64\n",
      " 20  A21     6435 non-null   int64\n",
      " 21  A22     6435 non-null   int64\n",
      " 22  A23     6435 non-null   int64\n",
      " 23  A24     6435 non-null   int64\n",
      " 24  A25     6435 non-null   int64\n",
      " 25  A26     6435 non-null   int64\n",
      " 26  A27     6435 non-null   int64\n",
      " 27  A28     6435 non-null   int64\n",
      " 28  A29     6435 non-null   int64\n",
      " 29  A30     6435 non-null   int64\n",
      " 30  A31     6435 non-null   int64\n",
      " 31  A32     6435 non-null   int64\n",
      " 32  A33     6435 non-null   int64\n",
      " 33  A34     6435 non-null   int64\n",
      " 34  A35     6435 non-null   int64\n",
      " 35  A36     6435 non-null   int64\n",
      " 36  class   6435 non-null   int64\n",
      "dtypes: int64(37)\n",
      "memory usage: 1.8 MB\n"
     ]
    }
   ],
   "source": [
    "satimage6.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d563125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>...</th>\n",
       "      <th>A28</th>\n",
       "      <th>A29</th>\n",
       "      <th>A30</th>\n",
       "      <th>A31</th>\n",
       "      <th>A32</th>\n",
       "      <th>A33</th>\n",
       "      <th>A34</th>\n",
       "      <th>A35</th>\n",
       "      <th>A36</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4435</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4436</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4437</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4438</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4439</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6430</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6431</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6432</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6433</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6434</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      A1  A2  A3  A4  A5  A6  A7  A8  A9  A10  ...  A28  A29  A30  A31  A32  \\\n",
       "4435   4   5   3   2   4   5   3   2   4    5  ...    3    3    5    3    4   \n",
       "4436   3   5   3   2   4   5   4   3   4    5  ...    3    3    5    3    4   \n",
       "4437   4   4   3   2   4   4   3   1   4    4  ...    3    3    4    2    3   \n",
       "4438   3   4   3   2   4   4   3   1   4    4  ...    3    3    4    2    3   \n",
       "4439   3   4   3   2   4   4   3   1   4    3  ...    2    3    4    2    3   \n",
       "...   ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...  ...  ...  ...  ...  ...   \n",
       "6430   1   3   2   3   3   3   3   3   3    2  ...    4    2    3    3    4   \n",
       "6431   2   2   2   3   2   2   2   3   2    2  ...    3    2    3    2    4   \n",
       "6432   1   2   1   2   2   2   2   2   2    1  ...    3    1    3    2    3   \n",
       "6433   1   2   1   2   2   2   2   2   2    1  ...    2    1    3    2    3   \n",
       "6434   1   2   1   2   2   2   4   4   2    1  ...    2    1    3    2    2   \n",
       "\n",
       "      A33  A34  A35  A36  class  \n",
       "4435    4    5    3    4      2  \n",
       "4436    4    5    3    3      2  \n",
       "4437    4    4    2    3      3  \n",
       "4438    4    4    2    3      3  \n",
       "4439    3    4    2    3      3  \n",
       "...   ...  ...  ...  ...    ...  \n",
       "6430    2    3    3    4      0  \n",
       "6431    2    3    2    3      0  \n",
       "6432    2    3    2    3      4  \n",
       "6433    1    3    2    2      4  \n",
       "6434    2    2    3    4      4  \n",
       "\n",
       "[2000 rows x 37 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make train test split\n",
    "train= satimage6.head(4435)\n",
    "test= satimage6.tail(2000)\n",
    "train\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb0320e",
   "metadata": {},
   "source": [
    "# 1. Categorical Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1cfced",
   "metadata": {},
   "source": [
    "## 1.1 6 Intervals from ChiMerge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1325e346",
   "metadata": {},
   "source": [
    "## 1.1 debug version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3a31e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "train= satimage6.head(4435)\n",
    "test= satimage6.tail(2000)\n",
    "X_train = train.drop('class', axis=1)\n",
    "y_train = train['class']\n",
    "X_test = test.drop('class', axis=1)\n",
    "y_test = test['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ced3d839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0430142879486084\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "cnb = CategoricalNB()\n",
    "cnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_cnb = cnb.predict(X_test)\n",
    "y_prob_pred_cnb = cnb.predict_proba(X_test)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start) # Total time execution for this sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e4a26e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoricalNB\n",
      "=========================\n",
      "Misclassified samples: 376\n",
      "Accuracy: 0.81\n",
      "=========================\n",
      "Recall score :  0.812\n",
      "Precision score :  0.812\n",
      "F1 score :  0.8119999999999999\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.85      0.88       461\n",
      "           1       0.98      0.92      0.95       224\n",
      "           2       0.91      0.89      0.90       397\n",
      "           3       0.48      0.72      0.58       211\n",
      "           4       0.68      0.71      0.69       237\n",
      "           5       0.86      0.74      0.80       470\n",
      "\n",
      "    accuracy                           0.81      2000\n",
      "   macro avg       0.80      0.81      0.80      2000\n",
      "weighted avg       0.83      0.81      0.82      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# how did our model perform?\n",
    "count_misclassified = (y_test != y_pred_cnb).sum()\n",
    "print(\"CategoricalNB\")\n",
    "print(\"=\" * 25)\n",
    "print('Misclassified samples: {}'.format(count_misclassified))\n",
    "accuracy = accuracy_score(y_test, y_pred_cnb)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_cnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3844d1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.186\n",
      "Average bias: 0.187\n",
      "Average variance: 0.013\n",
      "Sklearn 0-1 loss: 0.188\n"
     ]
    }
   ],
   "source": [
    "# calculate classification bias and variance\n",
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#We will load the Boston house dataset for our example\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import metrics\n",
    "\n",
    "# y_pred_cnb\n",
    "# y_prob_pred_cnb\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        cnb, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_cnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a86152",
   "metadata": {},
   "source": [
    "## 1.1 script version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99b94bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoricalNB\n",
      "=========================\n",
      "Misclassified samples: 376\n",
      "Accuracy: 0.81\n",
      "=========================\n",
      "Recall score :  0.812\n",
      "Precision score :  0.812\n",
      "F1 score :  0.8119999999999999\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.85      0.88       461\n",
      "           1       0.98      0.92      0.95       224\n",
      "           2       0.91      0.89      0.90       397\n",
      "           3       0.48      0.72      0.58       211\n",
      "           4       0.68      0.71      0.69       237\n",
      "           5       0.86      0.74      0.80       470\n",
      "\n",
      "    accuracy                           0.81      2000\n",
      "   macro avg       0.80      0.81      0.80      2000\n",
      "weighted avg       0.83      0.81      0.82      2000\n",
      "\n",
      "Computation time:\n",
      "0.04484415054321289\n"
     ]
    }
   ],
   "source": [
    "# make test & train split\n",
    "train= satimage6.head(4435)\n",
    "test= satimage6.tail(2000)\n",
    "X_train = train.drop('class', axis=1)\n",
    "y_train = train['class']\n",
    "X_test = test.drop('class', axis=1)\n",
    "y_test = test['class']\n",
    "\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "cnb = CategoricalNB()\n",
    "cnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_cnb = cnb.predict(X_test)\n",
    "y_prob_pred_cnb = cnb.predict_proba(X_test)\n",
    "\n",
    "# how did our model perform?\n",
    "count_misclassified = (y_test != y_pred_cnb).sum()\n",
    "print(\"CategoricalNB\")\n",
    "print(\"=\" * 25)\n",
    "print('Misclassified samples: {}'.format(count_misclassified))\n",
    "accuracy = accuracy_score(y_test, y_pred_cnb)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_cnb))\n",
    "\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82d4dfb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.186\n",
      "Average bias: 0.187\n",
      "Average variance: 0.013\n",
      "Sklearn 0-1 loss: 0.188\n"
     ]
    }
   ],
   "source": [
    "# calculate classification bias and variance\n",
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#We will load the Boston house dataset for our example\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import metrics\n",
    "\n",
    "# y_pred_cnb\n",
    "# y_prob_pred_cnb\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        cnb, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_cnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf64c978",
   "metadata": {},
   "source": [
    "## 1.2 8 Intervals from ChiMerge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91a2a331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoricalNB\n",
      "=========================\n",
      "Misclassified samples: 362\n",
      "Accuracy: 0.82\n",
      "=========================\n",
      "Recall score :  0.819\n",
      "Precision score :  0.819\n",
      "F1 score :  0.819\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90       461\n",
      "           1       0.98      0.92      0.94       224\n",
      "           2       0.91      0.89      0.90       397\n",
      "           3       0.48      0.73      0.58       211\n",
      "           4       0.71      0.71      0.71       237\n",
      "           5       0.87      0.75      0.80       470\n",
      "\n",
      "    accuracy                           0.82      2000\n",
      "   macro avg       0.81      0.81      0.81      2000\n",
      "weighted avg       0.84      0.82      0.83      2000\n",
      "\n",
      "Computation time:\n",
      "0.03703451156616211\n"
     ]
    }
   ],
   "source": [
    "# make test & train split\n",
    "train= satimage8.head(4435)\n",
    "test= satimage8.tail(2000)\n",
    "X_train = train.drop('class', axis=1)\n",
    "y_train = train['class']\n",
    "X_test = test.drop('class', axis=1)\n",
    "y_test = test['class']\n",
    "\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "cnb = CategoricalNB()\n",
    "cnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_cnb = cnb.predict(X_test)\n",
    "y_prob_pred_cnb = cnb.predict_proba(X_test)\n",
    "\n",
    "# how did our model perform?\n",
    "count_misclassified = (y_test != y_pred_cnb).sum()\n",
    "print(\"CategoricalNB\")\n",
    "print(\"=\" * 25)\n",
    "print('Misclassified samples: {}'.format(count_misclassified))\n",
    "accuracy = accuracy_score(y_test, y_pred_cnb)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_cnb))\n",
    "\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fed455dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.180\n",
      "Average bias: 0.180\n",
      "Average variance: 0.010\n",
      "Sklearn 0-1 loss: 0.181\n"
     ]
    }
   ],
   "source": [
    "# calculate classification bias and variance\n",
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#We will load the Boston house dataset for our example\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import metrics\n",
    "\n",
    "# y_pred_cnb\n",
    "# y_prob_pred_cnb\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        cnb, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_cnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd86461",
   "metadata": {},
   "source": [
    "## 1.3 10 Intervals from ChiMerge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3b9b6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoricalNB\n",
      "=========================\n",
      "Misclassified samples: 355\n",
      "Accuracy: 0.82\n",
      "=========================\n",
      "Recall score :  0.8225\n",
      "Precision score :  0.8225\n",
      "F1 score :  0.8225\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90       461\n",
      "           1       0.98      0.92      0.95       224\n",
      "           2       0.91      0.89      0.90       397\n",
      "           3       0.49      0.72      0.58       211\n",
      "           4       0.72      0.73      0.73       237\n",
      "           5       0.87      0.75      0.81       470\n",
      "\n",
      "    accuracy                           0.82      2000\n",
      "   macro avg       0.81      0.82      0.81      2000\n",
      "weighted avg       0.84      0.82      0.83      2000\n",
      "\n",
      "Computation time:\n",
      "0.03748345375061035\n"
     ]
    }
   ],
   "source": [
    "train= satimage10.head(4435)\n",
    "test= satimage10.tail(2000)\n",
    "X_train = train.drop('class', axis=1)\n",
    "y_train = train['class']\n",
    "X_test = test.drop('class', axis=1)\n",
    "y_test = test['class']\n",
    "\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "cnb = CategoricalNB()\n",
    "cnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_cnb = cnb.predict(X_test)\n",
    "y_prob_pred_cnb = cnb.predict_proba(X_test)\n",
    "\n",
    "# how did our model perform?\n",
    "count_misclassified = (y_test != y_pred_cnb).sum()\n",
    "print(\"CategoricalNB\")\n",
    "print(\"=\" * 25)\n",
    "print('Misclassified samples: {}'.format(count_misclassified))\n",
    "accuracy = accuracy_score(y_test, y_pred_cnb)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_cnb))\n",
    "\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b77b8fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.180\n",
      "Average bias: 0.177\n",
      "Average variance: 0.012\n",
      "Sklearn 0-1 loss: 0.177\n"
     ]
    }
   ],
   "source": [
    "# calculate classification bias and variance\n",
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#We will load the Boston house dataset for our example\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import metrics\n",
    "\n",
    "# y_pred_cnb\n",
    "# y_prob_pred_cnb\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        cnb, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_cnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b03574",
   "metadata": {},
   "source": [
    "## 1.4 15 Intervals from ChiMerge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eac24eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoricalNB\n",
      "=========================\n",
      "Misclassified samples: 357\n",
      "Accuracy: 0.82\n",
      "=========================\n",
      "Recall score :  0.8215\n",
      "Precision score :  0.8215\n",
      "F1 score :  0.8215\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.89      0.90       461\n",
      "           1       0.98      0.92      0.95       224\n",
      "           2       0.91      0.89      0.90       397\n",
      "           3       0.48      0.71      0.58       211\n",
      "           4       0.74      0.73      0.73       237\n",
      "           5       0.85      0.75      0.80       470\n",
      "\n",
      "    accuracy                           0.82      2000\n",
      "   macro avg       0.81      0.81      0.81      2000\n",
      "weighted avg       0.84      0.82      0.83      2000\n",
      "\n",
      "0.041306257247924805\n"
     ]
    }
   ],
   "source": [
    "train= satimage15.head(4435)\n",
    "test= satimage15.tail(2000)\n",
    "X_train = train.drop('class', axis=1)\n",
    "y_train = train['class']\n",
    "X_test = test.drop('class', axis=1)\n",
    "y_test = test['class']\n",
    "\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "cnb = CategoricalNB()\n",
    "cnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_cnb = cnb.predict(X_test)\n",
    "y_prob_pred_cnb = cnb.predict_proba(X_test)\n",
    "\n",
    "# how did our model perform?\n",
    "count_misclassified = (y_test != y_pred_cnb).sum()\n",
    "print(\"CategoricalNB\")\n",
    "print(\"=\" * 25)\n",
    "print('Misclassified samples: {}'.format(count_misclassified))\n",
    "accuracy = accuracy_score(y_test, y_pred_cnb)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_cnb))\n",
    "\n",
    "end = time.time()\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0b14728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.176\n",
      "Average bias: 0.177\n",
      "Average variance: 0.012\n",
      "Sklearn 0-1 loss: 0.178\n"
     ]
    }
   ],
   "source": [
    "# calculate classification bias and variance\n",
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#We will load the Boston house dataset for our example\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import metrics\n",
    "\n",
    "# y_pred_cnb\n",
    "# y_prob_pred_cnb\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        cnb, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_cnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36de93a1",
   "metadata": {},
   "source": [
    "# 2. Decision Tree ID3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5da502c",
   "metadata": {},
   "source": [
    "## 2.1 6 Intervals from ChiMerge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cc6ec6",
   "metadata": {},
   "source": [
    "### Debug version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "efd2a195",
   "metadata": {},
   "outputs": [],
   "source": [
    "train= satimage6.head(4435)\n",
    "test= satimage6.tail(2000)\n",
    "X_train = train.drop('class', axis=1)\n",
    "y_train = train['class']\n",
    "X_test = test.drop('class', axis=1)\n",
    "y_test = test['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b0a2232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation time:\n",
      "1.7056269645690918\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "estimator = Id3Estimator()\n",
    "estimator = estimator.fit(X_train, y_train, check_input=True)\n",
    "#tree = export_graphviz(estimator.tree_, 'tree.dot', y)\n",
    "\n",
    "y_pred_id3 = estimator.predict(X_test)\n",
    "#_prob_pred_id3 = estimator.predict_proba(X_test)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a3dc865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.84\n",
      "=========================\n",
      "Recall score :  0.8425\n",
      "Precision score :  0.8425\n",
      "F1 score :  0.8425\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95       461\n",
      "           1       0.93      0.96      0.95       224\n",
      "           2       0.87      0.88      0.87       397\n",
      "           3       0.54      0.55      0.54       211\n",
      "           4       0.84      0.80      0.82       237\n",
      "           5       0.83      0.80      0.81       470\n",
      "\n",
      "    accuracy                           0.84      2000\n",
      "   macro avg       0.82      0.82      0.82      2000\n",
      "weighted avg       0.84      0.84      0.84      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred_id3)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_id3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1fb0308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.170\n",
      "Average bias: 0.104\n",
      "Average variance: 0.131\n",
      "Sklearn 0-1 loss: 0.157\n"
     ]
    }
   ],
   "source": [
    "# calculate classification bias and variance\n",
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#We will load the Boston house dataset for our example\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import metrics\n",
    "\n",
    "# y_pred_cnb\n",
    "# y_prob_pred_cnb\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        estimator, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b305a740",
   "metadata": {},
   "source": [
    "### script version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6cfce8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.84\n",
      "=========================\n",
      "Recall score :  0.8425\n",
      "Precision score :  0.8425\n",
      "F1 score :  0.8425\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95       461\n",
      "           1       0.93      0.96      0.95       224\n",
      "           2       0.87      0.88      0.87       397\n",
      "           3       0.54      0.55      0.54       211\n",
      "           4       0.84      0.80      0.82       237\n",
      "           5       0.83      0.80      0.81       470\n",
      "\n",
      "    accuracy                           0.84      2000\n",
      "   macro avg       0.82      0.82      0.82      2000\n",
      "weighted avg       0.84      0.84      0.84      2000\n",
      "\n",
      "Computation time:\n",
      "1.7615313529968262\n"
     ]
    }
   ],
   "source": [
    "#make splits\n",
    "train= satimage6.head(4435)\n",
    "test= satimage6.tail(2000)\n",
    "X_train = train.drop('class', axis=1)\n",
    "y_train = train['class']\n",
    "X_test = test.drop('class', axis=1)\n",
    "y_test = test['class']\n",
    "#time recording\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "#build estimator\n",
    "estimator = Id3Estimator()\n",
    "estimator = estimator.fit(X_train, y_train, check_input=True)\n",
    "#tree = export_graphviz(estimator.tree_, 'tree.dot', y)\n",
    "#make predictions\n",
    "y_pred_id3 = estimator.predict(X_test)\n",
    "#_prob_pred_id3 = estimator.predict_proba(X_test)\n",
    "#report performance\n",
    "accuracy = accuracy_score(y_test, y_pred_id3)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "#stop time recoridng\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2421a98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.170\n",
      "Average bias: 0.104\n",
      "Average variance: 0.131\n",
      "Sklearn 0-1 loss: 0.157\n"
     ]
    }
   ],
   "source": [
    "# calculate classification bias and variance\n",
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#We will load the Boston house dataset for our example\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import metrics\n",
    "\n",
    "# y_pred_cnb\n",
    "# y_prob_pred_cnb\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        estimator, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c21b52",
   "metadata": {},
   "source": [
    "## 2.2 8 Intervals from ChiMerge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "011a2f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.85\n",
      "=========================\n",
      "Recall score :  0.8495\n",
      "Precision score :  0.8495\n",
      "F1 score :  0.8495\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       461\n",
      "           1       0.94      0.96      0.95       224\n",
      "           2       0.87      0.83      0.85       397\n",
      "           3       0.56      0.58      0.57       211\n",
      "           4       0.84      0.81      0.83       237\n",
      "           5       0.83      0.83      0.83       470\n",
      "\n",
      "    accuracy                           0.85      2000\n",
      "   macro avg       0.83      0.83      0.83      2000\n",
      "weighted avg       0.85      0.85      0.85      2000\n",
      "\n",
      "Computation time:\n",
      "2.3052749633789062\n"
     ]
    }
   ],
   "source": [
    "#make splits\n",
    "train= satimage8.head(4435)\n",
    "test= satimage8.tail(2000)\n",
    "X_train = train.drop('class', axis=1)\n",
    "y_train = train['class']\n",
    "X_test = test.drop('class', axis=1)\n",
    "y_test = test['class']\n",
    "#time recording\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "#build estimator\n",
    "estimator = Id3Estimator()\n",
    "estimator = estimator.fit(X_train, y_train)\n",
    "#tree = export_graphviz(estimator.tree_, 'tree.dot', y)\n",
    "#make predictions\n",
    "y_pred_id3 = estimator.predict(X_test)\n",
    "#_prob_pred_id3 = estimator.predict_proba(X_test)\n",
    "#report performance\n",
    "accuracy = accuracy_score(y_test, y_pred_id3)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "#stop time recoridng\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6d626911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.169\n",
      "Average bias: 0.103\n",
      "Average variance: 0.133\n",
      "Sklearn 0-1 loss: 0.150\n"
     ]
    }
   ],
   "source": [
    "# calculate classification bias and variance\n",
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#We will load the Boston house dataset for our example\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import metrics\n",
    "\n",
    "# y_pred_cnb\n",
    "# y_prob_pred_cnb\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        estimator, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687f1ea3",
   "metadata": {},
   "source": [
    "## 2.3 10 Intervals from ChiMerge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82063c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.85\n",
      "=========================\n",
      "Recall score :  0.8515\n",
      "Precision score :  0.8515\n",
      "F1 score :  0.8515\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       461\n",
      "           1       0.95      0.95      0.95       224\n",
      "           2       0.87      0.85      0.86       397\n",
      "           3       0.58      0.58      0.58       211\n",
      "           4       0.85      0.81      0.83       237\n",
      "           5       0.83      0.85      0.84       470\n",
      "\n",
      "    accuracy                           0.85      2000\n",
      "   macro avg       0.84      0.83      0.83      2000\n",
      "weighted avg       0.85      0.85      0.85      2000\n",
      "\n",
      "Computation time:\n",
      "1.8422093391418457\n"
     ]
    }
   ],
   "source": [
    "#make splits\n",
    "train= satimage10.head(4435)\n",
    "test= satimage10.tail(2000)\n",
    "X_train = train.drop('class', axis=1)\n",
    "y_train = train['class']\n",
    "X_test = test.drop('class', axis=1)\n",
    "y_test = test['class']\n",
    "#time recording\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "#build estimator\n",
    "estimator = Id3Estimator()\n",
    "estimator = estimator.fit(X_train, y_train, check_input=True)\n",
    "#tree = export_graphviz(estimator.tree_, 'tree.dot', y)\n",
    "#make predictions\n",
    "y_pred_id3 = estimator.predict(X_test)\n",
    "#_prob_pred_id3 = estimator.predict_proba(X_test)\n",
    "#report performance\n",
    "accuracy = accuracy_score(y_test, y_pred_id3)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "#stop time recoridng\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "457f91d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.165\n",
      "Average bias: 0.097\n",
      "Average variance: 0.131\n",
      "Sklearn 0-1 loss: 0.148\n"
     ]
    }
   ],
   "source": [
    "# calculate classification bias and variance\n",
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#We will load the Boston house dataset for our example\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import metrics\n",
    "\n",
    "# y_pred_cnb\n",
    "# y_prob_pred_cnb\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        estimator, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251b1503",
   "metadata": {},
   "source": [
    "## 2.4 15 Intervals from CHiMerge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9907debd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.85\n",
      "=========================\n",
      "Recall score :  0.8545\n",
      "Precision score :  0.8545\n",
      "F1 score :  0.8545\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95       461\n",
      "           1       0.96      0.96      0.96       224\n",
      "           2       0.85      0.87      0.86       397\n",
      "           3       0.60      0.55      0.58       211\n",
      "           4       0.83      0.82      0.83       237\n",
      "           5       0.83      0.86      0.84       470\n",
      "\n",
      "    accuracy                           0.85      2000\n",
      "   macro avg       0.84      0.83      0.84      2000\n",
      "weighted avg       0.85      0.85      0.85      2000\n",
      "\n",
      "Computation time:\n",
      "2.247255563735962\n"
     ]
    }
   ],
   "source": [
    "#make splits\n",
    "train= satimage15.head(4435)\n",
    "test= satimage15.tail(2000)\n",
    "X_train = train.drop('class', axis=1)\n",
    "y_train = train['class']\n",
    "X_test = test.drop('class', axis=1)\n",
    "y_test = test['class']\n",
    "#time recording\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "#build estimator\n",
    "estimator = Id3Estimator()\n",
    "estimator = estimator.fit(X_train, y_train, check_input=True)\n",
    "#tree = export_graphviz(estimator.tree_, 'tree.dot', y)\n",
    "#make predictions\n",
    "y_pred_id3 = estimator.predict(X_test)\n",
    "#_prob_pred_id3 = estimator.predict_proba(X_test)\n",
    "#report performance\n",
    "accuracy = accuracy_score(y_test, y_pred_id3)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "#stop time recoridng\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c23fced9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.164\n",
      "Average bias: 0.097\n",
      "Average variance: 0.129\n",
      "Sklearn 0-1 loss: 0.145\n"
     ]
    }
   ],
   "source": [
    "# calculate classification bias and variance\n",
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#We will load the Boston house dataset for our example\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import metrics\n",
    "\n",
    "# y_pred_cnb\n",
    "# y_prob_pred_cnb\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        estimator, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9d5f3d",
   "metadata": {},
   "source": [
    "# 3. KNN classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c35401cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data from ChiMerge discretization\n",
    "satimage6 = pd.read_csv('ChiM_discretized_6Intervals_satimage.csv')\n",
    "satimage8 = pd.read_csv('ChiM_discretized_8Intervals_satimage.csv')\n",
    "satimage10 = pd.read_csv('ChiM_discretized_10Intervals_satimage.csv')\n",
    "satimage15 = pd.read_csv('ChiM_discretized_15Intervals_satimage.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6145e2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class representation - training data:  Counter({2: 322, 3: 60, 1: 60, 5: 37, 4: 21})\n",
      "Class representation - testing data:  Counter({0: 70, 4: 18, 2: 9, 3: 3})\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "#df_ewd1 = satimage6\n",
    "disc = 'EWD'\n",
    "k = 4\n",
    "\n",
    "# df_ewd1.info()\n",
    "# data = df_ewd1.values\n",
    "# data.shape\n",
    "\n",
    "# train= satimage6.head(4435)\n",
    "# test= satimage6.tail(2000)\n",
    "\n",
    "train= satimage8.head(500)\n",
    "test= satimage8.tail(100)\n",
    "\n",
    "data_train = train.values\n",
    "data_train.shape\n",
    "data_test = test.values\n",
    "data_test.shape\n",
    "features = satimage6.drop('class', axis = 1).columns\n",
    "\n",
    "\n",
    "# separate the data into X and y\n",
    "x_train = data_train[:, : len(features)]\n",
    "y_train = data_train[:,-1]\n",
    "x_test = data_test[:, : len(features)]\n",
    "y_test = data_test[:,-1]\n",
    "\n",
    "#print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "#x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 30) \n",
    "\n",
    "# Check representation of class\n",
    "#print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfe593f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        70\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.17      0.89      0.29         9\n",
      "           3       0.12      1.00      0.21         3\n",
      "           4       0.46      0.67      0.55        18\n",
      "\n",
      "    accuracy                           0.23       100\n",
      "   macro avg       0.15      0.51      0.21       100\n",
      "weighted avg       0.10      0.23      0.13       100\n",
      "\n",
      "Time for training model Knn-VDM: 84.67768239974976.\n"
     ]
    }
   ],
   "source": [
    "# Knn-VDM complete code\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(x_train, y_train, continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "# Fit model\n",
    "knn_vdm.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(x_test)\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e68e4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "#         knn_vdm, x_train, y_train, x_test, y_test, \n",
    "#         loss='0-1_loss',\n",
    "#         random_seed=123)\n",
    "\n",
    "# print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "# print('Average bias: %.3f' % avg_bias)\n",
    "# print('Average variance: %.3f' % avg_var)\n",
    "# print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55006f71",
   "metadata": {},
   "source": [
    "## 3.1 KNN with ChiMerge 6 intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d96ac85a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class representation - training data:  Counter({5: 877, 2: 709, 1: 436, 3: 383, 4: 350, 0: 245})\n",
      "Class representation - testing data:  Counter({0: 454, 5: 169, 4: 146, 2: 129, 3: 87, 1: 15})\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "#df_ewd1 = satimage6\n",
    "disc = 'EWD'\n",
    "k = 4\n",
    "\n",
    "# df_ewd1.info()\n",
    "# data = df_ewd1.values\n",
    "# data.shape\n",
    "\n",
    "# train= satimage6.head(4435)\n",
    "# test= satimage6.tail(2000)\n",
    "\n",
    "train= satimage8.head(3000)\n",
    "test= satimage8.tail(1000)\n",
    "\n",
    "data_train = train.values\n",
    "data_train.shape\n",
    "data_test = test.values\n",
    "data_test.shape\n",
    "features = satimage6.drop('class', axis = 1).columns\n",
    "\n",
    "\n",
    "# separate the data into X and y\n",
    "x_train = data_train[:, : len(features)]\n",
    "y_train = data_train[:,-1]\n",
    "x_test = data_test[:, : len(features)]\n",
    "y_test = data_test[:,-1]\n",
    "\n",
    "#print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "#x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 30) \n",
    "\n",
    "# Check representation of class\n",
    "#print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "930a188d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.73      0.82       454\n",
      "           1       0.56      1.00      0.71        15\n",
      "           2       0.84      0.79      0.82       129\n",
      "           3       0.45      0.77      0.57        87\n",
      "           4       0.62      0.71      0.66       146\n",
      "           5       0.76      0.78      0.77       169\n",
      "\n",
      "    accuracy                           0.75      1000\n",
      "   macro avg       0.69      0.80      0.72      1000\n",
      "weighted avg       0.79      0.75      0.76      1000\n",
      "\n",
      "Time for training model Knn-VDM: 6072.8614184856415.\n"
     ]
    }
   ],
   "source": [
    "# Knn-VDM complete code\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(x_train, y_train, continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "# Fit model\n",
    "knn_vdm.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(x_test)\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb4fba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "#         knn_vdm, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "#         loss='0-1_loss',\n",
    "#         random_seed=123)\n",
    "\n",
    "# print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "# print('Average bias: %.3f' % avg_bias)\n",
    "# print('Average variance: %.3f' % avg_var)\n",
    "# print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0074f7e6",
   "metadata": {},
   "source": [
    "## 3.2 KNN with ChiMerge 8 intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d6b5aaea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class representation - training data:  Counter({2: 322, 3: 60, 1: 60, 5: 37, 4: 21})\n",
      "Class representation - testing data:  Counter({0: 70, 4: 18, 2: 9, 3: 3})\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "#df_ewd1 = satimage6\n",
    "disc = 'EWD'\n",
    "k = 4\n",
    "\n",
    "# df_ewd1.info()\n",
    "# data = df_ewd1.values\n",
    "# data.shape\n",
    "\n",
    "# train= satimage6.head(4435)\n",
    "# test= satimage6.tail(2000)\n",
    "\n",
    "train= satimage8.head(500)\n",
    "test= satimage8.tail(100)\n",
    "\n",
    "data_train = train.values\n",
    "data_train.shape\n",
    "data_test = test.values\n",
    "data_test.shape\n",
    "features = satimage6.drop('class', axis = 1).columns\n",
    "\n",
    "\n",
    "# separate the data into X and y\n",
    "x_train = data_train[:, : len(features)]\n",
    "y_train = data_train[:,-1]\n",
    "x_test = data_test[:, : len(features)]\n",
    "y_test = data_test[:,-1]\n",
    "\n",
    "#print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "#x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 30) \n",
    "\n",
    "# Check representation of class\n",
    "#print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bc402fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        70\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.17      0.89      0.29         9\n",
      "           3       0.12      1.00      0.21         3\n",
      "           4       0.46      0.67      0.55        18\n",
      "\n",
      "    accuracy                           0.23       100\n",
      "   macro avg       0.15      0.51      0.21       100\n",
      "weighted avg       0.10      0.23      0.13       100\n",
      "\n",
      "Time for training model Knn-VDM: 86.03074193000793.\n"
     ]
    }
   ],
   "source": [
    "# Knn-VDM complete code\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(x_train, y_train, continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "# Fit model\n",
    "knn_vdm.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(x_test)\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1c392d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "#         knn_vdm, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "#         loss='0-1_loss',\n",
    "#         random_seed=123)\n",
    "\n",
    "# print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "# print('Average bias: %.3f' % avg_bias)\n",
    "# print('Average variance: %.3f' % avg_var)\n",
    "# print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a527ed9",
   "metadata": {},
   "source": [
    "## 3.3 KNN with ChiMerge 10 intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5fba69b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class representation - training data:  Counter({2: 322, 3: 60, 1: 60, 5: 37, 4: 21})\n",
      "Class representation - testing data:  Counter({0: 70, 4: 18, 2: 9, 3: 3})\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "#df_ewd1 = satimage6\n",
    "disc = 'EWD'\n",
    "k = 4\n",
    "\n",
    "# df_ewd1.info()\n",
    "# data = df_ewd1.values\n",
    "# data.shape\n",
    "\n",
    "# train= satimage6.head(4435)\n",
    "# test= satimage6.tail(2000)\n",
    "\n",
    "train= satimage10.head(500)\n",
    "test= satimage10.tail(100)\n",
    "\n",
    "data_train = train.values\n",
    "data_train.shape\n",
    "data_test = test.values\n",
    "data_test.shape\n",
    "features = satimage6.drop('class', axis = 1).columns\n",
    "\n",
    "\n",
    "# separate the data into X and y\n",
    "x_train = data_train[:, : len(features)]\n",
    "y_train = data_train[:,-1]\n",
    "x_test = data_test[:, : len(features)]\n",
    "y_test = data_test[:,-1]\n",
    "\n",
    "#print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "#x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 30) \n",
    "\n",
    "# Check representation of class\n",
    "#print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "25cef1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        70\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.17      1.00      0.29         9\n",
      "           3       0.07      0.33      0.12         3\n",
      "           4       0.44      0.67      0.53        18\n",
      "           5       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.22       100\n",
      "   macro avg       0.11      0.33      0.16       100\n",
      "weighted avg       0.10      0.22      0.13       100\n",
      "\n",
      "Time for training model Knn-VDM: 120.34577012062073.\n"
     ]
    }
   ],
   "source": [
    "# Knn-VDM complete code\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(x_train, y_train, continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "# Fit model\n",
    "knn_vdm.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(x_test)\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f534d316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "#         knn_vdm, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "#         loss='0-1_loss',\n",
    "#         random_seed=123)\n",
    "\n",
    "# print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "# print('Average bias: %.3f' % avg_bias)\n",
    "# print('Average variance: %.3f' % avg_var)\n",
    "# print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb00a1f6",
   "metadata": {},
   "source": [
    "## 3.4 KNN with ChiMerge 15 intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "572a96f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class representation - training data:  Counter({2: 322, 3: 60, 1: 60, 5: 37, 4: 21})\n",
      "Class representation - testing data:  Counter({0: 70, 4: 18, 2: 9, 3: 3})\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "#df_ewd1 = satimage6\n",
    "disc = 'EWD'\n",
    "k = 4\n",
    "\n",
    "# df_ewd1.info()\n",
    "# data = df_ewd1.values\n",
    "# data.shape\n",
    "\n",
    "# train= satimage6.head(4435)\n",
    "# test= satimage6.tail(2000)\n",
    "\n",
    "train= satimage15.head(500)\n",
    "test= satimage15.tail(100)\n",
    "\n",
    "data_train = train.values\n",
    "data_train.shape\n",
    "data_test = test.values\n",
    "data_test.shape\n",
    "features = satimage6.drop('class', axis = 1).columns\n",
    "\n",
    "\n",
    "# separate the data into X and y\n",
    "x_train = data_train[:, : len(features)]\n",
    "y_train = data_train[:,-1]\n",
    "x_test = data_test[:, : len(features)]\n",
    "y_test = data_test[:,-1]\n",
    "\n",
    "#print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "#x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 30) \n",
    "\n",
    "# Check representation of class\n",
    "#print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7ae25db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        70\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.17      0.89      0.28         9\n",
      "           3       0.20      0.67      0.31         3\n",
      "           4       0.33      0.67      0.44        18\n",
      "\n",
      "    accuracy                           0.22       100\n",
      "   macro avg       0.14      0.44      0.21       100\n",
      "weighted avg       0.08      0.22      0.11       100\n",
      "\n",
      "Time for training model Knn-VDM: 111.9397599697113.\n"
     ]
    }
   ],
   "source": [
    "# Knn-VDM complete code\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(x_train, y_train, continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "# Fit model\n",
    "knn_vdm.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(x_test)\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ed7255be",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_70324/2301922218.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n\u001b[0m\u001b[0;32m      2\u001b[0m         \u001b[0mknn_vdm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'0-1_loss'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         random_seed=123)\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mlxtend\\evaluate\\bias_variance_decomp.py\u001b[0m in \u001b[0;36mbias_variance_decomp\u001b[1;34m(estimator, X_train, y_train, X_test, y_test, loss, num_rounds, random_seed, **fit_params)\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_boot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_boot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m         \u001b[0mall_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    217\u001b[0m             \u001b[1;31m# In that case, we do not need the distances to perform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m             \u001b[1;31m# the weighting so we do not compute them.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 219\u001b[1;33m             \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    220\u001b[0m             \u001b[0mneigh_dist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    794\u001b[0m                 \u001b[0mkwds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meffective_metric_params_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 796\u001b[1;33m             chunked_results = list(\n\u001b[0m\u001b[0;32m    797\u001b[0m                 pairwise_distances_chunked(\n\u001b[0;32m    798\u001b[0m                     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   1815\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1816\u001b[0m             \u001b[0mX_chunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msl\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1817\u001b[1;33m         \u001b[0mD_chunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpairwise_distances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_chunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1818\u001b[0m         if (X is Y or Y is None) and PAIRWISE_DISTANCE_FUNCTIONS.get(\n\u001b[0;32m   1819\u001b[0m             \u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[1;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   1987\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1988\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1989\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1990\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1529\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1530\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1532\u001b[0m     \u001b[1;31m# enforce a threading backend to prevent data communication overhead\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36m_pairwise_callable\u001b[1;34m(X, Y, metric, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   1572\u001b[0m         \u001b[0miterator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1573\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1574\u001b[1;33m             \u001b[0mout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1575\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1576\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\vdm3\\vdm.py\u001b[0m in \u001b[0;36mget_distance\u001b[1;34m(self, ins_1, ins_2, norm)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mDimensionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Dimension of ins_1 != Dimension of ins_2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m         \u001b[0mins_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[0mins_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        knn_vdm, x_train, y_train, x_test, y_test, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
