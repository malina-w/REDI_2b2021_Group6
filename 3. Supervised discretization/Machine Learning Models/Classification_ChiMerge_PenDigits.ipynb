{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abd2336c",
   "metadata": {},
   "source": [
    "# ML Experiments using different bin sizes & widths based on outputs from supervised discretization\n",
    "## Dataset: Pen Digits\n",
    "\n",
    "by: Malina & Sam , 26.06.2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83bc40c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score, recall_score, precision_score\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "import six\n",
    "import sys\n",
    "sys.modules['sklearn.externals.six'] = six\n",
    "import id3\n",
    "from id3 import Id3Estimator\n",
    "from id3 import export_graphviz\n",
    "import wittgenstein as lw\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# calculate classification bias and variance\n",
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#We will load the Boston house dataset for our example\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn import metrics\n",
    "\n",
    "## EDA\n",
    "from collections import Counter\n",
    "\n",
    "# Knn-VDM 3\n",
    "from vdm3 import ValueDifferenceMetric\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Pre-processing\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "# Cross validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score # 1 metric\n",
    "from sklearn.model_selection import cross_validate # more than 1 metric\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50eb04fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data from ChiMerge discretization\n",
    "pen6 = pd.read_csv('chim_pen_6int.csv')\n",
    "pen8 = pd.read_csv('chim_pen_8int.csv')\n",
    "pen10 = pd.read_csv('chim_pen_10int.csv')\n",
    "pen15 = pd.read_csv('chim_pen_15int.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d489dc73",
   "metadata": {},
   "source": [
    "## Counting interval frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c98900ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_list6 = pen6.columns.drop('class')\n",
    "num_list8 = pen8.columns.drop('class')\n",
    "num_list10 = pen10.columns.drop('class')\n",
    "num_list15 = pen15.columns.drop('class')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9bbb38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interval frequency for 6 Intervals\n",
      "Interval for A1\n",
      "Counter({3: 2438, 0: 2364, 2: 2322, 4: 1413, 1: 1312, 5: 1143})\n",
      "Interval for A2\n",
      "Counter({5: 3115, 3: 2327, 4: 2054, 1: 1298, 2: 1215, 0: 983})\n",
      "Interval for A3\n",
      "Counter({3: 2917, 4: 2910, 0: 2115, 2: 1375, 1: 1138, 5: 537})\n",
      "Interval for A4\n",
      "Counter({5: 4387, 3: 2600, 1: 1655, 4: 899, 2: 799, 0: 652})\n",
      "Interval for A5\n",
      "Counter({5: 2567, 4: 2420, 1: 2408, 0: 1568, 3: 1224, 2: 805})\n",
      "Interval for A6\n",
      "Counter({4: 3709, 2: 2375, 3: 1813, 5: 1115, 1: 1037, 0: 943})\n",
      "Interval for A7\n",
      "Counter({3: 4001, 2: 2348, 0: 2227, 4: 1123, 5: 899, 1: 394})\n",
      "Interval for A8\n",
      "Counter({4: 2093, 0: 2034, 2: 1933, 1: 1774, 5: 1662, 3: 1496})\n",
      "Interval for A9\n",
      "Counter({1: 2823, 4: 1983, 0: 1765, 5: 1764, 2: 1611, 3: 1046})\n",
      "Interval for A10\n",
      "Counter({5: 2299, 0: 2239, 4: 1854, 1: 1797, 2: 1431, 3: 1372})\n",
      "Interval for A11\n",
      "Counter({5: 3645, 0: 2656, 4: 1843, 3: 1397, 1: 741, 2: 710})\n",
      "Interval for A12\n",
      "Counter({4: 3254, 2: 2392, 1: 1527, 5: 1306, 3: 1286, 0: 1227})\n",
      "Interval for A13\n",
      "Counter({2: 2857, 1: 2214, 3: 2130, 4: 1834, 0: 1448, 5: 509})\n",
      "Interval for A14\n",
      "Counter({3: 2976, 5: 1907, 2: 1876, 1: 1780, 0: 1756, 4: 697})\n",
      "Interval for A15\n",
      "Counter({5: 2988, 0: 2917, 2: 1807, 1: 1328, 3: 1205, 4: 747})\n",
      "Interval for A16\n",
      "Counter({0: 4044, 4: 1549, 2: 1441, 3: 1407, 1: 1364, 5: 1187})\n"
     ]
    }
   ],
   "source": [
    "print('Interval frequency for 6 Intervals')\n",
    "for i in num_list6:\n",
    "    print('Interval for ' + i)\n",
    "    print(Counter(pen6[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12e6e7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency for iris with 8 Intervals\n",
      "Interval for A1\n",
      "Counter({0: 2364, 2: 2322, 3: 1672, 1: 1312, 7: 1143, 4: 766, 5: 750, 6: 663})\n",
      "Interval for A2\n",
      "Counter({7: 3115, 5: 2327, 6: 2054, 3: 1298, 4: 1215, 2: 720, 1: 234, 0: 29})\n",
      "Interval for A3\n",
      "Counter({0: 2115, 3: 1713, 5: 1712, 2: 1375, 4: 1204, 6: 1198, 1: 1138, 7: 537})\n",
      "Interval for A4\n",
      "Counter({7: 4387, 4: 1647, 1: 1105, 5: 953, 6: 899, 3: 799, 0: 652, 2: 550})\n",
      "Interval for A5\n",
      "Counter({7: 2567, 0: 1568, 6: 1452, 1: 1414, 4: 1224, 2: 994, 5: 968, 3: 805})\n",
      "Interval for A6\n",
      "Counter({5: 2737, 4: 1813, 3: 1788, 7: 1115, 1: 1037, 6: 972, 0: 943, 2: 587})\n",
      "Interval for A7\n",
      "Counter({5: 4001, 3: 1333, 1: 1201, 6: 1123, 0: 1026, 4: 1015, 7: 899, 2: 394})\n",
      "Interval for A8\n",
      "Counter({5: 2093, 3: 1933, 2: 1774, 0: 1556, 4: 1496, 6: 934, 7: 728, 1: 478})\n",
      "Interval for A9\n",
      "Counter({0: 1765, 7: 1764, 2: 1695, 3: 1611, 6: 1156, 1: 1128, 4: 1046, 5: 827})\n",
      "Interval for A10\n",
      "Counter({0: 2239, 1: 1797, 2: 1431, 3: 1372, 4: 1193, 7: 1161, 6: 1138, 5: 661})\n",
      "Interval for A11\n",
      "Counter({7: 2482, 5: 1843, 4: 1397, 1: 1356, 0: 1300, 6: 1163, 2: 741, 3: 710})\n",
      "Interval for A12\n",
      "Counter({2: 2392, 5: 1755, 1: 1527, 4: 1499, 3: 1286, 0: 1227, 6: 744, 7: 562})\n",
      "Interval for A13\n",
      "Counter({1: 2214, 5: 2130, 6: 1834, 4: 1674, 0: 1448, 2: 740, 7: 509, 3: 443})\n",
      "Interval for A14\n",
      "Counter({7: 1907, 4: 1848, 1: 1780, 0: 1756, 3: 1326, 5: 1128, 6: 697, 2: 550})\n",
      "Interval for A15\n",
      "Counter({7: 2988, 0: 2917, 2: 1273, 5: 1205, 3: 990, 4: 817, 6: 747, 1: 55})\n",
      "Interval for A16\n",
      "Counter({0: 4044, 4: 1407, 1: 1364, 7: 1187, 6: 1067, 2: 1006, 5: 482, 3: 435})\n"
     ]
    }
   ],
   "source": [
    "print('Frequency for iris with 8 Intervals')\n",
    "for i in num_list8:\n",
    "    print('Interval for ' + i)\n",
    "    print(Counter(pen8[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8464588e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency for iris with 10 Intervals\n",
      "Interval for A1\n",
      "Counter({0: 2364, 3: 2322, 9: 1143, 4: 1042, 6: 766, 7: 750, 2: 708, 8: 663, 5: 630, 1: 604})\n",
      "Interval for A2\n",
      "Counter({9: 3115, 5: 1568, 3: 1298, 4: 1215, 8: 1073, 7: 981, 6: 759, 2: 720, 1: 234, 0: 29})\n",
      "Interval for A3\n",
      "Counter({5: 1713, 7: 1712, 4: 1375, 6: 1204, 8: 1198, 1: 1162, 0: 953, 3: 612, 9: 537, 2: 526})\n",
      "Interval for A4\n",
      "Counter({9: 4387, 5: 1647, 2: 1105, 6: 953, 4: 799, 3: 550, 1: 486, 8: 451, 7: 448, 0: 166})\n",
      "Interval for A5\n",
      "Counter({0: 1568, 7: 1452, 8: 1412, 5: 1224, 9: 1155, 3: 994, 6: 968, 4: 805, 2: 712, 1: 702})\n",
      "Interval for A6\n",
      "Counter({7: 2737, 9: 1115, 1: 1037, 8: 972, 0: 943, 4: 929, 6: 917, 5: 896, 3: 859, 2: 587})\n",
      "Interval for A7\n",
      "Counter({5: 1853, 3: 1333, 6: 1317, 1: 1201, 8: 1123, 0: 1026, 4: 1015, 9: 899, 7: 831, 2: 394})\n",
      "Interval for A8\n",
      "Counter({4: 1933, 0: 1556, 6: 1524, 5: 1496, 3: 950, 8: 934, 2: 824, 9: 728, 7: 569, 1: 478})\n",
      "Interval for A9\n",
      "Counter({9: 1764, 3: 1695, 8: 1156, 2: 1128, 6: 1046, 0: 1028, 5: 961, 7: 827, 1: 737, 4: 650})\n",
      "Interval for A10\n",
      "Counter({0: 2239, 3: 1431, 4: 1372, 2: 1217, 5: 1193, 7: 1138, 9: 733, 6: 661, 1: 580, 8: 428})\n",
      "Interval for A11\n",
      "Counter({9: 2482, 7: 1843, 1: 1356, 0: 1300, 8: 1163, 6: 846, 2: 741, 5: 551, 3: 412, 4: 298})\n",
      "Interval for A12\n",
      "Counter({3: 1759, 7: 1755, 6: 1499, 5: 1286, 0: 1227, 2: 1130, 8: 744, 4: 633, 9: 562, 1: 397})\n",
      "Interval for A13\n",
      "Counter({2: 2214, 6: 2130, 5: 1674, 8: 1209, 1: 835, 3: 740, 7: 625, 0: 613, 9: 509, 4: 443})\n",
      "Interval for A14\n",
      "Counter({4: 1848, 1: 1780, 0: 1756, 3: 1326, 5: 1128, 8: 1013, 9: 894, 2: 550, 7: 467, 6: 230})\n",
      "Interval for A15\n",
      "Counter({9: 2988, 0: 2917, 2: 1273, 3: 990, 6: 880, 4: 817, 7: 376, 8: 371, 5: 325, 1: 55})\n",
      "Interval for A16\n",
      "Counter({0: 4044, 1: 1364, 9: 1187, 8: 1067, 2: 1006, 5: 891, 4: 516, 3: 435, 7: 272, 6: 210})\n"
     ]
    }
   ],
   "source": [
    "print('Frequency for iris with 10 Intervals')\n",
    "for i in num_list10:\n",
    "    print('Interval for ' + i)\n",
    "    print(Counter(pen10[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1584fcda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency for iris with 15 Intervals\n",
      "Interval for A1\n",
      "Counter({0: 2364, 6: 1228, 14: 1143, 7: 1042, 4: 977, 3: 708, 10: 685, 13: 663, 8: 630, 12: 597, 2: 460, 11: 153, 1: 144, 5: 117, 9: 81})\n",
      "Interval for A2\n",
      "Counter({14: 3115, 13: 1073, 12: 981, 10: 903, 11: 759, 9: 665, 7: 648, 8: 567, 6: 549, 4: 409, 3: 383, 5: 340, 2: 337, 1: 234, 0: 29})\n",
      "Interval for A3\n",
      "Counter({8: 1713, 10: 1712, 9: 1204, 0: 953, 7: 869, 11: 739, 3: 612, 5: 612, 4: 526, 6: 506, 12: 459, 2: 398, 14: 309, 13: 228, 1: 152})\n",
      "Interval for A4\n",
      "Counter({14: 4387, 4: 1105, 9: 971, 8: 676, 5: 550, 7: 545, 11: 478, 10: 475, 13: 451, 12: 448, 6: 254, 3: 245, 2: 241, 1: 90, 0: 76})\n",
      "Interval for A5\n",
      "Counter({0: 1568, 11: 1338, 14: 1155, 12: 1002, 9: 968, 3: 738, 2: 712, 1: 702, 8: 686, 7: 538, 5: 429, 13: 410, 6: 376, 4: 256, 10: 114})\n",
      "Interval for A6\n",
      "Counter({12: 1392, 11: 1345, 14: 1115, 13: 972, 10: 917, 9: 896, 6: 859, 3: 567, 0: 499, 8: 472, 2: 470, 7: 457, 1: 444, 4: 323, 5: 264})\n",
      "Interval for A7\n",
      "Counter({8: 1853, 0: 1026, 7: 1015, 6: 926, 14: 899, 11: 831, 9: 671, 10: 646, 12: 605, 13: 518, 1: 470, 2: 417, 5: 407, 4: 394, 3: 314})\n",
      "Interval for A8\n",
      "Counter({0: 1556, 5: 1182, 8: 1013, 4: 950, 9: 933, 6: 751, 14: 728, 3: 682, 12: 645, 10: 591, 11: 569, 7: 483, 1: 478, 13: 289, 2: 142})\n",
      "Interval for A9\n",
      "Counter({14: 1764, 4: 1122, 12: 1072, 0: 1028, 11: 827, 1: 737, 6: 650, 3: 584, 5: 573, 8: 573, 10: 571, 2: 544, 9: 475, 7: 388, 13: 84})\n",
      "Interval for A10\n",
      "Counter({0: 2239, 2: 1217, 7: 1193, 3: 833, 5: 698, 6: 674, 13: 664, 8: 661, 4: 598, 1: 580, 10: 576, 11: 460, 12: 428, 9: 102, 14: 69})\n",
      "Interval for A11\n",
      "Counter({14: 2482, 0: 1300, 13: 1163, 12: 959, 11: 884, 1: 874, 10: 706, 8: 551, 2: 482, 6: 412, 3: 368, 7: 298, 5: 216, 4: 157, 9: 140})\n",
      "Interval for A12\n",
      "Counter({3: 1759, 0: 1227, 11: 1211, 2: 1130, 7: 898, 12: 744, 5: 741, 4: 633, 6: 545, 10: 544, 1: 397, 8: 359, 13: 356, 9: 242, 14: 206})\n",
      "Interval for A13\n",
      "Counter({8: 1674, 5: 1616, 9: 1219, 13: 1209, 6: 740, 11: 640, 12: 625, 4: 598, 14: 509, 3: 462, 7: 443, 1: 427, 2: 373, 10: 271, 0: 186})\n",
      "Interval for A14\n",
      "Counter({0: 1756, 1: 1396, 6: 1346, 5: 1326, 13: 1013, 14: 894, 8: 730, 7: 502, 9: 398, 2: 384, 4: 361, 12: 250, 10: 230, 11: 217, 3: 189})\n",
      "Interval for A15\n",
      "Counter({14: 2988, 0: 2917, 2: 1273, 10: 805, 5: 710, 7: 429, 6: 388, 12: 376, 13: 371, 9: 284, 3: 211, 11: 75, 4: 69, 1: 55, 8: 41})\n",
      "Interval for A16\n",
      "Counter({0: 4044, 12: 1067, 14: 844, 1: 751, 2: 613, 4: 584, 8: 507, 5: 435, 3: 422, 9: 384, 13: 343, 7: 325, 11: 272, 10: 210, 6: 191})\n"
     ]
    }
   ],
   "source": [
    "print('Frequency for iris with 15 Intervals')\n",
    "for i in num_list15:\n",
    "    print('Interval for ' + i)\n",
    "    print(Counter(pen15[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d277f4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca83f36b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A5</th>\n",
       "      <th>A6</th>\n",
       "      <th>A7</th>\n",
       "      <th>A8</th>\n",
       "      <th>A9</th>\n",
       "      <th>A10</th>\n",
       "      <th>A11</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>A14</th>\n",
       "      <th>A15</th>\n",
       "      <th>A16</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10987</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10988</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10989</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10990</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10991</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10992 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       A1  A2  A3  A4  A5  A6  A7  A8  A9  A10  A11  A12  A13  A14  A15  A16  \\\n",
       "0       3   7   2   4   4   1   2   0   0    2    4    5    7    7    4    7   \n",
       "1       0   5   2   7   3   5   3   4   1    1    3    0    5    1    7    1   \n",
       "2       0   2   2   2   6   5   7   7   4    7    3    4    0    3    2    0   \n",
       "3       0   7   0   5   1   4   1   4   5    3    7    4    6    3    5    0   \n",
       "4       0   3   4   4   7   7   5   6   3    6    3    4    1    3    4    0   \n",
       "...    ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ...  ...  ...  ...  ...  ...   \n",
       "10987   2   7   1   3   0   1   4   3   6    4    5    5    6    3    7    0   \n",
       "10988   2   4   3   7   4   4   3   2   0    0    1    1    5    1    7    2   \n",
       "10989   4   7   2   4   0   1   1   0   3    1    7    4    6    7    4    6   \n",
       "10990   2   7   0   1   1   1   4   0   6    2    7    5    5    7    2    6   \n",
       "10991   3   7   3   4   1   3   0   2   3    2    7    4    6    3    5    0   \n",
       "\n",
       "       class  \n",
       "0          8  \n",
       "1          2  \n",
       "2          1  \n",
       "3          4  \n",
       "4          1  \n",
       "...      ...  \n",
       "10987      4  \n",
       "10988      2  \n",
       "10989      0  \n",
       "10990      0  \n",
       "10991      4  \n",
       "\n",
       "[10992 rows x 17 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pen8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb0320e",
   "metadata": {},
   "source": [
    "# 1. Categorical Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1cfced",
   "metadata": {},
   "source": [
    "## 1.1 6 Intervals from ChiMerge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1325e346",
   "metadata": {},
   "source": [
    "## 1.1 debug version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "219958cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataX = pen6.drop('class', axis=1)\n",
    "# dataY = pen6['class']\n",
    "\n",
    "# train_ratio = 0.75\n",
    "# validation_ratio = 0.15\n",
    "# test_ratio = 0.10\n",
    "\n",
    "# # train is now 75% of the entire data set\n",
    "# # the _junk suffix means that we drop that variable completely\n",
    "# # dataX, dataY: initial dataframe\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio)\n",
    "\n",
    "# # test is now 10% of the initial data set\n",
    "# # validation is now 15% of the initial data set\n",
    "# X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio))\n",
    "\n",
    "# #print(x_train, x_val, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ced3d839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# start = time.time() # For measuring time execution\n",
    "\n",
    "# cnb = CategoricalNB()\n",
    "# cnb.fit(X_train, y_train)\n",
    "\n",
    "# y_pred_cnb = cnb.predict(X_test)\n",
    "# y_prob_pred_cnb = cnb.predict_proba(X_test)\n",
    "\n",
    "# end = time.time()\n",
    "# print(end - start) # Total time execution for this sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e4a26e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # how did our model perform?\n",
    "# count_misclassified = (y_test != y_pred_cnb).sum()\n",
    "# print(\"CategoricalNB\")\n",
    "# print(\"=\" * 25)\n",
    "# print('Misclassified samples: {}'.format(count_misclassified))\n",
    "# accuracy = accuracy_score(y_test, y_pred_cnb)\n",
    "# print('Accuracy: {:.2f}'.format(accuracy))\n",
    "# print(\"=\" * 25)\n",
    "# print(\"Recall score : \", recall_score(y_test, y_pred_cnb , average='micro'))\n",
    "# print(\"Precision score : \",precision_score(y_test, y_pred_cnb , average='micro'))\n",
    "# print(\"F1 score : \",f1_score(y_test, y_pred_cnb , average='micro'))\n",
    "# print(\"=\" * 25)\n",
    "# print(\"Classification report:\")\n",
    "# print(classification_report(y_test, y_pred_cnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5989b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "#         cnb, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "#         loss='0-1_loss',\n",
    "#         random_seed=123)\n",
    "\n",
    "# print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "# print('Average bias: %.3f' % avg_bias)\n",
    "# print('Average variance: %.3f' % avg_var)\n",
    "# print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_cnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a86152",
   "metadata": {},
   "source": [
    "## 1.1 script version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99b94bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoricalNB\n",
      "=========================\n",
      "Misclassified samples: 145\n",
      "Accuracy: 0.87\n",
      "=========================\n",
      "Recall score :  0.8681818181818182\n",
      "Precision score :  0.8681818181818182\n",
      "F1 score :  0.8681818181818183\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.91       102\n",
      "           1       0.82      0.76      0.79       126\n",
      "           2       0.89      0.92      0.90       123\n",
      "           3       0.80      0.96      0.88        84\n",
      "           4       0.99      0.97      0.98       115\n",
      "           5       0.87      0.58      0.70       118\n",
      "           6       0.98      0.96      0.97        99\n",
      "           7       0.96      0.84      0.90       123\n",
      "           8       0.82      0.89      0.86       100\n",
      "           9       0.70      0.95      0.81       110\n",
      "\n",
      "    accuracy                           0.87      1100\n",
      "   macro avg       0.88      0.87      0.87      1100\n",
      "weighted avg       0.88      0.87      0.87      1100\n",
      "\n",
      "Classification report for validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.88      0.91       169\n",
      "           1       0.83      0.77      0.80       166\n",
      "           2       0.85      0.98      0.91       168\n",
      "           3       0.85      0.97      0.90       153\n",
      "           4       0.99      0.97      0.98       170\n",
      "           5       0.89      0.55      0.68       150\n",
      "           6       1.00      0.96      0.98       168\n",
      "           7       0.96      0.88      0.92       185\n",
      "           8       0.80      0.86      0.83       160\n",
      "           9       0.74      0.96      0.84       159\n",
      "\n",
      "    accuracy                           0.88      1648\n",
      "   macro avg       0.89      0.88      0.88      1648\n",
      "weighted avg       0.89      0.88      0.88      1648\n",
      "\n",
      "Computation time:\n",
      "0.07015776634216309\n"
     ]
    }
   ],
   "source": [
    "# make test & train split\n",
    "dataX = pen6.drop('class', axis=1)\n",
    "dataY = pen6['class']\n",
    "\n",
    "train_ratio = 0.75\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.10\n",
    "\n",
    "# train is now 75% of the entire data set\n",
    "# the _junk suffix means that we drop that variable completely\n",
    "# dataX, dataY: initial dataframe\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio)\n",
    "\n",
    "# test is now 10% of the initial data set\n",
    "# validation is now 15% of the initial data set\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio))\n",
    "\n",
    "#print(x_train, x_val, x_test)\n",
    "\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "cnb = CategoricalNB()\n",
    "cnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_cnb = cnb.predict(X_test)\n",
    "y_prob_pred_cnb = cnb.predict_proba(X_test)\n",
    "\n",
    "\n",
    "# how did our model perform?\n",
    "count_misclassified = (y_test != y_pred_cnb).sum()\n",
    "print(\"CategoricalNB\")\n",
    "print(\"=\" * 25)\n",
    "print('Misclassified samples: {}'.format(count_misclassified))\n",
    "accuracy = accuracy_score(y_test, y_pred_cnb)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_cnb))\n",
    "\n",
    "#for validation\n",
    "y_val_cnb = cnb.predict(X_val)\n",
    "y_val_pred_cnb = cnb.predict_proba(X_val)\n",
    "print(\"Classification report for validation:\")\n",
    "print(classification_report(y_val, y_val_cnb))\n",
    "\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "294481f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.132\n",
      "Average bias: 0.129\n",
      "Average variance: 0.015\n",
      "Sklearn 0-1 loss: 0.132\n"
     ]
    }
   ],
   "source": [
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        cnb, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_cnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68d44662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.91       102\n",
      "           1       0.82      0.76      0.79       126\n",
      "           2       0.89      0.92      0.90       123\n",
      "           3       0.80      0.96      0.88        84\n",
      "           4       0.99      0.97      0.98       115\n",
      "           5       0.87      0.58      0.70       118\n",
      "           6       0.98      0.96      0.97        99\n",
      "           7       0.96      0.84      0.90       123\n",
      "           8       0.82      0.89      0.86       100\n",
      "           9       0.70      0.95      0.81       110\n",
      "\n",
      "    accuracy                           0.87      1100\n",
      "   macro avg       0.88      0.87      0.87      1100\n",
      "weighted avg       0.88      0.87      0.87      1100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_cnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf64c978",
   "metadata": {},
   "source": [
    "## 1.2 8 Intervals from ChiMerge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f044694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make test & train split\n",
    "dataX = pen8.drop('class', axis=1)\n",
    "dataY = pen8['class']\n",
    "\n",
    "train_ratio = 0.75\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.10\n",
    "\n",
    "# train is now 75% of the entire data set\n",
    "# the _junk suffix means that we drop that variable completely\n",
    "# dataX, dataY: initial dataframe\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio)\n",
    "\n",
    "# test is now 10% of the initial data set\n",
    "# validation is now 15% of the initial data set\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio))\n",
    "\n",
    "#validation select the model or tune the parameters\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91a2a331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoricalNB\n",
      "=========================\n",
      "Misclassified samples: 142\n",
      "Accuracy: 0.87\n",
      "=========================\n",
      "Recall score :  0.8709090909090909\n",
      "Precision score :  0.8709090909090909\n",
      "F1 score :  0.8709090909090909\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.91       123\n",
      "           1       0.83      0.62      0.71       117\n",
      "           2       0.80      0.97      0.87       117\n",
      "           3       0.83      0.94      0.88       107\n",
      "           4       0.98      0.97      0.98       116\n",
      "           5       0.87      0.62      0.73       111\n",
      "           6       0.99      0.97      0.98       108\n",
      "           7       0.96      0.89      0.92        98\n",
      "           8       0.83      0.89      0.86        93\n",
      "           9       0.75      0.96      0.84       110\n",
      "\n",
      "    accuracy                           0.87      1100\n",
      "   macro avg       0.88      0.87      0.87      1100\n",
      "weighted avg       0.88      0.87      0.87      1100\n",
      "\n",
      "Classification report for validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92       183\n",
      "           1       0.76      0.70      0.73       177\n",
      "           2       0.80      0.94      0.86       169\n",
      "           3       0.83      0.97      0.89       145\n",
      "           4       0.98      0.98      0.98       174\n",
      "           5       0.84      0.57      0.68       151\n",
      "           6       0.98      0.96      0.97       164\n",
      "           7       0.99      0.83      0.90       166\n",
      "           8       0.85      0.85      0.85       165\n",
      "           9       0.76      0.95      0.84       154\n",
      "\n",
      "    accuracy                           0.87      1648\n",
      "   macro avg       0.87      0.87      0.86      1648\n",
      "weighted avg       0.87      0.87      0.86      1648\n",
      "\n",
      "Computation time:\n",
      "0.052400827407836914\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# make test & train split\n",
    "dataX = pen8.drop('class', axis=1)\n",
    "dataY = pen8['class']\n",
    "\n",
    "train_ratio = 0.75\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.10\n",
    "\n",
    "# train is now 75% of the entire data set\n",
    "# the _junk suffix means that we drop that variable completely\n",
    "# dataX, dataY: initial dataframe\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio)\n",
    "\n",
    "# test is now 10% of the initial data set\n",
    "# validation is now 15% of the initial data set\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio))\n",
    "\n",
    "#validation select the model or tune the parameters\n",
    "# \n",
    "\n",
    "cnb = CategoricalNB()\n",
    "cnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_cnb = cnb.predict(X_test)\n",
    "y_prob_pred_cnb = cnb.predict_proba(X_test)\n",
    "\n",
    "# how did our model perform?\n",
    "count_misclassified = (y_test != y_pred_cnb).sum()\n",
    "print(\"CategoricalNB\")\n",
    "print(\"=\" * 25)\n",
    "print('Misclassified samples: {}'.format(count_misclassified))\n",
    "accuracy = accuracy_score(y_test, y_pred_cnb)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_cnb))\n",
    "\n",
    "\n",
    "#for validation\n",
    "y_val_cnb = cnb.predict(X_val)\n",
    "y_val_pred_cnb = cnb.predict_proba(X_val)\n",
    "print(\"Classification report for validation:\")\n",
    "print(classification_report(y_val, y_val_cnb))\n",
    "\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e4d76235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.133\n",
      "Average bias: 0.127\n",
      "Average variance: 0.015\n",
      "Sklearn 0-1 loss: 0.129\n"
     ]
    }
   ],
   "source": [
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        cnb, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_cnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd86461",
   "metadata": {},
   "source": [
    "## 1.3 10 Intervals from ChiMerge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3b9b6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoricalNB\n",
      "=========================\n",
      "Misclassified samples: 128\n",
      "Accuracy: 0.88\n",
      "=========================\n",
      "Recall score :  0.8836363636363637\n",
      "Precision score :  0.8836363636363637\n",
      "F1 score :  0.8836363636363637\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.92       116\n",
      "           1       0.81      0.75      0.78       130\n",
      "           2       0.81      0.93      0.87       114\n",
      "           3       0.90      0.93      0.91       112\n",
      "           4       0.99      0.98      0.99       107\n",
      "           5       0.93      0.66      0.77       112\n",
      "           6       1.00      0.98      0.99       105\n",
      "           7       0.97      0.88      0.93       113\n",
      "           8       0.85      0.91      0.88       110\n",
      "           9       0.70      0.99      0.82        81\n",
      "\n",
      "    accuracy                           0.88      1100\n",
      "   macro avg       0.89      0.89      0.88      1100\n",
      "weighted avg       0.89      0.88      0.88      1100\n",
      "\n",
      "Classification report for validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.92       186\n",
      "           1       0.74      0.68      0.71       169\n",
      "           2       0.81      0.95      0.87       183\n",
      "           3       0.85      0.93      0.89       149\n",
      "           4       0.99      0.97      0.98       179\n",
      "           5       0.89      0.57      0.70       152\n",
      "           6       0.98      0.97      0.98       162\n",
      "           7       0.94      0.85      0.89       175\n",
      "           8       0.78      0.83      0.80       149\n",
      "           9       0.73      0.96      0.83       144\n",
      "\n",
      "    accuracy                           0.86      1648\n",
      "   macro avg       0.87      0.86      0.86      1648\n",
      "weighted avg       0.87      0.86      0.86      1648\n",
      "\n",
      "Computation time:\n",
      "0.0344851016998291\n"
     ]
    }
   ],
   "source": [
    "# make test & train split\n",
    "dataX = pen10.drop('class', axis=1)\n",
    "dataY = pen10['class']\n",
    "\n",
    "train_ratio = 0.75\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.10\n",
    "\n",
    "# train is now 75% of the entire data set\n",
    "# the _junk suffix means that we drop that variable completely\n",
    "# dataX, dataY: initial dataframe\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio)\n",
    "\n",
    "# test is now 10% of the initial data set\n",
    "# validation is now 15% of the initial data set\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio))\n",
    "\n",
    "#validation select the model or tune the parameters\n",
    "# \n",
    "\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "cnb = CategoricalNB()\n",
    "cnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_cnb = cnb.predict(X_test)\n",
    "y_prob_pred_cnb = cnb.predict_proba(X_test)\n",
    "\n",
    "# how did our model perform?\n",
    "count_misclassified = (y_test != y_pred_cnb).sum()\n",
    "print(\"CategoricalNB\")\n",
    "print(\"=\" * 25)\n",
    "print('Misclassified samples: {}'.format(count_misclassified))\n",
    "accuracy = accuracy_score(y_test, y_pred_cnb)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_cnb))\n",
    "\n",
    "\n",
    "#for validation\n",
    "y_val_cnb = cnb.predict(X_val)\n",
    "y_val_pred_cnb = cnb.predict_proba(X_val)\n",
    "print(\"Classification report for validation:\")\n",
    "print(classification_report(y_val, y_val_cnb))\n",
    "\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95a8a3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.119\n",
      "Average bias: 0.115\n",
      "Average variance: 0.019\n",
      "Sklearn 0-1 loss: 0.116\n"
     ]
    }
   ],
   "source": [
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        cnb, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_cnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b03574",
   "metadata": {},
   "source": [
    "## 1.4 15 Intervals from ChiMerge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eac24eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoricalNB\n",
      "=========================\n",
      "Misclassified samples: 117\n",
      "Accuracy: 0.89\n",
      "=========================\n",
      "Recall score :  0.8936363636363637\n",
      "Precision score :  0.8936363636363637\n",
      "F1 score :  0.8936363636363637\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93       123\n",
      "           1       0.81      0.74      0.78       109\n",
      "           2       0.83      0.96      0.89       118\n",
      "           3       0.88      0.95      0.92       109\n",
      "           4       0.98      0.96      0.97        96\n",
      "           5       0.92      0.68      0.78       101\n",
      "           6       0.98      0.99      0.99       104\n",
      "           7       1.00      0.86      0.93       118\n",
      "           8       0.87      0.89      0.88       114\n",
      "           9       0.78      0.95      0.86       108\n",
      "\n",
      "    accuracy                           0.89      1100\n",
      "   macro avg       0.90      0.89      0.89      1100\n",
      "weighted avg       0.90      0.89      0.89      1100\n",
      "\n",
      "Classification report for validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.87      0.90       172\n",
      "           1       0.75      0.76      0.76       160\n",
      "           2       0.86      0.95      0.91       172\n",
      "           3       0.90      0.94      0.92       142\n",
      "           4       0.99      0.97      0.98       184\n",
      "           5       0.91      0.70      0.79       149\n",
      "           6       0.98      0.98      0.98       172\n",
      "           7       0.97      0.85      0.91       181\n",
      "           8       0.81      0.88      0.84       154\n",
      "           9       0.79      0.95      0.86       162\n",
      "\n",
      "    accuracy                           0.89      1648\n",
      "   macro avg       0.89      0.89      0.88      1648\n",
      "weighted avg       0.89      0.89      0.89      1648\n",
      "\n",
      "0.041581153869628906\n"
     ]
    }
   ],
   "source": [
    "# make test & train split\n",
    "dataX = pen15.drop('class', axis=1)\n",
    "dataY = pen15['class']\n",
    "\n",
    "train_ratio = 0.75\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.10\n",
    "\n",
    "# train is now 75% of the entire data set\n",
    "# the _junk suffix means that we drop that variable completely\n",
    "# dataX, dataY: initial dataframe\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio)\n",
    "\n",
    "# test is now 10% of the initial data set\n",
    "# validation is now 15% of the initial data set\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio))\n",
    "\n",
    "#validation select the model or tune the parameters\n",
    "# \n",
    "\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "cnb = CategoricalNB()\n",
    "cnb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_cnb = cnb.predict(X_test)\n",
    "y_prob_pred_cnb = cnb.predict_proba(X_test)\n",
    "\n",
    "# how did our model perform?\n",
    "count_misclassified = (y_test != y_pred_cnb).sum()\n",
    "print(\"CategoricalNB\")\n",
    "print(\"=\" * 25)\n",
    "print('Misclassified samples: {}'.format(count_misclassified))\n",
    "accuracy = accuracy_score(y_test, y_pred_cnb)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_cnb , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_cnb))\n",
    "\n",
    "\n",
    "#for validation\n",
    "y_val_cnb = cnb.predict(X_val)\n",
    "y_val_pred_cnb = cnb.predict_proba(X_val)\n",
    "print(\"Classification report for validation:\")\n",
    "print(classification_report(y_val, y_val_cnb))\n",
    "\n",
    "end = time.time()\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9331673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.104\n",
      "Average bias: 0.105\n",
      "Average variance: 0.017\n",
      "Sklearn 0-1 loss: 0.106\n"
     ]
    }
   ],
   "source": [
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        cnb, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_cnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36de93a1",
   "metadata": {},
   "source": [
    "# 2. Decision Tree ID3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5da502c",
   "metadata": {},
   "source": [
    "## 2.1 6 Intervals from ChiMerge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cc6ec6",
   "metadata": {},
   "source": [
    "### Debug version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "efd2a195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = pena6.drop('label', axis=1)\n",
    "# y = pen6['label']\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b0a2232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# start = time.time() # For measuring time execution\n",
    "\n",
    "# estimator = Id3Estimator()\n",
    "# estimator = estimator.fit(X_train, y_train, check_input=True)\n",
    "# tree = export_graphviz(estimator.tree_, 'tree.dot', y)\n",
    "\n",
    "# y_pred_id3 = estimator.predict(X_test)\n",
    "# #_prob_pred_id3 = estimator.predict_proba(X_test)\n",
    "\n",
    "# end = time.time()\n",
    "# print(\"Computation time:\")\n",
    "# print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a3dc865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy = accuracy_score(y_test, y_pred_id3)\n",
    "# print('Accuracy: {:.2f}'.format(accuracy))\n",
    "# print(\"=\" * 25)\n",
    "# print(\"Recall score : \", recall_score(y_test, y_pred_id3 , average='micro'))\n",
    "# print(\"Precision score : \",precision_score(y_test, y_pred_id3 , average='micro'))\n",
    "# print(\"F1 score : \",f1_score(y_test, y_pred_id3 , average='micro'))\n",
    "# print(\"=\" * 25)\n",
    "# print(\"Classification report:\")\n",
    "# print(classification_report(y_test, y_pred_id3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95681052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "#         estimator, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "#         loss='0-1_loss',\n",
    "#         random_seed=123)\n",
    "\n",
    "# print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "# print('Average bias: %.3f' % avg_bias)\n",
    "# print('Average variance: %.3f' % avg_var)\n",
    "# print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b305a740",
   "metadata": {},
   "source": [
    "### script version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6cfce8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95\n",
      "=========================\n",
      "Recall score :  0.9472727272727273\n",
      "Precision score :  0.9472727272727273\n",
      "F1 score :  0.9472727272727273\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97       103\n",
      "           1       0.88      0.88      0.88       105\n",
      "           2       0.86      0.92      0.89       104\n",
      "           3       0.98      0.96      0.97       112\n",
      "           4       0.99      0.97      0.98       149\n",
      "           5       0.94      0.97      0.96       102\n",
      "           6       0.98      1.00      0.99       111\n",
      "           7       0.96      0.93      0.95       121\n",
      "           8       0.98      0.90      0.94        94\n",
      "           9       0.93      0.93      0.93        99\n",
      "\n",
      "    accuracy                           0.95      1100\n",
      "   macro avg       0.95      0.95      0.95      1100\n",
      "weighted avg       0.95      0.95      0.95      1100\n",
      "\n",
      "Classification report for validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       184\n",
      "           1       0.92      0.91      0.91       165\n",
      "           2       0.92      0.97      0.94       174\n",
      "           3       0.96      0.97      0.97       156\n",
      "           4       0.99      0.95      0.97       147\n",
      "           5       0.94      0.96      0.95       150\n",
      "           6       0.97      0.99      0.98       181\n",
      "           7       0.97      0.98      0.98       182\n",
      "           8       0.99      0.96      0.98       164\n",
      "           9       0.98      0.95      0.97       145\n",
      "\n",
      "    accuracy                           0.96      1648\n",
      "   macro avg       0.96      0.96      0.96      1648\n",
      "weighted avg       0.96      0.96      0.96      1648\n",
      "\n",
      "Computation time:\n",
      "0.6703085899353027\n"
     ]
    }
   ],
   "source": [
    "# make test & train split\n",
    "dataX = pen6.drop('class', axis=1)\n",
    "dataY = pen6['class']\n",
    "\n",
    "train_ratio = 0.75\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.10\n",
    "\n",
    "# train is now 75% of the entire data set\n",
    "# the _junk suffix means that we drop that variable completely\n",
    "# dataX, dataY: initial dataframe\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio)\n",
    "\n",
    "# test is now 10% of the initial data set\n",
    "# validation is now 15% of the initial data set\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio))\n",
    "#time recording\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "#build estimator\n",
    "estimator = Id3Estimator()\n",
    "estimator = estimator.fit(X_train, y_train, check_input=True)\n",
    "#tree = export_graphviz(estimator.tree_, 'tree.dot', y)\n",
    "#make predictions\n",
    "y_pred_id3 = estimator.predict(X_test)\n",
    "#_prob_pred_id3 = estimator.predict_proba(X_test)\n",
    "#report performance\n",
    "accuracy = accuracy_score(y_test, y_pred_id3)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "\n",
    "#for validation\n",
    "y_val_id3 = estimator.predict(X_val)\n",
    "print(\"Classification report for validation:\")\n",
    "print(classification_report(y_val, y_val_id3))\n",
    "\n",
    "\n",
    "#stop time recoridng\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fbdd3878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.058\n",
      "Average bias: 0.032\n",
      "Average variance: 0.045\n",
      "Sklearn 0-1 loss: 0.053\n"
     ]
    }
   ],
   "source": [
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        estimator, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c21b52",
   "metadata": {},
   "source": [
    "## 2.2 8 Intervals from ChiMerge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "011a2f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96\n",
      "=========================\n",
      "Recall score :  0.96\n",
      "Precision score :  0.96\n",
      "F1 score :  0.96\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       120\n",
      "           1       0.92      0.91      0.91       116\n",
      "           2       0.91      0.95      0.93       115\n",
      "           3       1.00      0.98      0.99       110\n",
      "           4       0.98      0.97      0.97       117\n",
      "           5       0.97      1.00      0.99       106\n",
      "           6       0.97      0.97      0.97        92\n",
      "           7       0.98      0.95      0.96       125\n",
      "           8       0.96      0.96      0.96       105\n",
      "           9       0.96      0.91      0.93        94\n",
      "\n",
      "    accuracy                           0.96      1100\n",
      "   macro avg       0.96      0.96      0.96      1100\n",
      "weighted avg       0.96      0.96      0.96      1100\n",
      "\n",
      "Classification report for validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       160\n",
      "           1       0.92      0.91      0.91       170\n",
      "           2       0.89      0.94      0.92       170\n",
      "           3       0.96      0.96      0.96       137\n",
      "           4       0.98      0.98      0.98       179\n",
      "           5       0.96      0.97      0.96       161\n",
      "           6       0.97      0.98      0.97       174\n",
      "           7       0.97      0.94      0.96       174\n",
      "           8       0.97      0.95      0.96       166\n",
      "           9       0.96      0.94      0.95       157\n",
      "\n",
      "    accuracy                           0.96      1648\n",
      "   macro avg       0.96      0.96      0.96      1648\n",
      "weighted avg       0.96      0.96      0.96      1648\n",
      "\n",
      "Computation time:\n",
      "0.7289807796478271\n"
     ]
    }
   ],
   "source": [
    "# make test & train split\n",
    "dataX = pen8.drop('class', axis=1)\n",
    "dataY = pen8['class']\n",
    "\n",
    "train_ratio = 0.75\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.10\n",
    "\n",
    "# train is now 75% of the entire data set\n",
    "# the _junk suffix means that we drop that variable completely\n",
    "# dataX, dataY: initial dataframe\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio)\n",
    "\n",
    "# test is now 10% of the initial data set\n",
    "# validation is now 15% of the initial data set\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio))\n",
    "#time recording\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "#build estimator\n",
    "estimator = Id3Estimator()\n",
    "estimator = estimator.fit(X_train, y_train)\n",
    "#tree = export_graphviz(estimator.tree_, 'tree.dot', y)\n",
    "#make predictions\n",
    "y_pred_id3 = estimator.predict(X_test)\n",
    "#_prob_pred_id3 = estimator.predict_proba(X_test)\n",
    "#report performance\n",
    "accuracy = accuracy_score(y_test, y_pred_id3)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "\n",
    "#for validation\n",
    "y_val_id3 = estimator.predict(X_val)\n",
    "print(\"Classification report for validation:\")\n",
    "print(classification_report(y_val, y_val_id3))\n",
    "\n",
    "#stop time recoridng\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1fa40c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.054\n",
      "Average bias: 0.021\n",
      "Average variance: 0.049\n",
      "Sklearn 0-1 loss: 0.040\n"
     ]
    }
   ],
   "source": [
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        estimator, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687f1ea3",
   "metadata": {},
   "source": [
    "## 2.3 10 Intervals from ChiMerge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82063c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96\n",
      "=========================\n",
      "Recall score :  0.9590909090909091\n",
      "Precision score :  0.9590909090909091\n",
      "F1 score :  0.9590909090909091\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       130\n",
      "           1       0.88      0.91      0.90       104\n",
      "           2       0.93      0.91      0.92       113\n",
      "           3       0.97      0.97      0.97       102\n",
      "           4       0.99      0.97      0.98        99\n",
      "           5       0.98      0.97      0.97        95\n",
      "           6       1.00      0.99      1.00       126\n",
      "           7       0.97      0.94      0.96       121\n",
      "           8       0.96      0.97      0.96        96\n",
      "           9       0.94      0.97      0.96       114\n",
      "\n",
      "    accuracy                           0.96      1100\n",
      "   macro avg       0.96      0.96      0.96      1100\n",
      "weighted avg       0.96      0.96      0.96      1100\n",
      "\n",
      "Classification report for validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       170\n",
      "           1       0.84      0.94      0.89       154\n",
      "           2       0.95      0.91      0.93       184\n",
      "           3       0.97      0.97      0.97       153\n",
      "           4       0.98      0.97      0.98       197\n",
      "           5       0.97      0.97      0.97       144\n",
      "           6       0.99      0.98      0.99       165\n",
      "           7       0.96      0.92      0.94       160\n",
      "           8       0.95      0.96      0.96       158\n",
      "           9       0.96      0.93      0.94       163\n",
      "\n",
      "    accuracy                           0.96      1648\n",
      "   macro avg       0.96      0.96      0.95      1648\n",
      "weighted avg       0.96      0.96      0.96      1648\n",
      "\n",
      "Computation time:\n",
      "0.7245194911956787\n"
     ]
    }
   ],
   "source": [
    "# make test & train split\n",
    "dataX = pen10.drop('class', axis=1)\n",
    "dataY = pen10['class']\n",
    "\n",
    "train_ratio = 0.75\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.10\n",
    "\n",
    "# train is now 75% of the entire data set\n",
    "# the _junk suffix means that we drop that variable completely\n",
    "# dataX, dataY: initial dataframe\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio)\n",
    "\n",
    "# test is now 10% of the initial data set\n",
    "# validation is now 15% of the initial data set\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio))\n",
    "#time recording\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "#build estimator\n",
    "estimator = Id3Estimator()\n",
    "estimator = estimator.fit(X_train, y_train, check_input=True)\n",
    "#tree = export_graphviz(estimator.tree_, 'tree.dot', y)\n",
    "#make predictions\n",
    "y_pred_id3 = estimator.predict(X_test)\n",
    "#_prob_pred_id3 = estimator.predict_proba(X_test)\n",
    "#report performance\n",
    "accuracy = accuracy_score(y_test, y_pred_id3)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "\n",
    "#for validation\n",
    "y_val_id3 = estimator.predict(X_val)\n",
    "print(\"Classification report for validation:\")\n",
    "print(classification_report(y_val, y_val_id3))\n",
    "\n",
    "#stop time recoridng\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4239d3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.049\n",
      "Average bias: 0.020\n",
      "Average variance: 0.042\n",
      "Sklearn 0-1 loss: 0.041\n"
     ]
    }
   ],
   "source": [
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        estimator, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251b1503",
   "metadata": {},
   "source": [
    "## 2.4 15 Intervals from CHiMerge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9907debd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96\n",
      "=========================\n",
      "Recall score :  0.9645454545454546\n",
      "Precision score :  0.9645454545454546\n",
      "F1 score :  0.9645454545454546\n",
      "=========================\n",
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       119\n",
      "           1       0.97      0.91      0.94       120\n",
      "           2       0.92      0.97      0.94       102\n",
      "           3       0.96      1.00      0.98        90\n",
      "           4       0.98      0.98      0.98       124\n",
      "           5       0.95      0.97      0.96       117\n",
      "           6       0.97      0.98      0.98       106\n",
      "           7       0.95      0.97      0.96       109\n",
      "           8       0.98      0.95      0.97       118\n",
      "           9       0.98      0.93      0.95        95\n",
      "\n",
      "    accuracy                           0.96      1100\n",
      "   macro avg       0.96      0.96      0.96      1100\n",
      "weighted avg       0.97      0.96      0.96      1100\n",
      "\n",
      "Classification report for validation:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       182\n",
      "           1       0.95      0.89      0.92       177\n",
      "           2       0.90      0.95      0.93       163\n",
      "           3       0.97      0.98      0.97       155\n",
      "           4       0.99      0.99      0.99       156\n",
      "           5       0.94      0.99      0.96       151\n",
      "           6       0.99      0.99      0.99       175\n",
      "           7       0.96      0.97      0.97       168\n",
      "           8       0.97      0.96      0.97       159\n",
      "           9       0.97      0.94      0.95       162\n",
      "\n",
      "    accuracy                           0.96      1648\n",
      "   macro avg       0.96      0.96      0.96      1648\n",
      "weighted avg       0.96      0.96      0.96      1648\n",
      "\n",
      "Computation time:\n",
      "0.9621145725250244\n"
     ]
    }
   ],
   "source": [
    "# make test & train split\n",
    "dataX = pen15.drop('class', axis=1)\n",
    "dataY = pen15['class']\n",
    "\n",
    "train_ratio = 0.75\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.10\n",
    "\n",
    "# train is now 75% of the entire data set\n",
    "# the _junk suffix means that we drop that variable completely\n",
    "# dataX, dataY: initial dataframe\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataX, dataY, test_size=1 - train_ratio)\n",
    "\n",
    "# test is now 10% of the initial data set\n",
    "# validation is now 15% of the initial data set\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio))\n",
    "#time recording\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "#build estimator\n",
    "estimator = Id3Estimator()\n",
    "estimator = estimator.fit(X_train, y_train, check_input=True)\n",
    "#tree = export_graphviz(estimator.tree_, 'tree.dot', y)\n",
    "#make predictions\n",
    "y_pred_id3 = estimator.predict(X_test)\n",
    "#_prob_pred_id3 = estimator.predict_proba(X_test)\n",
    "#report performance\n",
    "accuracy = accuracy_score(y_test, y_pred_id3)\n",
    "print('Accuracy: {:.2f}'.format(accuracy))\n",
    "print(\"=\" * 25)\n",
    "print(\"Recall score : \", recall_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"Precision score : \",precision_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"F1 score : \",f1_score(y_test, y_pred_id3 , average='micro'))\n",
    "print(\"=\" * 25)\n",
    "print(\"Classification report:\")\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "\n",
    "#for validation\n",
    "y_val_id3 = estimator.predict(X_val)\n",
    "print(\"Classification report for validation:\")\n",
    "print(classification_report(y_val, y_val_id3))\n",
    "\n",
    "#stop time recoridng\n",
    "end = time.time()\n",
    "print(\"Computation time:\")\n",
    "print(end - start) # Total time execution for this sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "da73d6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.041\n",
      "Average bias: 0.012\n",
      "Average variance: 0.036\n",
      "Sklearn 0-1 loss: 0.035\n"
     ]
    }
   ],
   "source": [
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        estimator, X_train.values, y_train.values, X_test.values, y_test.values, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3533e6de",
   "metadata": {},
   "source": [
    "# 3. KNN classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "434480bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in data from ChiMerge discretization\n",
    "pen6 = pd.read_csv('chim_pen_6int.csv')\n",
    "pen8 = pd.read_csv('chim_pen_8int.csv')\n",
    "pen10 = pd.read_csv('chim_pen_10int.csv')\n",
    "pen15 = pd.read_csv('chim_pen_15int.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6c2243",
   "metadata": {},
   "source": [
    "## 3.1 KNN with ChiMerge 6 Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2aa62f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500 entries, 0 to 499\n",
      "Data columns (total 17 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   A1      500 non-null    int64\n",
      " 1   A2      500 non-null    int64\n",
      " 2   A3      500 non-null    int64\n",
      " 3   A4      500 non-null    int64\n",
      " 4   A5      500 non-null    int64\n",
      " 5   A6      500 non-null    int64\n",
      " 6   A7      500 non-null    int64\n",
      " 7   A8      500 non-null    int64\n",
      " 8   A9      500 non-null    int64\n",
      " 9   A10     500 non-null    int64\n",
      " 10  A11     500 non-null    int64\n",
      " 11  A12     500 non-null    int64\n",
      " 12  A13     500 non-null    int64\n",
      " 13  A14     500 non-null    int64\n",
      " 14  A15     500 non-null    int64\n",
      " 15  A16     500 non-null    int64\n",
      " 16  class   500 non-null    int64\n",
      "dtypes: int64(17)\n",
      "memory usage: 66.5 KB\n",
      "(500, 16) (500,)\n",
      "Class representation - original:  Counter({0: 61, 5: 56, 6: 55, 3: 51, 2: 49, 4: 47, 1: 46, 7: 46, 8: 45, 9: 44})\n",
      "Class representation - training data:  Counter({0: 49, 5: 44, 3: 42, 2: 39, 6: 38, 4: 35, 8: 34, 1: 33, 9: 31, 7: 30})\n",
      "Class representation - testing data:  Counter({6: 17, 7: 16, 1: 13, 9: 13, 0: 12, 5: 12, 4: 12, 8: 11, 2: 10, 3: 9})\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_ewd1 = pen6.head(500)\n",
    "disc = 'EWD'\n",
    "k = 4\n",
    "\n",
    "df_ewd1.info()\n",
    "data = df_ewd1.values\n",
    "data.shape\n",
    "\n",
    "features = df_ewd1.drop('class', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 30)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a8733d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92        12\n",
      "           1       0.71      0.77      0.74        13\n",
      "           2       0.82      0.90      0.86        10\n",
      "           3       0.82      1.00      0.90         9\n",
      "           4       1.00      1.00      1.00        12\n",
      "           5       0.92      0.92      0.92        12\n",
      "           6       1.00      1.00      1.00        17\n",
      "           7       1.00      0.81      0.90        16\n",
      "           8       1.00      0.73      0.84        11\n",
      "           9       1.00      1.00      1.00        13\n",
      "\n",
      "    accuracy                           0.91       125\n",
      "   macro avg       0.91      0.91      0.91       125\n",
      "weighted avg       0.92      0.91      0.91       125\n",
      "\n",
      "Time for training model Knn-VDM: 90.7321572303772.\n"
     ]
    }
   ],
   "source": [
    "# Knn-VDM complete code\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(x_train, y_train, continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "# Fit model\n",
    "knn_vdm.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(x_test)\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c978b0f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_64424/2301922218.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n\u001b[0m\u001b[0;32m      2\u001b[0m         \u001b[0mknn_vdm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'0-1_loss'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         random_seed=123)\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\mlxtend\\evaluate\\bias_variance_decomp.py\u001b[0m in \u001b[0;36mbias_variance_decomp\u001b[1;34m(estimator, X_train, y_train, X_test, y_test, loss, num_rounds, random_seed, **fit_params)\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_boot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_boot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m         \u001b[0mall_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    217\u001b[0m             \u001b[1;31m# In that case, we do not need the distances to perform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m             \u001b[1;31m# the weighting so we do not compute them.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 219\u001b[1;33m             \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    220\u001b[0m             \u001b[0mneigh_dist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    794\u001b[0m                 \u001b[0mkwds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meffective_metric_params_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 796\u001b[1;33m             chunked_results = list(\n\u001b[0m\u001b[0;32m    797\u001b[0m                 pairwise_distances_chunked(\n\u001b[0;32m    798\u001b[0m                     \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   1815\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1816\u001b[0m             \u001b[0mX_chunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msl\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1817\u001b[1;33m         \u001b[0mD_chunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpairwise_distances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_chunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1818\u001b[0m         if (X is Y or Y is None) and PAIRWISE_DISTANCE_FUNCTIONS.get(\n\u001b[0;32m   1819\u001b[0m             \u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[1;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   1987\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1988\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1989\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1990\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1528\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1529\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1530\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1532\u001b[0m     \u001b[1;31m# enforce a threading backend to prevent data communication overhead\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36m_pairwise_callable\u001b[1;34m(X, Y, metric, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   1572\u001b[0m         \u001b[0miterator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitertools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1573\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1574\u001b[1;33m             \u001b[0mout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1575\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1576\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\vdm3\\vdm.py\u001b[0m in \u001b[0;36mget_distance\u001b[1;34m(self, ins_1, ins_2, norm)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[0mins_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m         \u001b[0mins_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontinuous\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        knn_vdm, x_train, y_train, x_test, y_test, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed92116",
   "metadata": {},
   "source": [
    "## 3.2 KNN with ChiMerge 8 Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b884bb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_ewd1 = pen8.head(500)\n",
    "disc = 'EWD'\n",
    "k = 4\n",
    "\n",
    "df_ewd1.info()\n",
    "data = df_ewd1.values\n",
    "data.shape\n",
    "\n",
    "features = df_ewd1.drop('class', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 30)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e564bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knn-VDM complete code\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(x_train, y_train, continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "# Fit model\n",
    "knn_vdm.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(x_test)\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7231bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        knn_vdm, x_train, y_train, x_test, y_test, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654ef1a1",
   "metadata": {},
   "source": [
    "## 3.3 KNN with ChiMerge 10 Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bf57e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_ewd1 = pen10.head(500)\n",
    "disc = 'EWD'\n",
    "k = 4\n",
    "\n",
    "df_ewd1.info()\n",
    "data = df_ewd1.values\n",
    "data.shape\n",
    "\n",
    "features = df_ewd1.drop('class', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 30)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221f0a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knn-VDM complete code\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(x_train, y_train, continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "# Fit model\n",
    "knn_vdm.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(x_test)\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3a80da",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        knn_vdm, x_train, y_train, x_test, y_test, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9516fd7",
   "metadata": {},
   "source": [
    "## 3.4 KNN with ChiMerge 15 Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbf9df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_ewd1 = pen15.head(500)\n",
    "disc = 'EWD'\n",
    "k = 4\n",
    "\n",
    "df_ewd1.info()\n",
    "data = df_ewd1.values\n",
    "data.shape\n",
    "\n",
    "features = df_ewd1.drop('class', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split train test\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 30)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(Y)) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ', Counter(y_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7d598f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knn-VDM complete code\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(x_train, y_train, continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "# Fit model\n",
    "knn_vdm.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(x_test)\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffcccbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "        knn_vdm, x_train, y_train, x_test, y_test, \n",
    "        loss='0-1_loss',\n",
    "        random_seed=123)\n",
    "\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
