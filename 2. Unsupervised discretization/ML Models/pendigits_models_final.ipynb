{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "514e58db",
   "metadata": {},
   "source": [
    "# Classification models\n",
    "\n",
    "Dataset: pendigits<br>\n",
    "By: Sam<br>\n",
    "Update at: 29/06/2022<br>\n",
    "\n",
    "====\n",
    "\n",
    "Summary:<br>\n",
    "- Import unsupervised discretised datasets (already encoded categorical attributes)\n",
    "- Split dataset: 75% training, 15% validation, 10% testing, seed = 30\n",
    "- Perform classification models: ID3, Naive Bayes. Knn-VDM is not applicable for the whole dataset due to long time training (brute force algorithm)\n",
    "- No cross validation\n",
    "- Evaluation performance metrics: Accuracy, F1-score (average/ macro), Bias, Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b9c296",
   "metadata": {},
   "source": [
    "### About Dataset\n",
    "\n",
    "pendigits.tra: Training\t7494<br>\n",
    "pendigits.tes: Testing\t3498<br>\n",
    "The way we used the dataset was to use first half of training for  actual training, one-fourth for validation and one-fourth for writer-dependent testing. The test set was used for writer-independent testing and is the actual quality measure.<br>\n",
    "Number of Attributes: 16 input + 1 class attribute (10 classes from 0-9)<br>\n",
    "The input vector size is 2xT, two times the number of points resampled. We considered spatial resampling to T=8,12,16 points in our experiments and found that T=8 gave the best trade-off between accuracy and complexity.<br>\n",
    "All attributes are numeric.<br>\n",
    "No missing value, balanced class<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e959660",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "from pandas import set_option\n",
    "import numpy as np\n",
    "from numpy import arange\n",
    "## EDA\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c39986bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "# Cross validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import cross_val_score # 1 metric\n",
    "from sklearn.model_selection import cross_validate # more than 1 metric\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76585941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RIPPER (https://pypi.org/project/wittgenstein/) Only for binary\n",
    "import wittgenstein as lw "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1d3237a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Naive Bayes\n",
    "from sklearn.naive_bayes import CategoricalNB # Categorical Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB # Multinominal Naive Bayes (suitable for NLP)\n",
    "from mixed_naive_bayes import MixedNB # Mixed Naive Bayes for combination of both discrete & continuous feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e9ddea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For decision tree ID3 \n",
    "# https://stackoverflow.com/questions/61867945/python-import-error-cannot-import-name-six-from-sklearn-externals\n",
    "import six\n",
    "import sys\n",
    "sys.modules['sklearn.externals.six'] = six\n",
    "import mlrose\n",
    "from id3 import Id3Estimator # ID3 Decision Tree (https://pypi.org/project/decision-tree-id3/)\n",
    "from id3 import export_graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e98484cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knn-VDM 3\n",
    "from vdm3 import ValueDifferenceMetric\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "039c536e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For model evaluation\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4ec1b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13679f21",
   "metadata": {},
   "source": [
    "# EWD data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f773ca",
   "metadata": {},
   "source": [
    "## EWD, k = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5f147af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10992 entries, 0 to 10991\n",
      "Data columns (total 17 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   A1      10992 non-null  int64\n",
      " 1   A2      10992 non-null  int64\n",
      " 2   A3      10992 non-null  int64\n",
      " 3   A4      10992 non-null  int64\n",
      " 4   A5      10992 non-null  int64\n",
      " 5   A6      10992 non-null  int64\n",
      " 6   A7      10992 non-null  int64\n",
      " 7   A8      10992 non-null  int64\n",
      " 8   A9      10992 non-null  int64\n",
      " 9   A10     10992 non-null  int64\n",
      " 10  A11     10992 non-null  int64\n",
      " 11  A12     10992 non-null  int64\n",
      " 12  A13     10992 non-null  int64\n",
      " 13  A14     10992 non-null  int64\n",
      " 14  A15     10992 non-null  int64\n",
      " 15  A16     10992 non-null  int64\n",
      " 16  class   10992 non-null  int64\n",
      "dtypes: int64(17)\n",
      "memory usage: 1.4 MB\n",
      "(10992, 16) (10992,)\n",
      "Class representation - original:  Counter({2: 1144, 4: 1144, 1: 1143, 0: 1143, 7: 1142, 6: 1056, 8: 1055, 5: 1055, 9: 1055, 3: 1055})\n",
      "Class representation - training data:  Counter({4: 858, 2: 858, 0: 857, 1: 857, 7: 857, 5: 792, 6: 792, 3: 791, 8: 791, 9: 791})\n",
      "Class representation - testing data:  Counter({1: 115, 7: 114, 4: 114, 2: 114, 0: 114, 6: 106, 3: 106, 9: 106, 8: 106, 5: 105})\n",
      "Class representation - validation data:  Counter({4: 172, 0: 172, 2: 172, 1: 171, 7: 171, 8: 158, 6: 158, 5: 158, 3: 158, 9: 158})\n",
      "(8244, 16) (1648, 16) (1100, 16)\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_ewd1 = pd.read_csv('pendigits_ewd1.csv')\n",
    "disc = 'EWD'\n",
    "k = 4\n",
    "\n",
    "df_ewd1.info()\n",
    "data = df_ewd1.values\n",
    "data.shape\n",
    "\n",
    "features = df_ewd1.drop('class', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split data:\n",
    "train_ratio = 0.75\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.10\n",
    "\n",
    "# train is now 75% of the entire data set\n",
    "# the _junk suffix means that we drop that variable completely\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=1 - train_ratio, random_state = 30, stratify = Y)\n",
    "\n",
    "# test is now 10% of the initial data set\n",
    "# validation is now 15% of the initial data set\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio), random_state = 30, stratify = y_test)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(df_ewd1['class'])) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ',Counter(y_test)) \n",
    "print('Class representation - validation data: ',Counter(y_val))\n",
    "\n",
    "print(x_train.shape, x_val.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d98f4f",
   "metadata": {},
   "source": [
    "### Models, EWD, k=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2358e288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       114\n",
      "           1       0.95      0.82      0.88       115\n",
      "           2       0.86      0.99      0.92       114\n",
      "           3       0.90      0.97      0.94       106\n",
      "           4       0.98      0.95      0.96       114\n",
      "           5       0.93      0.95      0.94       105\n",
      "           6       0.98      0.98      0.98       106\n",
      "           7       0.96      0.94      0.95       114\n",
      "           8       0.97      0.97      0.97       106\n",
      "           9       0.94      0.91      0.92       106\n",
      "\n",
      "    accuracy                           0.95      1100\n",
      "   macro avg       0.95      0.95      0.95      1100\n",
      "weighted avg       0.95      0.95      0.95      1100\n",
      "\n",
      "Time for training model ID3 - default, EWD, k = 4 is: 0.637890100479126.\n"
     ]
    }
   ],
   "source": [
    "# ID3 - Default\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "model_id3 = Id3Estimator()\n",
    "model_id3.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_id3 = model_id3.predict(x_test)\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model ID3 - default, {disc}, k = {k} is: {end - start}.') # Total time execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c5b0e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93       114\n",
      "           1       0.70      0.68      0.69       115\n",
      "           2       0.80      0.93      0.86       114\n",
      "           3       0.84      0.96      0.89       106\n",
      "           4       0.99      0.94      0.96       114\n",
      "           5       0.85      0.57      0.68       105\n",
      "           6       0.94      0.99      0.96       106\n",
      "           7       0.97      0.88      0.92       114\n",
      "           8       0.86      0.82      0.84       106\n",
      "           9       0.76      0.92      0.83       106\n",
      "\n",
      "    accuracy                           0.86      1100\n",
      "   macro avg       0.86      0.86      0.86      1100\n",
      "weighted avg       0.86      0.86      0.86      1100\n",
      "\n",
      "Time for training model Naive Bayes - default, EWD, k = 4 is: 0.02654099464416504.\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes - Default\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "model_nb = CategoricalNB()\n",
    "model_nb.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_nb = model_nb.predict(x_test)\n",
    "model_nb.classes_\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "end = time.time()\n",
    "print(f'Time for training model Naive Bayes - default, {disc}, k = {k} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4156a860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97        50\n",
      "           1       0.85      0.79      0.81        42\n",
      "           2       0.86      0.96      0.91        46\n",
      "           3       0.83      0.98      0.90        50\n",
      "           4       0.98      0.81      0.89        58\n",
      "           5       0.81      0.88      0.85        50\n",
      "           6       0.84      1.00      0.91        46\n",
      "           7       0.89      0.92      0.91        53\n",
      "           8       1.00      0.84      0.91        44\n",
      "           9       0.92      0.80      0.86        61\n",
      "\n",
      "    accuracy                           0.89       500\n",
      "   macro avg       0.90      0.89      0.89       500\n",
      "weighted avg       0.90      0.89      0.89       500\n",
      "\n",
      "Time for training model Knn-VDM, EWD, k = 4 is: 481.4514729976654.\n"
     ]
    }
   ],
   "source": [
    "# Knn-VDM complete code - TRY SAMPLE 500\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(x_train[:500,:], y_train[:500], continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "## Fit model\n",
    "knn_vdm.fit(x_train[:500,:], y_train[:500])\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(x_test[:500,:])\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test[:500], y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM, {disc}, k = {k} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00b37c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation result, accuracy, EWD, k = 4.\n",
      "ID3, validation accuracy:, 0.9526699029126213\n",
      "CNB, validation accuracy:, 0.8549757281553398\n"
     ]
    }
   ],
   "source": [
    "# VALIDATION\n",
    "scores = 'accuracy'\n",
    "print(f'Validation result, {scores}, {disc}, k = {k}.')\n",
    "# Create list of algorithms\n",
    "models = []\n",
    "models.append(('ID3', model_id3))\n",
    "models.append(('CNB', model_nb))\n",
    "# models.append(('Knn-VDM', KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')))\n",
    "\n",
    "# Evaluate each model in turn\n",
    "# get predicted prices on validation data\n",
    "for name, model in models:\n",
    "    val_pred = model.predict(x_val)\n",
    "    val_results = metrics.accuracy_score(y_val, val_pred)\n",
    "    print(f'{name}, validation accuracy:, {val_results}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f2784e",
   "metadata": {},
   "source": [
    "### Evaluation, EWD, k=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5eae7391",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39678696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.066\n",
      "Average bias: 0.050\n",
      "Average variance: 0.046\n",
      "Sklearn 0-1 loss: 0.055\n"
     ]
    }
   ],
   "source": [
    "# ID3\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_id3, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec3177b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.141\n",
      "Average bias: 0.140\n",
      "Average variance: 0.012\n",
      "Sklearn 0-1 loss: 0.139\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_nb, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a17804e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-581f8942ceba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# For measuring time execution\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mknn_vdm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'0-1_loss'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/mlxtend/evaluate/bias_variance_decomp.py\u001b[0m in \u001b[0;36mbias_variance_decomp\u001b[0;34m(estimator, X_train, y_train, X_test, y_test, loss, num_rounds, random_seed, **fit_params)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_boot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_boot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m         \u001b[0mall_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/neighbors/_classification.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mdata\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \"\"\"\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0m_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    750\u001b[0m                 \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meffective_metric_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m             chunked_results = list(\n\u001b[0m\u001b[1;32m    753\u001b[0m                 pairwise_distances_chunked(\n\u001b[1;32m    754\u001b[0m                     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[1;32m   1715\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1716\u001b[0m             \u001b[0mX_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1717\u001b[0;31m         \u001b[0mD_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpairwise_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1718\u001b[0m         if (X is Y or Y is None) and PAIRWISE_DISTANCE_FUNCTIONS.get(\n\u001b[1;32m   1719\u001b[0m             \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[0;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   1887\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1889\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m     \u001b[0;31m# enforce a threading backend to prevent data communication overhead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_pairwise_callable\u001b[0;34m(X, Y, metric, force_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   1472\u001b[0m         \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1474\u001b[0;31m             \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/vdm3/vdm.py\u001b[0m in \u001b[0;36mget_distance\u001b[0;34m(self, ins_1, ins_2, norm)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mins_2_cat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mcat_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_delta_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcond_proba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mins_1_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mins_2_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontinuous\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/vdm3/components.py\u001b[0m in \u001b[0;36mget_delta_nd\u001b[0;34m(cond_proba, ins_1, ins_2, norm)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mReturns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdeltas\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0mbetween\u001b[0m \u001b[0mins_1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mins_2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \"\"\"\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mdeltas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mget_delta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond_proba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mins_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mins_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcond_proba\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeltas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/vdm3/components.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mReturns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdeltas\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0mbetween\u001b[0m \u001b[0mins_1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mins_2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \"\"\"\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mdeltas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mget_delta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond_proba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mins_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mins_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcond_proba\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeltas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/vdm3/components.py\u001b[0m in \u001b[0;36mget_delta\u001b[0;34m(cond_proba, val_1, val_2, norm)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mReturns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthis\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \"\"\"\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond_proba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muni_x\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcond_proba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muni_x\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0muni_x\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcond_proba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mproba\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/vdm3/components.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mReturns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthis\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \"\"\"\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond_proba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muni_x\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcond_proba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muni_x\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0muni_x\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcond_proba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mproba\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3078\u001b[0m             \u001b[0mcasted_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Knn - SAMPLE 500\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "knn_vdm, x_train[:500,:], y_train[:500], x_test[:500,:], y_test[:500],\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for evaluation model Knn-VDM, {disc}, k = {k} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c0a4f2",
   "metadata": {},
   "source": [
    "## EWD, k = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e55eec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10992 entries, 0 to 10991\n",
      "Data columns (total 17 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   A1      10992 non-null  int64\n",
      " 1   A2      10992 non-null  int64\n",
      " 2   A3      10992 non-null  int64\n",
      " 3   A4      10992 non-null  int64\n",
      " 4   A5      10992 non-null  int64\n",
      " 5   A6      10992 non-null  int64\n",
      " 6   A7      10992 non-null  int64\n",
      " 7   A8      10992 non-null  int64\n",
      " 8   A9      10992 non-null  int64\n",
      " 9   A10     10992 non-null  int64\n",
      " 10  A11     10992 non-null  int64\n",
      " 11  A12     10992 non-null  int64\n",
      " 12  A13     10992 non-null  int64\n",
      " 13  A14     10992 non-null  int64\n",
      " 14  A15     10992 non-null  int64\n",
      " 15  A16     10992 non-null  int64\n",
      " 16  class   10992 non-null  int64\n",
      "dtypes: int64(17)\n",
      "memory usage: 1.4 MB\n",
      "(10992, 16) (10992,)\n",
      "Class representation - original:  Counter({2: 1144, 4: 1144, 1: 1143, 0: 1143, 7: 1142, 6: 1056, 8: 1055, 5: 1055, 9: 1055, 3: 1055})\n",
      "Class representation - training data:  Counter({4: 858, 2: 858, 0: 857, 1: 857, 7: 857, 5: 792, 6: 792, 3: 791, 8: 791, 9: 791})\n",
      "Class representation - testing data:  Counter({1: 115, 7: 114, 4: 114, 2: 114, 0: 114, 6: 106, 3: 106, 9: 106, 8: 106, 5: 105})\n",
      "Class representation - validation data:  Counter({4: 172, 0: 172, 2: 172, 1: 171, 7: 171, 8: 158, 6: 158, 5: 158, 3: 158, 9: 158})\n",
      "(8244, 16) (1648, 16) (1100, 16)\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_ewd2 = pd.read_csv('pendigits_ewd2.csv')\n",
    "disc = 'EWD'\n",
    "k = 7\n",
    "\n",
    "df_ewd2.info()\n",
    "data = df_ewd2.values\n",
    "data.shape\n",
    "\n",
    "features = df_ewd2.drop('class', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split data:\n",
    "train_ratio = 0.75\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.10\n",
    "\n",
    "# train is now 75% of the entire data set\n",
    "# the _junk suffix means that we drop that variable completely\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=1 - train_ratio, random_state = 30, stratify = Y)\n",
    "\n",
    "# test is now 10% of the initial data set\n",
    "# validation is now 15% of the initial data set\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio), random_state = 30, stratify = y_test)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(df_ewd2['class'])) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ',Counter(y_test)) \n",
    "print('Class representation - validation data: ',Counter(y_val))\n",
    "\n",
    "print(x_train.shape, x_val.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee130c0",
   "metadata": {},
   "source": [
    "### Models, EWD, k=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8eb9deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       114\n",
      "           1       0.95      0.90      0.93       115\n",
      "           2       0.92      0.96      0.94       114\n",
      "           3       0.94      0.95      0.94       106\n",
      "           4       0.97      0.99      0.98       114\n",
      "           5       0.94      0.94      0.94       105\n",
      "           6       0.98      0.99      0.99       106\n",
      "           7       0.97      0.96      0.97       114\n",
      "           8       0.99      0.97      0.98       106\n",
      "           9       0.93      0.93      0.93       106\n",
      "\n",
      "    accuracy                           0.96      1100\n",
      "   macro avg       0.96      0.96      0.96      1100\n",
      "weighted avg       0.96      0.96      0.96      1100\n",
      "\n",
      "Time for training model ID3 - default, EWD, k = 7 is: 0.6859009265899658.\n"
     ]
    }
   ],
   "source": [
    "# ID3 - Default\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "model_id3 = Id3Estimator()\n",
    "model_id3.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_id3 = model_id3.predict(x_test)\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model ID3 - default, {disc}, k = {k} is: {end - start}.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7182d763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92       114\n",
      "           1       0.74      0.69      0.71       115\n",
      "           2       0.80      0.94      0.86       114\n",
      "           3       0.88      0.95      0.91       106\n",
      "           4       1.00      0.96      0.98       114\n",
      "           5       0.90      0.58      0.71       105\n",
      "           6       0.97      0.98      0.98       106\n",
      "           7       0.96      0.89      0.92       114\n",
      "           8       0.87      0.82      0.84       106\n",
      "           9       0.75      0.97      0.84       106\n",
      "\n",
      "    accuracy                           0.87      1100\n",
      "   macro avg       0.88      0.87      0.87      1100\n",
      "weighted avg       0.88      0.87      0.87      1100\n",
      "\n",
      "Time for training model Naive Bayes - default, EWD, k = 7 is: 0.018597841262817383.\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes - Default\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "model_nb = CategoricalNB()\n",
    "model_nb.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_nb = model_nb.predict(x_test)\n",
    "model_nb.classes_\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "end = time.time()\n",
    "print(f'Time for training model Naive Bayes - default, {disc}, k = {k} is: {end - start}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "227d0aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       0.84      0.76      0.80        42\n",
      "           2       0.85      0.96      0.90        46\n",
      "           3       0.84      0.96      0.90        50\n",
      "           4       0.98      0.93      0.96        58\n",
      "           5       0.91      0.82      0.86        50\n",
      "           6       0.94      0.98      0.96        46\n",
      "           7       0.87      0.98      0.92        53\n",
      "           8       1.00      0.89      0.94        44\n",
      "           9       0.91      0.84      0.87        61\n",
      "\n",
      "    accuracy                           0.91       500\n",
      "   macro avg       0.91      0.91      0.91       500\n",
      "weighted avg       0.92      0.91      0.91       500\n",
      "\n",
      "Time for training model Knn-VDM, EWD, k = 7 is: 482.4279270172119.\n"
     ]
    }
   ],
   "source": [
    "# Knn-VDM complete code - TRY SAMPLE 500\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(x_train[:500,:], y_train[:500], continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "## Fit model\n",
    "knn_vdm.fit(x_train[:500,:], y_train[:500])\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(x_test[:500,:])\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test[:500], y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM, {disc}, k = {k} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f8d5b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation result, accuracy, EWD, k = 7.\n",
      "ID3, validation accuracy:, 0.9672330097087378\n",
      "CNB, validation accuracy:, 0.8713592233009708\n"
     ]
    }
   ],
   "source": [
    "# VALIDATION\n",
    "scores = 'accuracy'\n",
    "print(f'Validation result, {scores}, {disc}, k = {k}.')\n",
    "# Create list of algorithms\n",
    "models = []\n",
    "models.append(('ID3', model_id3))\n",
    "models.append(('CNB', model_nb))\n",
    "#models.append(('Knn-VDM', KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')))\n",
    "\n",
    "# Evaluate each model in turn\n",
    "# get predicted prices on validation data\n",
    "for name, model in models:\n",
    "    val_pred = model.predict(x_val)\n",
    "    val_results = metrics.accuracy_score(y_val, val_pred)\n",
    "    print(f'{name}, validation accuracy:, {val_results}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b187b3f3",
   "metadata": {},
   "source": [
    "### Evaluation, EWD, k= 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99b004be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "64306a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.052\n",
      "Average bias: 0.021\n",
      "Average variance: 0.044\n",
      "Sklearn 0-1 loss: 0.042\n"
     ]
    }
   ],
   "source": [
    "# ID3\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_id3, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5ae6dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.129\n",
      "Average bias: 0.129\n",
      "Average variance: 0.011\n",
      "Sklearn 0-1 loss: 0.129\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_nb, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d9296c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Knn - SAMPLE 500 - WARNING: LONG TIME (>> 1 HOURS)\n",
    "# import time\n",
    "# start = time.time() # For measuring time execution\n",
    "\n",
    "# avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "# knn_vdm, x_train[:500,:], y_train[:500], x_test[:500,:], y_test[:500],\n",
    "# loss='0-1_loss',\n",
    "# random_seed=123)\n",
    "# #---\n",
    "# print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "# print('Average bias: %.3f' % avg_bias)\n",
    "# print('Average variance: %.3f' % avg_var)\n",
    "# print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))\n",
    "\n",
    "# end = time.time()\n",
    "# print(f'Time for evaluation model Knn-VDM, {disc}, k = {k} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa5bbd8",
   "metadata": {},
   "source": [
    "## EWD, k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e7a7655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10992 entries, 0 to 10991\n",
      "Data columns (total 17 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   A1      10992 non-null  int64\n",
      " 1   A2      10992 non-null  int64\n",
      " 2   A3      10992 non-null  int64\n",
      " 3   A4      10992 non-null  int64\n",
      " 4   A5      10992 non-null  int64\n",
      " 5   A6      10992 non-null  int64\n",
      " 6   A7      10992 non-null  int64\n",
      " 7   A8      10992 non-null  int64\n",
      " 8   A9      10992 non-null  int64\n",
      " 9   A10     10992 non-null  int64\n",
      " 10  A11     10992 non-null  int64\n",
      " 11  A12     10992 non-null  int64\n",
      " 12  A13     10992 non-null  int64\n",
      " 13  A14     10992 non-null  int64\n",
      " 14  A15     10992 non-null  int64\n",
      " 15  A16     10992 non-null  int64\n",
      " 16  class   10992 non-null  int64\n",
      "dtypes: int64(17)\n",
      "memory usage: 1.4 MB\n",
      "(10992, 16) (10992,)\n",
      "Class representation - original:  Counter({2: 1144, 4: 1144, 1: 1143, 0: 1143, 7: 1142, 6: 1056, 8: 1055, 5: 1055, 9: 1055, 3: 1055})\n",
      "Class representation - training data:  Counter({4: 858, 2: 858, 0: 857, 1: 857, 7: 857, 5: 792, 6: 792, 3: 791, 8: 791, 9: 791})\n",
      "Class representation - testing data:  Counter({1: 115, 7: 114, 4: 114, 2: 114, 0: 114, 6: 106, 3: 106, 9: 106, 8: 106, 5: 105})\n",
      "Class representation - validation data:  Counter({4: 172, 0: 172, 2: 172, 1: 171, 7: 171, 8: 158, 6: 158, 5: 158, 3: 158, 9: 158})\n",
      "(8244, 16) (1648, 16) (1100, 16)\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_ewd3 = pd.read_csv('pendigits_ewd3.csv')\n",
    "disc = 'EWD'\n",
    "k = 10\n",
    "\n",
    "df_ewd3.info()\n",
    "data = df_ewd3.values\n",
    "data.shape\n",
    "\n",
    "features = df_ewd3.drop('class', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split data:\n",
    "train_ratio = 0.75\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.10\n",
    "\n",
    "# train is now 75% of the entire data set\n",
    "# the _junk suffix means that we drop that variable completely\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=1 - train_ratio, random_state = 30, stratify = Y)\n",
    "\n",
    "# test is now 10% of the initial data set\n",
    "# validation is now 15% of the initial data set\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio), random_state = 30, stratify = y_test)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(df_ewd3['class'])) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ',Counter(y_test)) \n",
    "print('Class representation - validation data: ',Counter(y_val))\n",
    "\n",
    "print(x_train.shape, x_val.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8aa093",
   "metadata": {},
   "source": [
    "### Models, EWD, k=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f08b8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       114\n",
      "           1       0.82      0.88      0.85       115\n",
      "           2       0.92      0.89      0.90       114\n",
      "           3       0.96      0.94      0.95       106\n",
      "           4       0.97      0.96      0.96       114\n",
      "           5       0.94      0.94      0.94       105\n",
      "           6       0.98      0.98      0.98       106\n",
      "           7       0.95      0.97      0.96       114\n",
      "           8       0.97      0.96      0.97       106\n",
      "           9       0.92      0.91      0.91       106\n",
      "\n",
      "    accuracy                           0.94      1100\n",
      "   macro avg       0.94      0.94      0.94      1100\n",
      "weighted avg       0.94      0.94      0.94      1100\n",
      "\n",
      "Time for training model ID3 - default, EWD, k = 10 is: 0.7593410015106201.\n"
     ]
    }
   ],
   "source": [
    "# ID3 - Default\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "model_id3 = Id3Estimator()\n",
    "model_id3.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_id3 = model_id3.predict(x_test)\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model ID3 - default, {disc}, k = {k} is: {end - start}.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f97c293b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92       114\n",
      "           1       0.75      0.69      0.71       115\n",
      "           2       0.81      0.93      0.87       114\n",
      "           3       0.88      0.98      0.93       106\n",
      "           4       1.00      0.96      0.98       114\n",
      "           5       0.88      0.58      0.70       105\n",
      "           6       0.98      0.98      0.98       106\n",
      "           7       0.96      0.89      0.92       114\n",
      "           8       0.85      0.82      0.84       106\n",
      "           9       0.74      0.97      0.84       106\n",
      "\n",
      "    accuracy                           0.87      1100\n",
      "   macro avg       0.88      0.87      0.87      1100\n",
      "weighted avg       0.88      0.87      0.87      1100\n",
      "\n",
      "Time for training model Naive Bayes - default, EWD, k = 10 is: 0.017505884170532227.\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes - Default\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "model_nb = CategoricalNB()\n",
    "model_nb.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_nb = model_nb.predict(x_test)\n",
    "model_nb.classes_\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "end = time.time()\n",
    "print(f'Time for training model Naive Bayes - default, {disc}, k = {k} is: {end - start}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce7c8398",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1.0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-48975f37ca5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mknn_vdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0my_pred_knn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn_vdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mknn_vdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_knn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/neighbors/_classification.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mdata\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \"\"\"\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0m_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    750\u001b[0m                 \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meffective_metric_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m             chunked_results = list(\n\u001b[0m\u001b[1;32m    753\u001b[0m                 pairwise_distances_chunked(\n\u001b[1;32m    754\u001b[0m                     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[1;32m   1715\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1716\u001b[0m             \u001b[0mX_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1717\u001b[0;31m         \u001b[0mD_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpairwise_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1718\u001b[0m         if (X is Y or Y is None) and PAIRWISE_DISTANCE_FUNCTIONS.get(\n\u001b[1;32m   1719\u001b[0m             \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[0;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   1887\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1889\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m     \u001b[0;31m# enforce a threading backend to prevent data communication overhead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_pairwise_callable\u001b[0;34m(X, Y, metric, force_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   1472\u001b[0m         \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1474\u001b[0;31m             \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/vdm3/vdm.py\u001b[0m in \u001b[0;36mget_distance\u001b[0;34m(self, ins_1, ins_2, norm)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mins_2_cat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mcat_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_delta_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcond_proba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mins_1_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mins_2_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontinuous\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/vdm3/components.py\u001b[0m in \u001b[0;36mget_delta_nd\u001b[0;34m(cond_proba, ins_1, ins_2, norm)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mReturns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdeltas\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0mbetween\u001b[0m \u001b[0mins_1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mins_2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \"\"\"\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mdeltas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mget_delta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond_proba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mins_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mins_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcond_proba\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeltas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/vdm3/components.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mReturns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdeltas\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0mbetween\u001b[0m \u001b[0mins_1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mins_2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \"\"\"\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mdeltas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mget_delta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond_proba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mins_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mins_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcond_proba\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeltas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/vdm3/components.py\u001b[0m in \u001b[0;36mget_delta\u001b[0;34m(cond_proba, val_1, val_2, norm)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mReturns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthis\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \"\"\"\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond_proba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muni_x\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcond_proba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muni_x\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0muni_x\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcond_proba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mproba\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1.0"
     ]
    }
   ],
   "source": [
    "# Knn-VDM complete code - TRY SAMPLE 500\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(x_train[:500,:], y_train[:500], continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "## Fit model\n",
    "knn_vdm.fit(x_train[:500,:], y_train[:500])\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(x_test[:500,:])\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test[:500], y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM, {disc}, k = {k} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "43bb9402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation result, accuracy, EWD, k = 10.\n",
      "ID3, validation accuracy:, 0.9641990291262136\n",
      "CNB, validation accuracy:, 0.8774271844660194\n"
     ]
    }
   ],
   "source": [
    "# VALIDATION\n",
    "scores = 'accuracy'\n",
    "print(f'Validation result, {scores}, {disc}, k = {k}.')\n",
    "# Create list of algorithms\n",
    "models = []\n",
    "models.append(('ID3', model_id3))\n",
    "models.append(('CNB', model_nb))\n",
    "# models.append(('Knn-VDM', KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')))\n",
    "\n",
    "# Evaluate each model in turn\n",
    "# get predicted prices on validation data\n",
    "for name, model in models:\n",
    "    val_pred = model.predict(x_val)\n",
    "    val_results = metrics.accuracy_score(y_val, val_pred)\n",
    "    print(f'{name}, validation accuracy:, {val_results}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ab2bb1",
   "metadata": {},
   "source": [
    "### Evaluation, EWD, k= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8cb06315",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "972fce3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.052\n",
      "Average bias: 0.023\n",
      "Average variance: 0.044\n",
      "Sklearn 0-1 loss: 0.059\n"
     ]
    }
   ],
   "source": [
    "# ID3\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_id3, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5d8a1e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.127\n",
      "Average bias: 0.126\n",
      "Average variance: 0.014\n",
      "Sklearn 0-1 loss: 0.127\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_nb, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "36660484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Knn\n",
    "# avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "# knn_vdm, x_train, y_train, x_test, y_test,\n",
    "# loss='0-1_loss',\n",
    "# random_seed=123)\n",
    "# #---\n",
    "# print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "# print('Average bias: %.3f' % avg_bias)\n",
    "# print('Average variance: %.3f' % avg_var)\n",
    "# print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc73dbb8",
   "metadata": {},
   "source": [
    "# EFD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e0ab18",
   "metadata": {},
   "source": [
    "## EFD, k = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65e34739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10992 entries, 0 to 10991\n",
      "Data columns (total 17 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   A1      10992 non-null  int64\n",
      " 1   A2      10992 non-null  int64\n",
      " 2   A3      10992 non-null  int64\n",
      " 3   A4      10992 non-null  int64\n",
      " 4   A5      10992 non-null  int64\n",
      " 5   A6      10992 non-null  int64\n",
      " 6   A7      10992 non-null  int64\n",
      " 7   A8      10992 non-null  int64\n",
      " 8   A9      10992 non-null  int64\n",
      " 9   A10     10992 non-null  int64\n",
      " 10  A11     10992 non-null  int64\n",
      " 11  A12     10992 non-null  int64\n",
      " 12  A13     10992 non-null  int64\n",
      " 13  A14     10992 non-null  int64\n",
      " 14  A15     10992 non-null  int64\n",
      " 15  A16     10992 non-null  int64\n",
      " 16  class   10992 non-null  int64\n",
      "dtypes: int64(17)\n",
      "memory usage: 1.4 MB\n",
      "(10992, 16) (10992,)\n",
      "Class representation - original:  Counter({2: 1144, 4: 1144, 1: 1143, 0: 1143, 7: 1142, 6: 1056, 8: 1055, 5: 1055, 9: 1055, 3: 1055})\n",
      "Class representation - training data:  Counter({4: 858, 2: 858, 0: 857, 1: 857, 7: 857, 5: 792, 6: 792, 3: 791, 8: 791, 9: 791})\n",
      "Class representation - testing data:  Counter({1: 115, 7: 114, 4: 114, 2: 114, 0: 114, 6: 106, 3: 106, 9: 106, 8: 106, 5: 105})\n",
      "Class representation - validation data:  Counter({4: 172, 0: 172, 2: 172, 1: 171, 7: 171, 8: 158, 6: 158, 5: 158, 3: 158, 9: 158})\n",
      "(8244, 16) (1648, 16) (1100, 16)\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_efd1 = pd.read_csv('pendigits_efd1.csv')\n",
    "disc = 'EFD'\n",
    "k = 4\n",
    "\n",
    "df_efd1.info()\n",
    "data = df_efd1.values\n",
    "data.shape\n",
    "\n",
    "features = df_efd1.drop('class', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split data:\n",
    "train_ratio = 0.75\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.10\n",
    "\n",
    "# train is now 75% of the entire data set\n",
    "# the _junk suffix means that we drop that variable completely\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=1 - train_ratio, random_state = 30, stratify = Y)\n",
    "\n",
    "# test is now 10% of the initial data set\n",
    "# validation is now 15% of the initial data set\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio), random_state = 30, stratify = y_test)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(df_efd1['class'])) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ',Counter(y_test)) \n",
    "print('Class representation - validation data: ',Counter(y_val))\n",
    "\n",
    "print(x_train.shape, x_val.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619010db",
   "metadata": {},
   "source": [
    "### Models, EFD, k=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cd064cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       114\n",
      "           1       0.91      0.90      0.90       115\n",
      "           2       0.92      0.96      0.94       114\n",
      "           3       0.93      0.96      0.94       106\n",
      "           4       0.97      0.96      0.97       114\n",
      "           5       0.95      0.90      0.92       105\n",
      "           6       0.98      1.00      0.99       106\n",
      "           7       0.96      0.94      0.95       114\n",
      "           8       0.96      0.95      0.96       106\n",
      "           9       0.93      0.94      0.93       106\n",
      "\n",
      "    accuracy                           0.95      1100\n",
      "   macro avg       0.95      0.95      0.95      1100\n",
      "weighted avg       0.95      0.95      0.95      1100\n",
      "\n",
      "Time for training model ID3 - default, EFD, k = 4 is: 0.6160540580749512.\n"
     ]
    }
   ],
   "source": [
    "# ID3 - Default\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "model_id3 = Id3Estimator()\n",
    "model_id3.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_id3 = model_id3.predict(x_test)\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model ID3 - default, {disc}, k = {k} is: {end - start}.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e9ad8a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90       114\n",
      "           1       0.71      0.69      0.70       115\n",
      "           2       0.81      0.89      0.85       114\n",
      "           3       0.88      0.95      0.91       106\n",
      "           4       0.98      0.96      0.97       114\n",
      "           5       0.84      0.55      0.67       105\n",
      "           6       0.99      0.95      0.97       106\n",
      "           7       0.95      0.84      0.89       114\n",
      "           8       0.81      0.77      0.79       106\n",
      "           9       0.72      0.96      0.82       106\n",
      "\n",
      "    accuracy                           0.85      1100\n",
      "   macro avg       0.86      0.85      0.85      1100\n",
      "weighted avg       0.86      0.85      0.85      1100\n",
      "\n",
      "Time for training model Naive Bayes - default, EFD, k = 4 is: 0.020608901977539062.\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes - Default\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "model_nb = CategoricalNB()\n",
    "model_nb.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_nb = model_nb.predict(x_test)\n",
    "model_nb.classes_\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "end = time.time()\n",
    "print(f'Time for training model Naive Bayes - default, {disc}, k = {k} is: {end - start}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a05b6ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98        50\n",
      "           1       0.69      0.88      0.77        42\n",
      "           2       0.93      0.91      0.92        46\n",
      "           3       0.94      0.98      0.96        50\n",
      "           4       0.98      0.93      0.96        58\n",
      "           5       0.94      0.88      0.91        50\n",
      "           6       0.92      1.00      0.96        46\n",
      "           7       0.93      0.94      0.93        53\n",
      "           8       0.97      0.84      0.90        44\n",
      "           9       0.95      0.89      0.92        61\n",
      "\n",
      "    accuracy                           0.92       500\n",
      "   macro avg       0.92      0.92      0.92       500\n",
      "weighted avg       0.93      0.92      0.92       500\n",
      "\n",
      "Time for training model Knn-VDM, EFD, k = 4 is: 485.34148502349854.\n"
     ]
    }
   ],
   "source": [
    "# Knn-VDM complete code - TRY SAMPLE 500\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(x_train[:500,:], y_train[:500], continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "## Fit model\n",
    "knn_vdm.fit(x_train[:500,:], y_train[:500])\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(x_test[:500,:])\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test[:500], y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM, {disc}, k = {k} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6d41f76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation result, accuracy, EFD, k = 4.\n",
      "ID3, validation accuracy:, 0.9550970873786407\n",
      "CNB, validation accuracy:, 0.8555825242718447\n"
     ]
    }
   ],
   "source": [
    "# VALIDATION\n",
    "scores = 'accuracy'\n",
    "print(f'Validation result, {scores}, {disc}, k = {k}.')\n",
    "# Create list of algorithms\n",
    "models = []\n",
    "models.append(('ID3', model_id3))\n",
    "models.append(('CNB', model_nb))\n",
    "# models.append(('Knn-VDM', KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')))\n",
    "\n",
    "# Evaluate each model in turn\n",
    "# get predicted prices on validation data\n",
    "for name, model in models:\n",
    "    val_pred = model.predict(x_val)\n",
    "    val_results = metrics.accuracy_score(y_val, val_pred)\n",
    "    print(f'{name}, validation accuracy:, {val_results}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35644998",
   "metadata": {},
   "source": [
    "### Evaluation, EFD, k=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "546cf9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b8a62c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.062\n",
      "Average bias: 0.026\n",
      "Average variance: 0.051\n",
      "Sklearn 0-1 loss: 0.050\n"
     ]
    }
   ],
   "source": [
    "# ID3\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_id3, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "88c2ab65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.150\n",
      "Average bias: 0.147\n",
      "Average variance: 0.015\n",
      "Sklearn 0-1 loss: 0.149\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_nb, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a5a2f725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Knn\n",
    "# avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "# knn_vdm, x_train, y_train, x_test, y_test,\n",
    "# loss='0-1_loss',\n",
    "# random_seed=123)\n",
    "# #---\n",
    "# print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "# print('Average bias: %.3f' % avg_bias)\n",
    "# print('Average variance: %.3f' % avg_var)\n",
    "# print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927b824b",
   "metadata": {},
   "source": [
    "## EFD, k = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc402ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10992 entries, 0 to 10991\n",
      "Data columns (total 17 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   A1      10992 non-null  int64\n",
      " 1   A2      10992 non-null  int64\n",
      " 2   A3      10992 non-null  int64\n",
      " 3   A4      10992 non-null  int64\n",
      " 4   A5      10992 non-null  int64\n",
      " 5   A6      10992 non-null  int64\n",
      " 6   A7      10992 non-null  int64\n",
      " 7   A8      10992 non-null  int64\n",
      " 8   A9      10992 non-null  int64\n",
      " 9   A10     10992 non-null  int64\n",
      " 10  A11     10992 non-null  int64\n",
      " 11  A12     10992 non-null  int64\n",
      " 12  A13     10992 non-null  int64\n",
      " 13  A14     10992 non-null  int64\n",
      " 14  A15     10992 non-null  int64\n",
      " 15  A16     10992 non-null  int64\n",
      " 16  class   10992 non-null  int64\n",
      "dtypes: int64(17)\n",
      "memory usage: 1.4 MB\n",
      "(10992, 16) (10992,)\n",
      "Class representation - original:  Counter({2: 1144, 4: 1144, 1: 1143, 0: 1143, 7: 1142, 6: 1056, 8: 1055, 5: 1055, 9: 1055, 3: 1055})\n",
      "Class representation - training data:  Counter({4: 858, 2: 858, 0: 857, 1: 857, 7: 857, 5: 792, 6: 792, 3: 791, 8: 791, 9: 791})\n",
      "Class representation - testing data:  Counter({1: 115, 7: 114, 4: 114, 2: 114, 0: 114, 6: 106, 3: 106, 9: 106, 8: 106, 5: 105})\n",
      "Class representation - validation data:  Counter({4: 172, 0: 172, 2: 172, 1: 171, 7: 171, 8: 158, 6: 158, 5: 158, 3: 158, 9: 158})\n",
      "(8244, 16) (1648, 16) (1100, 16)\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_efd2 = pd.read_csv('pendigits_efd2.csv')\n",
    "disc = 'EFD'\n",
    "k = 7\n",
    "\n",
    "df_efd2.info()\n",
    "data = df_efd2.values\n",
    "data.shape\n",
    "\n",
    "features = df_efd2.drop('class', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split data:\n",
    "train_ratio = 0.75\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.10\n",
    "\n",
    "# train is now 75% of the entire data set\n",
    "# the _junk suffix means that we drop that variable completely\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=1 - train_ratio, random_state = 30, stratify = Y)\n",
    "\n",
    "# test is now 10% of the initial data set\n",
    "# validation is now 15% of the initial data set\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio), random_state = 30, stratify = y_test)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(df_efd2['class'])) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ',Counter(y_test)) \n",
    "print('Class representation - validation data: ',Counter(y_val))\n",
    "\n",
    "print(x_train.shape, x_val.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abd578a",
   "metadata": {},
   "source": [
    "### Models, EFD, k=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e8e73906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       114\n",
      "           1       0.91      0.92      0.92       115\n",
      "           2       0.97      0.95      0.96       114\n",
      "           3       0.96      0.96      0.96       106\n",
      "           4       0.98      0.98      0.98       114\n",
      "           5       0.94      0.94      0.94       105\n",
      "           6       1.00      1.00      1.00       106\n",
      "           7       0.93      0.97      0.95       114\n",
      "           8       0.99      0.95      0.97       106\n",
      "           9       0.93      0.93      0.93       106\n",
      "\n",
      "    accuracy                           0.96      1100\n",
      "   macro avg       0.96      0.96      0.96      1100\n",
      "weighted avg       0.96      0.96      0.96      1100\n",
      "\n",
      "Time for training model ID3 - default, EFD, k = 7 is: 0.6947641372680664.\n"
     ]
    }
   ],
   "source": [
    "# ID3 - Default\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "model_id3 = Id3Estimator()\n",
    "model_id3.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_id3 = model_id3.predict(x_test)\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model ID3 - default, {disc}, k = {k} is: {end - start}.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "66d2af2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93       114\n",
      "           1       0.75      0.70      0.72       115\n",
      "           2       0.81      0.91      0.86       114\n",
      "           3       0.84      0.95      0.89       106\n",
      "           4       1.00      0.96      0.98       114\n",
      "           5       0.88      0.58      0.70       105\n",
      "           6       0.98      0.98      0.98       106\n",
      "           7       0.93      0.88      0.90       114\n",
      "           8       0.86      0.81      0.83       106\n",
      "           9       0.73      0.95      0.83       106\n",
      "\n",
      "    accuracy                           0.87      1100\n",
      "   macro avg       0.87      0.87      0.86      1100\n",
      "weighted avg       0.87      0.87      0.86      1100\n",
      "\n",
      "Time for training model Naive Bayes - default, EFD, k = 7 is: 0.01694202423095703.\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes - Default\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "model_nb = CategoricalNB()\n",
    "model_nb.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_nb = model_nb.predict(x_test)\n",
    "model_nb.classes_\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "end = time.time()\n",
    "print(f'Time for training model Naive Bayes - default, {disc}, k = {k} is: {end - start}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc24a0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97        50\n",
      "           1       0.80      0.93      0.86        42\n",
      "           2       0.95      0.91      0.93        46\n",
      "           3       0.86      1.00      0.93        50\n",
      "           4       0.95      0.90      0.92        58\n",
      "           5       0.98      0.86      0.91        50\n",
      "           6       0.94      0.96      0.95        46\n",
      "           7       0.89      0.96      0.93        53\n",
      "           8       0.98      0.91      0.94        44\n",
      "           9       0.95      0.87      0.91        61\n",
      "\n",
      "    accuracy                           0.92       500\n",
      "   macro avg       0.93      0.93      0.92       500\n",
      "weighted avg       0.93      0.92      0.92       500\n",
      "\n",
      "Time for training model Knn-VDM, EFD, k = 7 is: 481.2034821510315.\n"
     ]
    }
   ],
   "source": [
    "# Knn-VDM complete code - TRY SAMPLE 500\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(x_train[:500,:], y_train[:500], continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "## Fit model\n",
    "knn_vdm.fit(x_train[:500,:], y_train[:500])\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(x_test[:500,:])\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test[:500], y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM, {disc}, k = {k} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7c3cfb40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation result, accuracy, EFD, k = 7.\n",
      "ID3, validation accuracy:, 0.9557038834951457\n",
      "CNB, validation accuracy:, 0.8756067961165048\n"
     ]
    }
   ],
   "source": [
    "# VALIDATION\n",
    "scores = 'accuracy'\n",
    "print(f'Validation result, {scores}, {disc}, k = {k}.')\n",
    "# Create list of algorithms\n",
    "models = []\n",
    "models.append(('ID3', model_id3))\n",
    "models.append(('CNB', model_nb))\n",
    "# models.append(('Knn-VDM', KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')))\n",
    "\n",
    "# Evaluate each model in turn\n",
    "# get predicted prices on validation data\n",
    "for name, model in models:\n",
    "    val_pred = model.predict(x_val)\n",
    "    val_results = metrics.accuracy_score(y_val, val_pred)\n",
    "    print(f'{name}, validation accuracy:, {val_results}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91993882",
   "metadata": {},
   "source": [
    "### Evaluation, EFD, k=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7b0a4e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a5ec29b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.057\n",
      "Average bias: 0.022\n",
      "Average variance: 0.047\n",
      "Sklearn 0-1 loss: 0.040\n"
     ]
    }
   ],
   "source": [
    "# ID3\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_id3, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7bffd545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.132\n",
      "Average bias: 0.134\n",
      "Average variance: 0.011\n",
      "Sklearn 0-1 loss: 0.134\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_nb, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ae103676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Knn\n",
    "# avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "# knn_vdm, x_train, y_train, x_test, y_test,\n",
    "# loss='0-1_loss',\n",
    "# random_seed=123)\n",
    "# #---\n",
    "# print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "# print('Average bias: %.3f' % avg_bias)\n",
    "# print('Average variance: %.3f' % avg_var)\n",
    "# print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98edc4d0",
   "metadata": {},
   "source": [
    "## EFD, k =10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36f71230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10992 entries, 0 to 10991\n",
      "Data columns (total 17 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   A1      10992 non-null  int64\n",
      " 1   A2      10992 non-null  int64\n",
      " 2   A3      10992 non-null  int64\n",
      " 3   A4      10992 non-null  int64\n",
      " 4   A5      10992 non-null  int64\n",
      " 5   A6      10992 non-null  int64\n",
      " 6   A7      10992 non-null  int64\n",
      " 7   A8      10992 non-null  int64\n",
      " 8   A9      10992 non-null  int64\n",
      " 9   A10     10992 non-null  int64\n",
      " 10  A11     10992 non-null  int64\n",
      " 11  A12     10992 non-null  int64\n",
      " 12  A13     10992 non-null  int64\n",
      " 13  A14     10992 non-null  int64\n",
      " 14  A15     10992 non-null  int64\n",
      " 15  A16     10992 non-null  int64\n",
      " 16  class   10992 non-null  int64\n",
      "dtypes: int64(17)\n",
      "memory usage: 1.4 MB\n",
      "(10992, 16) (10992,)\n",
      "Class representation - original:  Counter({2: 1144, 4: 1144, 1: 1143, 0: 1143, 7: 1142, 6: 1056, 8: 1055, 5: 1055, 9: 1055, 3: 1055})\n",
      "Class representation - training data:  Counter({4: 858, 2: 858, 0: 857, 1: 857, 7: 857, 5: 792, 6: 792, 3: 791, 8: 791, 9: 791})\n",
      "Class representation - testing data:  Counter({1: 115, 7: 114, 4: 114, 2: 114, 0: 114, 6: 106, 3: 106, 9: 106, 8: 106, 5: 105})\n",
      "Class representation - validation data:  Counter({4: 172, 0: 172, 2: 172, 1: 171, 7: 171, 8: 158, 6: 158, 5: 158, 3: 158, 9: 158})\n",
      "(8244, 16) (1648, 16) (1100, 16)\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_efd3 = pd.read_csv('pendigits_efd3.csv')\n",
    "disc = 'EFD'\n",
    "k = 10\n",
    "\n",
    "df_efd3.info()\n",
    "data = df_efd3.values\n",
    "data.shape\n",
    "\n",
    "features = df_efd3.drop('class', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split data:\n",
    "train_ratio = 0.75\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.10\n",
    "\n",
    "# train is now 75% of the entire data set\n",
    "# the _junk suffix means that we drop that variable completely\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=1 - train_ratio, random_state = 30, stratify = Y)\n",
    "\n",
    "# test is now 10% of the initial data set\n",
    "# validation is now 15% of the initial data set\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio), random_state = 30, stratify = y_test)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(df_efd3['class'])) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ',Counter(y_test)) \n",
    "print('Class representation - validation data: ',Counter(y_val))\n",
    "\n",
    "print(x_train.shape, x_val.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816a9ff9",
   "metadata": {},
   "source": [
    "### Models, EFD, k=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dc637e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       114\n",
      "           1       0.93      0.90      0.91       115\n",
      "           2       0.92      0.96      0.94       114\n",
      "           3       0.93      0.96      0.94       106\n",
      "           4       0.98      0.98      0.98       114\n",
      "           5       0.96      0.93      0.95       105\n",
      "           6       0.98      0.97      0.98       106\n",
      "           7       0.95      0.99      0.97       114\n",
      "           8       0.98      0.94      0.96       106\n",
      "           9       0.94      0.93      0.94       106\n",
      "\n",
      "    accuracy                           0.96      1100\n",
      "   macro avg       0.96      0.96      0.96      1100\n",
      "weighted avg       0.96      0.96      0.96      1100\n",
      "\n",
      "Time for training model ID3 - default, EFD, k = 10 is: 0.780156135559082.\n"
     ]
    }
   ],
   "source": [
    "# ID3 - Default\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "model_id3 = Id3Estimator()\n",
    "model_id3.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_id3 = model_id3.predict(x_test)\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model ID3 - default, {disc}, k = {k} is: {end - start}.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "40eb5a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.93       114\n",
      "           1       0.77      0.71      0.74       115\n",
      "           2       0.82      0.93      0.87       114\n",
      "           3       0.87      0.96      0.91       106\n",
      "           4       0.99      0.97      0.98       114\n",
      "           5       0.91      0.61      0.73       105\n",
      "           6       0.97      0.99      0.98       106\n",
      "           7       0.96      0.88      0.92       114\n",
      "           8       0.90      0.85      0.87       106\n",
      "           9       0.75      1.00      0.85       106\n",
      "\n",
      "    accuracy                           0.88      1100\n",
      "   macro avg       0.89      0.88      0.88      1100\n",
      "weighted avg       0.89      0.88      0.88      1100\n",
      "\n",
      "Time for training model Naive Bayes - default, EFD, k = 10 is: 0.018495798110961914.\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes - Default\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "model_nb = CategoricalNB()\n",
    "model_nb.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_nb = model_nb.predict(x_test)\n",
    "model_nb.classes_\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "end = time.time()\n",
    "print(f'Time for training model Naive Bayes - default, {disc}, k = {k} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07c74b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        50\n",
      "           1       0.78      0.93      0.85        42\n",
      "           2       0.93      0.85      0.89        46\n",
      "           3       0.86      0.98      0.92        50\n",
      "           4       0.96      0.91      0.94        58\n",
      "           5       0.96      0.88      0.92        50\n",
      "           6       0.94      0.96      0.95        46\n",
      "           7       0.88      0.96      0.92        53\n",
      "           8       0.97      0.86      0.92        44\n",
      "           9       0.95      0.89      0.92        61\n",
      "\n",
      "    accuracy                           0.92       500\n",
      "   macro avg       0.92      0.92      0.92       500\n",
      "weighted avg       0.93      0.92      0.92       500\n",
      "\n",
      "Time for training model Knn-VDM, EFD, k = 10 is: 496.08610677719116.\n"
     ]
    }
   ],
   "source": [
    "# Knn-VDM complete code - TRY SAMPLE 500\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(x_train[:500,:], y_train[:500], continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "## Fit model\n",
    "knn_vdm.fit(x_train[:500,:], y_train[:500])\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(x_test[:500,:])\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test[:500], y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM, {disc}, k = {k} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6b9aec18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation result, accuracy, EFD, k = 10.\n",
      "ID3, validation accuracy:, 0.9587378640776699\n",
      "CNB, validation accuracy:, 0.8786407766990292\n"
     ]
    }
   ],
   "source": [
    "# VALIDATION\n",
    "scores = 'accuracy'\n",
    "print(f'Validation result, {scores}, {disc}, k = {k}.')\n",
    "# Create list of algorithms\n",
    "models = []\n",
    "models.append(('ID3', model_id3))\n",
    "models.append(('CNB', model_nb))\n",
    "# models.append(('Knn-VDM', KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')))\n",
    "\n",
    "# Evaluate each model in turn\n",
    "# get predicted prices on validation data\n",
    "for name, model in models:\n",
    "    val_pred = model.predict(x_val)\n",
    "    val_results = metrics.accuracy_score(y_val, val_pred)\n",
    "    print(f'{name}, validation accuracy:, {val_results}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffbf2bf",
   "metadata": {},
   "source": [
    "### Evaluation, EFD, k= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e26b33c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "64029a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.056\n",
      "Average bias: 0.024\n",
      "Average variance: 0.048\n",
      "Sklearn 0-1 loss: 0.044\n"
     ]
    }
   ],
   "source": [
    "# ID3\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_id3, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dd924eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.123\n",
      "Average bias: 0.117\n",
      "Average variance: 0.016\n",
      "Sklearn 0-1 loss: 0.117\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_nb, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d18ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knn-VDM complete code - TRY SAMPLE 500\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(x_train[:500,:], y_train[:500], continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "## Fit model\n",
    "knn_vdm.fit(x_train[:500,:], y_train[:500])\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(x_test[:500,:])\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test[:500], y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM, {disc}, k = {k} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "37d24da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Knn\n",
    "# avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "# knn_vdm, x_train, y_train, x_test, y_test,\n",
    "# loss='0-1_loss',\n",
    "# random_seed=123)\n",
    "# #---\n",
    "# print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "# print('Average bias: %.3f' % avg_bias)\n",
    "# print('Average variance: %.3f' % avg_var)\n",
    "# print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e44dc0",
   "metadata": {},
   "source": [
    "# FFD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c05353",
   "metadata": {},
   "source": [
    "## FFD, m =10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be3e8ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10992 entries, 0 to 10991\n",
      "Data columns (total 17 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   A1      10992 non-null  int64\n",
      " 1   A2      10992 non-null  int64\n",
      " 2   A3      10992 non-null  int64\n",
      " 3   A4      10992 non-null  int64\n",
      " 4   A5      10992 non-null  int64\n",
      " 5   A6      10992 non-null  int64\n",
      " 6   A7      10992 non-null  int64\n",
      " 7   A8      10992 non-null  int64\n",
      " 8   A9      10992 non-null  int64\n",
      " 9   A10     10992 non-null  int64\n",
      " 10  A11     10992 non-null  int64\n",
      " 11  A12     10992 non-null  int64\n",
      " 12  A13     10992 non-null  int64\n",
      " 13  A14     10992 non-null  int64\n",
      " 14  A15     10992 non-null  int64\n",
      " 15  A16     10992 non-null  int64\n",
      " 16  class   10992 non-null  int64\n",
      "dtypes: int64(17)\n",
      "memory usage: 1.4 MB\n",
      "(10992, 16) (10992,)\n",
      "Class representation - original:  Counter({2: 1144, 4: 1144, 1: 1143, 0: 1143, 7: 1142, 6: 1056, 8: 1055, 5: 1055, 9: 1055, 3: 1055})\n",
      "Class representation - training data:  Counter({4: 858, 2: 858, 0: 857, 1: 857, 7: 857, 5: 792, 6: 792, 3: 791, 8: 791, 9: 791})\n",
      "Class representation - testing data:  Counter({1: 115, 7: 114, 4: 114, 2: 114, 0: 114, 6: 106, 3: 106, 9: 106, 8: 106, 5: 105})\n",
      "Class representation - validation data:  Counter({4: 172, 0: 172, 2: 172, 1: 171, 7: 171, 8: 158, 6: 158, 5: 158, 3: 158, 9: 158})\n",
      "(8244, 16) (1648, 16) (1100, 16)\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_ffd1 = pd.read_csv('pendigits_ffd1.csv')\n",
    "disc = 'FFD'\n",
    "m = 10\n",
    "\n",
    "df_ffd1.info()\n",
    "data = df_ffd1.values\n",
    "data.shape\n",
    "\n",
    "features = df_ffd1.drop('class', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split data:\n",
    "train_ratio = 0.75\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.10\n",
    "\n",
    "# train is now 75% of the entire data set\n",
    "# the _junk suffix means that we drop that variable completely\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=1 - train_ratio, random_state = 30, stratify = Y)\n",
    "\n",
    "# test is now 10% of the initial data set\n",
    "# validation is now 15% of the initial data set\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio), random_state = 30, stratify = y_test)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(df_ffd1['class'])) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ',Counter(y_test)) \n",
    "print('Class representation - validation data: ',Counter(y_val))\n",
    "\n",
    "print(x_train.shape, x_val.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9b069e",
   "metadata": {},
   "source": [
    "### Models, FFD, m=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "df3d4096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       114\n",
      "           1       0.90      0.93      0.91       115\n",
      "           2       0.96      0.92      0.94       114\n",
      "           3       0.93      0.94      0.94       106\n",
      "           4       0.99      0.98      0.99       114\n",
      "           5       0.97      0.96      0.97       105\n",
      "           6       0.97      0.98      0.98       106\n",
      "           7       0.93      0.97      0.95       114\n",
      "           8       0.99      0.97      0.98       106\n",
      "           9       0.94      0.93      0.94       106\n",
      "\n",
      "    accuracy                           0.96      1100\n",
      "   macro avg       0.96      0.96      0.96      1100\n",
      "weighted avg       0.96      0.96      0.96      1100\n",
      "\n",
      "Time for training model ID3 - default, FFD, m = 10 is: 2.4367880821228027.\n"
     ]
    }
   ],
   "source": [
    "# ID3 - Default\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "model_id3 = Id3Estimator()\n",
    "model_id3.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_id3 = model_id3.predict(x_test)\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model ID3 - default, {disc}, m = {m} is: {end - start}.') # Total time execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b6ab7375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.88       114\n",
      "           1       0.77      0.70      0.74       115\n",
      "           2       0.80      0.91      0.85       114\n",
      "           3       0.82      0.97      0.89       106\n",
      "           4       1.00      0.96      0.98       114\n",
      "           5       0.96      0.63      0.76       105\n",
      "           6       0.95      0.98      0.96       106\n",
      "           7       0.93      0.88      0.90       114\n",
      "           8       0.88      0.72      0.79       106\n",
      "           9       0.75      0.94      0.83       106\n",
      "\n",
      "    accuracy                           0.86      1100\n",
      "   macro avg       0.87      0.86      0.86      1100\n",
      "weighted avg       0.87      0.86      0.86      1100\n",
      "\n",
      "Time for training model Naive Bayes - default, FFD, m = 10 is: 0.01919388771057129.\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes - Default\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "model_nb = CategoricalNB()\n",
    "model_nb.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_nb = model_nb.predict(x_test)\n",
    "model_nb.classes_\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "end = time.time()\n",
    "print(f'Time for training model Naive Bayes - default, {disc}, m = {m} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d16f3baa",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "76.0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-48975f37ca5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mknn_vdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0my_pred_knn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn_vdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mknn_vdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_knn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/neighbors/_classification.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mdata\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \"\"\"\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0m_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    750\u001b[0m                 \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meffective_metric_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m             chunked_results = list(\n\u001b[0m\u001b[1;32m    753\u001b[0m                 pairwise_distances_chunked(\n\u001b[1;32m    754\u001b[0m                     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[1;32m   1715\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1716\u001b[0m             \u001b[0mX_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1717\u001b[0;31m         \u001b[0mD_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpairwise_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1718\u001b[0m         if (X is Y or Y is None) and PAIRWISE_DISTANCE_FUNCTIONS.get(\n\u001b[1;32m   1719\u001b[0m             \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[0;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   1887\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1889\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m     \u001b[0;31m# enforce a threading backend to prevent data communication overhead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_pairwise_callable\u001b[0;34m(X, Y, metric, force_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   1472\u001b[0m         \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1474\u001b[0;31m             \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/vdm3/vdm.py\u001b[0m in \u001b[0;36mget_distance\u001b[0;34m(self, ins_1, ins_2, norm)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mins_2_cat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mcat_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_delta_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcond_proba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mins_1_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mins_2_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontinuous\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/vdm3/components.py\u001b[0m in \u001b[0;36mget_delta_nd\u001b[0;34m(cond_proba, ins_1, ins_2, norm)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mReturns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdeltas\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0mbetween\u001b[0m \u001b[0mins_1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mins_2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \"\"\"\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mdeltas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mget_delta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond_proba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mins_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mins_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcond_proba\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeltas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/vdm3/components.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mReturns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdeltas\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0mbetween\u001b[0m \u001b[0mins_1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mins_2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \"\"\"\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mdeltas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mget_delta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond_proba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mins_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mins_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcond_proba\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeltas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/vdm3/components.py\u001b[0m in \u001b[0;36mget_delta\u001b[0;34m(cond_proba, val_1, val_2, norm)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mReturns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthis\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \"\"\"\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond_proba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muni_x\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcond_proba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muni_x\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0muni_x\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcond_proba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mproba\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 76.0"
     ]
    }
   ],
   "source": [
    "# Knn-VDM complete code - TRY SAMPLE 500\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(x_train[:500,:], y_train[:500], continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "## Fit model\n",
    "knn_vdm.fit(x_train[:500,:], y_train[:500])\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(x_test[:500,:])\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test[:500], y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM, {disc}, m = {m} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "01bce734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation result, accuracy, FFD, k = 10.\n",
      "ID3, validation accuracy:, 0.9629854368932039\n",
      "CNB, validation accuracy:, 0.8671116504854369\n"
     ]
    }
   ],
   "source": [
    "# VALIDATION\n",
    "scores = 'accuracy'\n",
    "print(f'Validation result, {scores}, {disc}, k = {k}.')\n",
    "# Create list of algorithms\n",
    "models = []\n",
    "models.append(('ID3', model_id3))\n",
    "models.append(('CNB', model_nb))\n",
    "# models.append(('Knn-VDM', KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')))\n",
    "\n",
    "# Evaluate each model in turn\n",
    "# get predicted prices on validation data\n",
    "for name, model in models:\n",
    "    val_pred = model.predict(x_val)\n",
    "    val_results = metrics.accuracy_score(y_val, val_pred)\n",
    "    print(f'{name}, validation accuracy:, {val_results}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747b0235",
   "metadata": {},
   "source": [
    "### Evaluation, FFD, m= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "573bc805",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d6cb00e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.052\n",
      "Average bias: 0.017\n",
      "Average variance: 0.048\n",
      "Sklearn 0-1 loss: 0.041\n"
     ]
    }
   ],
   "source": [
    "# ID3\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_id3, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "844d0605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.146\n",
      "Average bias: 0.140\n",
      "Average variance: 0.043\n",
      "Sklearn 0-1 loss: 0.138\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_nb, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1b7bfa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Knn\n",
    "# avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "# knn_vdm, x_train, y_train, x_test, y_test,\n",
    "# loss='0-1_loss',\n",
    "# random_seed=123)\n",
    "# #---\n",
    "# print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "# print('Average bias: %.3f' % avg_bias)\n",
    "# print('Average variance: %.3f' % avg_var)\n",
    "# print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7be02e",
   "metadata": {},
   "source": [
    "## FFD, m = 30, pendigits_ffd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7d52f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10992 entries, 0 to 10991\n",
      "Data columns (total 17 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   A1      10992 non-null  int64\n",
      " 1   A2      10992 non-null  int64\n",
      " 2   A3      10992 non-null  int64\n",
      " 3   A4      10992 non-null  int64\n",
      " 4   A5      10992 non-null  int64\n",
      " 5   A6      10992 non-null  int64\n",
      " 6   A7      10992 non-null  int64\n",
      " 7   A8      10992 non-null  int64\n",
      " 8   A9      10992 non-null  int64\n",
      " 9   A10     10992 non-null  int64\n",
      " 10  A11     10992 non-null  int64\n",
      " 11  A12     10992 non-null  int64\n",
      " 12  A13     10992 non-null  int64\n",
      " 13  A14     10992 non-null  int64\n",
      " 14  A15     10992 non-null  int64\n",
      " 15  A16     10992 non-null  int64\n",
      " 16  class   10992 non-null  int64\n",
      "dtypes: int64(17)\n",
      "memory usage: 1.4 MB\n",
      "(10992, 16) (10992,)\n",
      "Class representation - original:  Counter({2: 1144, 4: 1144, 1: 1143, 0: 1143, 7: 1142, 6: 1056, 8: 1055, 5: 1055, 9: 1055, 3: 1055})\n",
      "Class representation - training data:  Counter({4: 858, 2: 858, 0: 857, 1: 857, 7: 857, 5: 792, 6: 792, 3: 791, 8: 791, 9: 791})\n",
      "Class representation - testing data:  Counter({1: 115, 7: 114, 4: 114, 2: 114, 0: 114, 6: 106, 3: 106, 9: 106, 8: 106, 5: 105})\n",
      "Class representation - validation data:  Counter({4: 172, 0: 172, 2: 172, 1: 171, 7: 171, 8: 158, 6: 158, 5: 158, 3: 158, 9: 158})\n",
      "(8244, 16) (1648, 16) (1100, 16)\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_ffd2 = pd.read_csv('pendigits_ffd2.csv')\n",
    "disc = 'FFD'\n",
    "m = 30\n",
    "\n",
    "df_ffd2.info()\n",
    "data = df_ffd2.values\n",
    "data.shape\n",
    "\n",
    "features = df_ffd2.drop('class', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split data:\n",
    "train_ratio = 0.75\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.10\n",
    "\n",
    "# train is now 75% of the entire data set\n",
    "# the _junk suffix means that we drop that variable completely\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=1 - train_ratio, random_state = 30, stratify = Y)\n",
    "\n",
    "# test is now 10% of the initial data set\n",
    "# validation is now 15% of the initial data set\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio), random_state = 30, stratify = y_test)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(df_ffd2['class'])) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ',Counter(y_test)) \n",
    "print('Class representation - validation data: ',Counter(y_val))\n",
    "\n",
    "print(x_train.shape, x_val.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7e6dae",
   "metadata": {},
   "source": [
    "### Models, FFD, m=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "80660694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       114\n",
      "           1       0.89      0.93      0.91       115\n",
      "           2       0.96      0.91      0.94       114\n",
      "           3       0.93      0.94      0.94       106\n",
      "           4       0.99      0.98      0.99       114\n",
      "           5       0.97      0.96      0.97       105\n",
      "           6       0.97      0.98      0.98       106\n",
      "           7       0.93      0.97      0.95       114\n",
      "           8       0.99      0.97      0.98       106\n",
      "           9       0.94      0.93      0.94       106\n",
      "\n",
      "    accuracy                           0.96      1100\n",
      "   macro avg       0.96      0.96      0.96      1100\n",
      "weighted avg       0.96      0.96      0.96      1100\n",
      "\n",
      "Time for training model ID3 - default, FFD, m = 30 is: 2.528325080871582.\n"
     ]
    }
   ],
   "source": [
    "# ID3 - Default\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "model_id3 = Id3Estimator()\n",
    "model_id3.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_id3 = model_id3.predict(x_test)\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model ID3 - default, {disc}, m = {m} is: {end - start}.') # Total time execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "00881918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.88       114\n",
      "           1       0.76      0.70      0.73       115\n",
      "           2       0.80      0.91      0.85       114\n",
      "           3       0.83      0.97      0.90       106\n",
      "           4       1.00      0.96      0.98       114\n",
      "           5       0.94      0.63      0.75       105\n",
      "           6       0.95      0.98      0.96       106\n",
      "           7       0.93      0.88      0.90       114\n",
      "           8       0.88      0.71      0.79       106\n",
      "           9       0.75      0.94      0.83       106\n",
      "\n",
      "    accuracy                           0.86      1100\n",
      "   macro avg       0.87      0.86      0.86      1100\n",
      "weighted avg       0.87      0.86      0.86      1100\n",
      "\n",
      "Time for training model Naive Bayes - default, FFD, m = 30 is: 0.021018028259277344.\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes - Default\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "model_nb = CategoricalNB()\n",
    "model_nb.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_nb = model_nb.predict(x_test)\n",
    "model_nb.classes_\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "end = time.time()\n",
    "print(f'Time for training model Naive Bayes - default, {disc}, m = {m} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3e1da400",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "70.0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-0f4ada6ff58f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mknn_vdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0my_pred_knn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn_vdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mknn_vdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_knn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/neighbors/_classification.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mdata\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \"\"\"\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0m_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    750\u001b[0m                 \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meffective_metric_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m             chunked_results = list(\n\u001b[0m\u001b[1;32m    753\u001b[0m                 pairwise_distances_chunked(\n\u001b[1;32m    754\u001b[0m                     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[1;32m   1715\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1716\u001b[0m             \u001b[0mX_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1717\u001b[0;31m         \u001b[0mD_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpairwise_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1718\u001b[0m         if (X is Y or Y is None) and PAIRWISE_DISTANCE_FUNCTIONS.get(\n\u001b[1;32m   1719\u001b[0m             \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[0;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   1887\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1889\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m     \u001b[0;31m# enforce a threading backend to prevent data communication overhead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_pairwise_callable\u001b[0;34m(X, Y, metric, force_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   1472\u001b[0m         \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1474\u001b[0;31m             \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/vdm3/vdm.py\u001b[0m in \u001b[0;36mget_distance\u001b[0;34m(self, ins_1, ins_2, norm)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mins_2_cat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mcat_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_delta_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcond_proba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mins_1_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mins_2_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontinuous\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/vdm3/components.py\u001b[0m in \u001b[0;36mget_delta_nd\u001b[0;34m(cond_proba, ins_1, ins_2, norm)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mReturns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdeltas\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0mbetween\u001b[0m \u001b[0mins_1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mins_2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \"\"\"\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mdeltas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mget_delta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond_proba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mins_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mins_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcond_proba\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeltas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/vdm3/components.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mReturns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdeltas\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0mbetween\u001b[0m \u001b[0mins_1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mins_2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \"\"\"\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mdeltas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mget_delta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond_proba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mins_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mins_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcond_proba\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeltas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/vdm3/components.py\u001b[0m in \u001b[0;36mget_delta\u001b[0;34m(cond_proba, val_1, val_2, norm)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mReturns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthis\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \"\"\"\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond_proba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muni_x\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcond_proba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muni_x\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0muni_x\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcond_proba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mproba\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 70.0"
     ]
    }
   ],
   "source": [
    "# Knn-VDM complete code - TRY SAMPLE 500\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(x_train[:500,:], y_train[:500], continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "## Fit model\n",
    "knn_vdm.fit(x_train[:500,:], y_train[:500])\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(x_test[:500,:])\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test[:500], y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM, {disc}, m = {m} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "25289082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation result, accuracy, FFD, k = 10.\n",
      "ID3, validation accuracy:, 0.9635922330097088\n",
      "CNB, validation accuracy:, 0.8695388349514563\n"
     ]
    }
   ],
   "source": [
    "# VALIDATION\n",
    "scores = 'accuracy'\n",
    "print(f'Validation result, {scores}, {disc}, k = {k}.')\n",
    "# Create list of algorithms\n",
    "models = []\n",
    "models.append(('ID3', model_id3))\n",
    "models.append(('CNB', model_nb))\n",
    "#models.append(('Knn-VDM', KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')))\n",
    "\n",
    "# Evaluate each model in turn\n",
    "# get predicted prices on validation data\n",
    "for name, model in models:\n",
    "    val_pred = model.predict(x_val)\n",
    "    val_results = metrics.accuracy_score(y_val, val_pred)\n",
    "    print(f'{name}, validation accuracy:, {val_results}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb83dbf3",
   "metadata": {},
   "source": [
    "### Evaluation, FFD, m= 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ff9bf8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f9a1e250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.052\n",
      "Average bias: 0.016\n",
      "Average variance: 0.048\n",
      "Sklearn 0-1 loss: 0.042\n"
     ]
    }
   ],
   "source": [
    "# ID3\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_id3, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c1e89946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.146\n",
      "Average bias: 0.140\n",
      "Average variance: 0.042\n",
      "Sklearn 0-1 loss: 0.139\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_nb, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d0313a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Knn\n",
    "# avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "# knn_vdm, x_train, y_train, x_test, y_test,\n",
    "# loss='0-1_loss',\n",
    "# random_seed=123)\n",
    "# #---\n",
    "# print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "# print('Average bias: %.3f' % avg_bias)\n",
    "# print('Average variance: %.3f' % avg_var)\n",
    "# print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645c5260",
   "metadata": {},
   "source": [
    "## FFD, m = 60, pendigits_ffd3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e84da500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10992 entries, 0 to 10991\n",
      "Data columns (total 17 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   A1      10992 non-null  int64\n",
      " 1   A2      10992 non-null  int64\n",
      " 2   A3      10992 non-null  int64\n",
      " 3   A4      10992 non-null  int64\n",
      " 4   A5      10992 non-null  int64\n",
      " 5   A6      10992 non-null  int64\n",
      " 6   A7      10992 non-null  int64\n",
      " 7   A8      10992 non-null  int64\n",
      " 8   A9      10992 non-null  int64\n",
      " 9   A10     10992 non-null  int64\n",
      " 10  A11     10992 non-null  int64\n",
      " 11  A12     10992 non-null  int64\n",
      " 12  A13     10992 non-null  int64\n",
      " 13  A14     10992 non-null  int64\n",
      " 14  A15     10992 non-null  int64\n",
      " 15  A16     10992 non-null  int64\n",
      " 16  class   10992 non-null  int64\n",
      "dtypes: int64(17)\n",
      "memory usage: 1.4 MB\n",
      "(10992, 16) (10992,)\n",
      "Class representation - original:  Counter({2: 1144, 4: 1144, 1: 1143, 0: 1143, 7: 1142, 6: 1056, 8: 1055, 5: 1055, 9: 1055, 3: 1055})\n",
      "Class representation - training data:  Counter({4: 858, 2: 858, 0: 857, 1: 857, 7: 857, 5: 792, 6: 792, 3: 791, 8: 791, 9: 791})\n",
      "Class representation - testing data:  Counter({1: 115, 7: 114, 4: 114, 2: 114, 0: 114, 6: 106, 3: 106, 9: 106, 8: 106, 5: 105})\n",
      "Class representation - validation data:  Counter({4: 172, 0: 172, 2: 172, 1: 171, 7: 171, 8: 158, 6: 158, 5: 158, 3: 158, 9: 158})\n",
      "(8244, 16) (1648, 16) (1100, 16)\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_ffd3 = pd.read_csv('pendigits_ffd3.csv')\n",
    "disc = 'FFD'\n",
    "m = 60\n",
    "\n",
    "df_ffd3.info()\n",
    "data = df_ffd3.values\n",
    "data.shape\n",
    "\n",
    "features = df_ffd3.drop('class', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split data:\n",
    "train_ratio = 0.75\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.10\n",
    "\n",
    "# train is now 75% of the entire data set\n",
    "# the _junk suffix means that we drop that variable completely\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=1 - train_ratio, random_state = 30, stratify = Y)\n",
    "\n",
    "# test is now 10% of the initial data set\n",
    "# validation is now 15% of the initial data set\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio), random_state = 30, stratify = y_test)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(df_ffd3['class'])) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ',Counter(y_test)) \n",
    "print('Class representation - validation data: ',Counter(y_val))\n",
    "\n",
    "print(x_train.shape, x_val.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de94e5e0",
   "metadata": {},
   "source": [
    "### Models, FFD, m=60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7e8d8cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       114\n",
      "           1       0.89      0.93      0.91       115\n",
      "           2       0.96      0.91      0.94       114\n",
      "           3       0.93      0.94      0.94       106\n",
      "           4       0.99      0.98      0.99       114\n",
      "           5       0.97      0.96      0.97       105\n",
      "           6       0.97      0.98      0.98       106\n",
      "           7       0.93      0.97      0.95       114\n",
      "           8       0.99      0.97      0.98       106\n",
      "           9       0.94      0.93      0.94       106\n",
      "\n",
      "    accuracy                           0.96      1100\n",
      "   macro avg       0.96      0.96      0.96      1100\n",
      "weighted avg       0.96      0.96      0.96      1100\n",
      "\n",
      "Time for training model ID3 - default, FFD, m = 60 is: 2.300124168395996.\n"
     ]
    }
   ],
   "source": [
    "# ID3 - Default\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "model_id3 = Id3Estimator()\n",
    "model_id3.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_id3 = model_id3.predict(x_test)\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model ID3 - default, {disc}, m = {m} is: {end - start}.') # Total time execution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ab1d431e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.88       114\n",
      "           1       0.76      0.71      0.74       115\n",
      "           2       0.81      0.91      0.86       114\n",
      "           3       0.84      0.97      0.90       106\n",
      "           4       1.00      0.96      0.98       114\n",
      "           5       0.94      0.64      0.76       105\n",
      "           6       0.95      0.98      0.97       106\n",
      "           7       0.93      0.88      0.90       114\n",
      "           8       0.88      0.70      0.78       106\n",
      "           9       0.74      0.94      0.83       106\n",
      "\n",
      "    accuracy                           0.86      1100\n",
      "   macro avg       0.87      0.86      0.86      1100\n",
      "weighted avg       0.87      0.86      0.86      1100\n",
      "\n",
      "Time for training model Naive Bayes - default, FFD, m = 60 is: 0.019541025161743164.\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes - Default\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "model_nb = CategoricalNB()\n",
    "model_nb.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_nb = model_nb.predict(x_test)\n",
    "model_nb.classes_\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "end = time.time()\n",
    "print(f'Time for training model Naive Bayes - default, {disc}, m = {m} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3fc0c27f",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "66.0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-0f4ada6ff58f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mknn_vdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0my_pred_knn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn_vdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mknn_vdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_knn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/neighbors/_classification.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mdata\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \"\"\"\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0m_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    750\u001b[0m                 \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meffective_metric_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m             chunked_results = list(\n\u001b[0m\u001b[1;32m    753\u001b[0m                 pairwise_distances_chunked(\n\u001b[1;32m    754\u001b[0m                     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[1;32m   1715\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1716\u001b[0m             \u001b[0mX_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1717\u001b[0;31m         \u001b[0mD_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpairwise_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1718\u001b[0m         if (X is Y or Y is None) and PAIRWISE_DISTANCE_FUNCTIONS.get(\n\u001b[1;32m   1719\u001b[0m             \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[0;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   1887\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1889\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m     \u001b[0;31m# enforce a threading backend to prevent data communication overhead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_pairwise_callable\u001b[0;34m(X, Y, metric, force_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   1472\u001b[0m         \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1474\u001b[0;31m             \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/vdm3/vdm.py\u001b[0m in \u001b[0;36mget_distance\u001b[0;34m(self, ins_1, ins_2, norm)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mins_2_cat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mcat_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_delta_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcond_proba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mins_1_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mins_2_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontinuous\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/vdm3/components.py\u001b[0m in \u001b[0;36mget_delta_nd\u001b[0;34m(cond_proba, ins_1, ins_2, norm)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mReturns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdeltas\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0mbetween\u001b[0m \u001b[0mins_1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mins_2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \"\"\"\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mdeltas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mget_delta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond_proba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mins_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mins_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcond_proba\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeltas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/vdm3/components.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mReturns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdeltas\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0mbetween\u001b[0m \u001b[0mins_1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mins_2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \"\"\"\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mdeltas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mget_delta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond_proba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mins_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mins_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcond_proba\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeltas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/vdm3/components.py\u001b[0m in \u001b[0;36mget_delta\u001b[0;34m(cond_proba, val_1, val_2, norm)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mReturns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthis\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \"\"\"\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond_proba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muni_x\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcond_proba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muni_x\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0muni_x\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcond_proba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mproba\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 66.0"
     ]
    }
   ],
   "source": [
    "# Knn-VDM complete code - TRY SAMPLE 500\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(x_train[:500,:], y_train[:500], continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "## Fit model\n",
    "knn_vdm.fit(x_train[:500,:], y_train[:500])\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(x_test[:500,:])\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test[:500], y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM, {disc}, m = {m} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9bcffb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation result, accuracy, FFD, k = 10.\n",
      "ID3, validation accuracy:, 0.9635922330097088\n",
      "CNB, validation accuracy:, 0.8725728155339806\n"
     ]
    }
   ],
   "source": [
    "# VALIDATION\n",
    "scores = 'accuracy'\n",
    "print(f'Validation result, {scores}, {disc}, k = {k}.')\n",
    "# Create list of algorithms\n",
    "models = []\n",
    "models.append(('ID3', model_id3))\n",
    "models.append(('CNB', model_nb))\n",
    "# models.append(('Knn-VDM', KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')))\n",
    "\n",
    "# Evaluate each model in turn\n",
    "# get predicted prices on validation data\n",
    "for name, model in models:\n",
    "    val_pred = model.predict(x_val)\n",
    "    val_results = metrics.accuracy_score(y_val, val_pred)\n",
    "    print(f'{name}, validation accuracy:, {val_results}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba29e73",
   "metadata": {},
   "source": [
    "### Evaluation, FFD, m=60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5738e093",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "66e074fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.053\n",
      "Average bias: 0.017\n",
      "Average variance: 0.048\n",
      "Sklearn 0-1 loss: 0.042\n"
     ]
    }
   ],
   "source": [
    "# ID3\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_id3, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0633fc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.142\n",
      "Average bias: 0.140\n",
      "Average variance: 0.040\n",
      "Sklearn 0-1 loss: 0.138\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_nb, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "33e36652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Knn\n",
    "# avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "# knn_vdm, x_train, y_train, x_test, y_test,\n",
    "# loss='0-1_loss',\n",
    "# random_seed=123)\n",
    "# #---\n",
    "# print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "# print('Average bias: %.3f' % avg_bias)\n",
    "# print('Average variance: %.3f' % avg_var)\n",
    "# print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcae22c3",
   "metadata": {},
   "source": [
    "## FFD, m = 100 (pendigits_ffd4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa5b1e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10992 entries, 0 to 10991\n",
      "Data columns (total 17 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   A1      10992 non-null  int64\n",
      " 1   A2      10992 non-null  int64\n",
      " 2   A3      10992 non-null  int64\n",
      " 3   A4      10992 non-null  int64\n",
      " 4   A5      10992 non-null  int64\n",
      " 5   A6      10992 non-null  int64\n",
      " 6   A7      10992 non-null  int64\n",
      " 7   A8      10992 non-null  int64\n",
      " 8   A9      10992 non-null  int64\n",
      " 9   A10     10992 non-null  int64\n",
      " 10  A11     10992 non-null  int64\n",
      " 11  A12     10992 non-null  int64\n",
      " 12  A13     10992 non-null  int64\n",
      " 13  A14     10992 non-null  int64\n",
      " 14  A15     10992 non-null  int64\n",
      " 15  A16     10992 non-null  int64\n",
      " 16  class   10992 non-null  int64\n",
      "dtypes: int64(17)\n",
      "memory usage: 1.4 MB\n",
      "(10992, 16) (10992,)\n",
      "Class representation - original:  Counter({2: 1144, 4: 1144, 1: 1143, 0: 1143, 7: 1142, 6: 1056, 8: 1055, 5: 1055, 9: 1055, 3: 1055})\n",
      "Class representation - training data:  Counter({4: 858, 2: 858, 0: 857, 1: 857, 7: 857, 5: 792, 6: 792, 3: 791, 8: 791, 9: 791})\n",
      "Class representation - testing data:  Counter({1: 115, 7: 114, 4: 114, 2: 114, 0: 114, 6: 106, 3: 106, 9: 106, 8: 106, 5: 105})\n",
      "Class representation - validation data:  Counter({4: 172, 0: 172, 2: 172, 1: 171, 7: 171, 8: 158, 6: 158, 5: 158, 3: 158, 9: 158})\n",
      "(8244, 16) (1648, 16) (1100, 16)\n"
     ]
    }
   ],
   "source": [
    "# Complete code for data preperation\n",
    "# Read data\n",
    "df_ffd4 = pd.read_csv('pendigits_ffd4.csv')\n",
    "disc = 'FFD'\n",
    "m = 100\n",
    "\n",
    "df_ffd4.info()\n",
    "data = df_ffd4.values\n",
    "data.shape\n",
    "\n",
    "features = df_ffd4.drop('class', axis = 1).columns\n",
    "\n",
    "# separate the data into X and y\n",
    "X = data[:, : len(features)]\n",
    "Y = data[:,-1]\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "# Split data:\n",
    "train_ratio = 0.75\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.10\n",
    "\n",
    "# train is now 75% of the entire data set\n",
    "# the _junk suffix means that we drop that variable completely\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=1 - train_ratio, random_state = 30, stratify = Y)\n",
    "\n",
    "# test is now 10% of the initial data set\n",
    "# validation is now 15% of the initial data set\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio), random_state = 30, stratify = y_test)\n",
    "\n",
    "# Check representation of class\n",
    "print('Class representation - original: ', Counter(df_ffd4['class'])) \n",
    "print('Class representation - training data: ', Counter(y_train)) \n",
    "print('Class representation - testing data: ',Counter(y_test)) \n",
    "print('Class representation - validation data: ',Counter(y_val))\n",
    "\n",
    "print(x_train.shape, x_val.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f46c46",
   "metadata": {},
   "source": [
    "### Models, FFD, m=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1852747c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       114\n",
      "           1       0.91      0.92      0.92       115\n",
      "           2       0.95      0.93      0.94       114\n",
      "           3       0.93      0.94      0.93       106\n",
      "           4       0.99      0.98      0.99       114\n",
      "           5       0.98      0.95      0.97       105\n",
      "           6       0.97      1.00      0.99       106\n",
      "           7       0.93      0.97      0.95       114\n",
      "           8       0.99      0.97      0.98       106\n",
      "           9       0.93      0.92      0.92       106\n",
      "\n",
      "    accuracy                           0.96      1100\n",
      "   macro avg       0.96      0.96      0.96      1100\n",
      "weighted avg       0.96      0.96      0.96      1100\n",
      "\n",
      "Time for training model ID3 - default, FFD, m = 100 is: 2.0468451976776123.\n"
     ]
    }
   ],
   "source": [
    "# ID3 - Default\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "model_id3 = Id3Estimator()\n",
    "model_id3.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_id3 = model_id3.predict(x_test)\n",
    "print(classification_report(y_test, y_pred_id3))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model ID3 - default, {disc}, m = {m} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "398251e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.92      0.89       114\n",
      "           1       0.77      0.72      0.74       115\n",
      "           2       0.82      0.91      0.86       114\n",
      "           3       0.86      0.97      0.91       106\n",
      "           4       1.00      0.96      0.98       114\n",
      "           5       0.93      0.67      0.78       105\n",
      "           6       0.96      0.98      0.97       106\n",
      "           7       0.95      0.89      0.92       114\n",
      "           8       0.89      0.74      0.80       106\n",
      "           9       0.76      0.97      0.85       106\n",
      "\n",
      "    accuracy                           0.87      1100\n",
      "   macro avg       0.88      0.87      0.87      1100\n",
      "weighted avg       0.88      0.87      0.87      1100\n",
      "\n",
      "Time for training model Naive Bayes - default, FFD, m = 100 is: 0.018578767776489258.\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes - Default\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "model_nb = CategoricalNB()\n",
    "model_nb.fit(x_train, y_train)\n",
    "# Testing\n",
    "y_pred_nb = model_nb.predict(x_test)\n",
    "model_nb.classes_\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "end = time.time()\n",
    "print(f'Time for training model Naive Bayes - default, {disc}, m = {m} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "793350f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "62.0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-0f4ada6ff58f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mknn_vdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0my_pred_knn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn_vdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mknn_vdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_knn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/neighbors/_classification.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mdata\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \"\"\"\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0m_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    750\u001b[0m                 \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meffective_metric_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m             chunked_results = list(\n\u001b[0m\u001b[1;32m    753\u001b[0m                 pairwise_distances_chunked(\n\u001b[1;32m    754\u001b[0m                     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[0;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[1;32m   1715\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1716\u001b[0m             \u001b[0mX_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1717\u001b[0;31m         \u001b[0mD_chunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpairwise_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1718\u001b[0m         if (X is Y or Y is None) and PAIRWISE_DISTANCE_FUNCTIONS.get(\n\u001b[1;32m   1719\u001b[0m             \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[0;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   1887\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1888\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1889\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[0;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[1;32m   1428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m     \u001b[0;31m# enforce a threading backend to prevent data communication overhead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36m_pairwise_callable\u001b[0;34m(X, Y, metric, force_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   1472\u001b[0m         \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1474\u001b[0;31m             \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/vdm3/vdm.py\u001b[0m in \u001b[0;36mget_distance\u001b[0;34m(self, ins_1, ins_2, norm)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mins_2_cat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mcat_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_delta_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcond_proba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mins_1_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mins_2_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontinuous\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/vdm3/components.py\u001b[0m in \u001b[0;36mget_delta_nd\u001b[0;34m(cond_proba, ins_1, ins_2, norm)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mReturns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdeltas\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0mbetween\u001b[0m \u001b[0mins_1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mins_2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \"\"\"\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mdeltas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mget_delta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond_proba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mins_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mins_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcond_proba\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeltas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/vdm3/components.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mReturns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdeltas\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0mbetween\u001b[0m \u001b[0mins_1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mins_2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \"\"\"\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0mdeltas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mget_delta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond_proba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mins_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mins_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcond_proba\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeltas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/vdm3/components.py\u001b[0m in \u001b[0;36mget_delta\u001b[0;34m(cond_proba, val_1, val_2, norm)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mReturns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthis\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \"\"\"\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond_proba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muni_x\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcond_proba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muni_x\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0muni_x\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcond_proba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mproba\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 62.0"
     ]
    }
   ],
   "source": [
    "# Knn-VDM complete code - TRY SAMPLE 500\n",
    "import time\n",
    "start = time.time() # For measuring time execution\n",
    "\n",
    "# specific the continuous columns index if any\n",
    "vdm = ValueDifferenceMetric(x_train[:500,:], y_train[:500], continuous = None)\n",
    "vdm.fit()\n",
    "# Knn model, n_neigbour = 3, metrics = vdm\n",
    "knn_vdm = KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')\n",
    "## Fit model\n",
    "knn_vdm.fit(x_train[:500,:], y_train[:500])\n",
    "# Testing\n",
    "y_pred_knn = knn_vdm.predict(x_test[:500,:])\n",
    "knn_vdm.classes_\n",
    "print(classification_report(y_test[:500], y_pred_knn))\n",
    "\n",
    "end = time.time()\n",
    "print(f'Time for training model Knn-VDM, {disc}, m = {m} is: {end - start}.') # Total time execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "11429824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation result, accuracy, FFD, k = 10.\n",
      "ID3, validation accuracy:, 0.9654126213592233\n",
      "CNB, validation accuracy:, 0.8780339805825242\n"
     ]
    }
   ],
   "source": [
    "# VALIDATION\n",
    "scores = 'accuracy'\n",
    "print(f'Validation result, {scores}, {disc}, k = {k}.')\n",
    "# Create list of algorithms\n",
    "models = []\n",
    "models.append(('ID3', model_id3))\n",
    "models.append(('CNB', model_nb))\n",
    "# models.append(('Knn-VDM', KNeighborsClassifier(n_neighbors=3, metric=vdm.get_distance, algorithm='brute')))\n",
    "\n",
    "# Evaluate each model in turn\n",
    "# get predicted prices on validation data\n",
    "for name, model in models:\n",
    "    val_pred = model.predict(x_val)\n",
    "    val_results = metrics.accuracy_score(y_val, val_pred)\n",
    "    print(f'{name}, validation accuracy:, {val_results}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e376be",
   "metadata": {},
   "source": [
    "### Evaluation, FFD, m=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "112fc357",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import zero_one_loss\n",
    "#This library is used to decompose bias and variance in our models\n",
    "from mlxtend.evaluate import bias_variance_decomp\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "11da5847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.053\n",
      "Average bias: 0.015\n",
      "Average variance: 0.049\n",
      "Sklearn 0-1 loss: 0.042\n"
     ]
    }
   ],
   "source": [
    "# ID3\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_id3, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_id3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "06f1afd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average expected loss: 0.135\n",
      "Average bias: 0.128\n",
      "Average variance: 0.035\n",
      "Sklearn 0-1 loss: 0.126\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "model_nb, x_train, y_train, x_test, y_test,\n",
    "loss='0-1_loss',\n",
    "random_seed=123)\n",
    "#---\n",
    "print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "print('Average bias: %.3f' % avg_bias)\n",
    "print('Average variance: %.3f' % avg_var)\n",
    "print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fa0142cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Knn\n",
    "# avg_expected_loss, avg_bias, avg_var = bias_variance_decomp(\n",
    "# knn_vdm, x_train, y_train, x_test, y_test,\n",
    "# loss='0-1_loss',\n",
    "# random_seed=123)\n",
    "# #---\n",
    "# print('Average expected loss: %.3f' % avg_expected_loss)\n",
    "# print('Average bias: %.3f' % avg_bias)\n",
    "# print('Average variance: %.3f' % avg_var)\n",
    "# print('Sklearn 0-1 loss: %.3f' % zero_one_loss(y_test,y_pred_knn))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
